{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/robots.txt","path":"robots.txt","modified":0,"renderable":0},{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"themes/next/source/baidu_verify_oo3AHvvCK7.html","path":"baidu_verify_oo3AHvvCK7.html","modified":0,"renderable":1},{"_id":"themes/next/source/google1bfaee946527fc4a.html","path":"google1bfaee946527fc4a.html","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.jpg","path":"images/avatar.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/js/love.js","path":"js/love.js","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/love.js","path":"js/src/love.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/README.md","path":"lib/needsharebutton/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/LICENSE","path":"lib/needsharebutton/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1}],"Cache":[{"_id":"source/baidu_verify_oo3AHvvCK7.html","hash":"303f274f65b6bc92de6bce1b222fb819abbc432d","modified":1564500942744},{"_id":"source/robots.txt","hash":"a05b35a4ee0eea6e94f0d1721fd090cbf097b20a","modified":1565168068467},{"_id":"source/google1bfaee946527fc4a.html","hash":"12f5515e76f58eef28153a53898a8c922e268d76","modified":1564500942744},{"_id":"source/CNAME","hash":"3d80c81638dc40478d251e1deab3820104ce8789","modified":1564500942713},{"_id":"themes/next/.gitattributes","hash":"8454b9313cb1a97b63fb87e2d29daee497ce6249","modified":1564500942838},{"_id":"themes/next/.editorconfig","hash":"211d2c92bfdddb3e81ea946f4ca7a539f150f4da","modified":1564500942838},{"_id":"themes/next/.bowerrc","hash":"334da94ca6f024d60d012cc26ea655681e724ad8","modified":1564500942838},{"_id":"themes/next/.jshintrc","hash":"b7d23f2ce8d99fa073f22f9960605f318acd7710","modified":1564500942838},{"_id":"themes/next/.gitignore","hash":"ee0b13c268cc8695d3883a5da84930af02d4ed08","modified":1564500942838},{"_id":"themes/next/.hound.yml","hash":"289dcf5bfe92dbd680d54d6e0668f41c9c9c0c78","modified":1564500942838},{"_id":"themes/next/.javascript_ignore","hash":"cd250ad74ca22bd2c054476456a73d9687f05f87","modified":1564500942838},{"_id":"themes/next/.stylintrc","hash":"3b7f9785e9ad0dab764e1c535b40df02f4ff5fd6","modified":1564500942838},{"_id":"themes/next/LICENSE","hash":"ec44503d7e617144909e54533754f0147845f0c5","modified":1564500942838},{"_id":"themes/next/README.cn.md","hash":"23e92a2599725db2f8dbd524fbef2087c6d11c7b","modified":1564500942853},{"_id":"themes/next/README.md","hash":"50abff86ffe4113051a409c1ed9261195d2aead0","modified":1564500942853},{"_id":"themes/next/bower.json","hash":"486ebd72068848c97def75f36b71cbec9bb359c5","modified":1564500942853},{"_id":"themes/next/.travis.yml","hash":"6674fbdfe0d0c03b8a04527ffb8ab66a94253acd","modified":1564500942838},{"_id":"themes/next/package.json","hash":"3963ad558a24c78a3fd4ef23cf5f73f421854627","modified":1564500942916},{"_id":"themes/next/gulpfile.coffee","hash":"412defab3d93d404b7c26aaa0279e2e586e97454","modified":1564500942853},{"_id":"themes/next/_config.yml","hash":"d7f24bd52169f18725525a2dfc78d8457fd69bb8","modified":1565335812880},{"_id":"source/_posts/Network-in-Network.md","hash":"c36e65b2459161ac50795cb8631b6816abdf4a9b","modified":1564500942728},{"_id":"source/_posts/C-梳理笔记.md","hash":"a94647eb981d3f26aa6cf20f91e5b5d1d09245b8","modified":1564500942713},{"_id":"source/_posts/Deep-Residual-Learning-for-Image-Recognition.md","hash":"e3870d55a8e9bd2113004bb6de8674a562a51057","modified":1564500942728},{"_id":"source/_posts/git使用.md","hash":"7f1f7e1eef8e5be433942ae1c884339c194bb2d3","modified":1564504750819},{"_id":"source/_posts/pandas-分层和多级索引.md","hash":"a77266f2257a74a65d6395875c9e0645bcc53975","modified":1568182849779},{"_id":"source/_posts/pandas-数据结构.md","hash":"34c60aca4cb0648d53c962e5ae44122f982b76b9","modified":1565314776577},{"_id":"source/_posts/XGBoost.md","hash":"570fcc914585c46449c28c98bd682850e957542d","modified":1564504796988},{"_id":"source/_posts/pandas-缺失值处理.md","hash":"f719473bc5f78030516fc73039b99563c1291f50","modified":1568182827595},{"_id":"source/_posts/pandas-索引和选择数据.md","hash":"853893bcfaffb977503934adb483f0fadedb3e39","modified":1565518893095},{"_id":"source/_posts/pandas-时间-日期处理.md","hash":"eaca09da04c7af9ce26872d5a95c8b2bd743bb27","modified":1568182837932},{"_id":"source/_posts/决策树-1基本概念.md","hash":"329eddf4834f05b33bd9ebeaa2a667d5b3a6138f","modified":1564923628036},{"_id":"source/_posts/华为软挑.md","hash":"d74c6c6bf2887dcae1b67b5e2a512df6e73da31b","modified":1564500942728},{"_id":"source/_posts/pandas-重复值处理.md","hash":"8e14d84a38861772a7c4dfcdd0adf11727f7a45a","modified":1568182813038},{"_id":"source/_posts/评价指标-ROC与AUC.md","hash":"06541f832926d9bb0566fb2e6964f6cec360cff5","modified":1565316557555},{"_id":"source/_posts/欢迎来我的小屋！.md","hash":"2654ebc2df76f19f2cd0c890b9643b8628068533","modified":1564500942744},{"_id":"source/_posts/机器学习模型的偏差与方差.md","hash":"fd8fd2281721702e211b83a874f0ea1f42de498d","modified":1564712812381},{"_id":"source/_posts/集成学习-Adaboost.md","hash":"ecf5eaf424106c0379136ec3c40689cde6f48e66","modified":1564500942744},{"_id":"source/_posts/虚拟机类加载机制.md","hash":"7109bf461cb8068058f4ead136b71711fd0dbc7f","modified":1564500942744},{"_id":"source/about/index.md","hash":"c6143a439da4ad92a2c6e487c67bdb4a8fd2695a","modified":1564500942744},{"_id":"source/tags/index.md","hash":"2a77955e0063f1cc7435b780bc76a549844ff7e9","modified":1564500942744},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5adfad3ef1b870063e621bc0838268eb2c7c697a","modified":1564500942838},{"_id":"source/categories/index.md","hash":"f793ab61c3f03e58c74db3f278d8a3575b5fa613","modified":1564500942744},{"_id":"source/_posts/逻辑回归.md","hash":"b83e09403e4f5995050050337fc6ca9b05f1ed31","modified":1564500942744},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"a0a82dbfabdef9a9d7c17a08ceebfb4052d98d81","modified":1564500942838},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1564500942838},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"1228506a940114288d61812bfe60c045a0abeac1","modified":1564500942838},{"_id":"themes/next/languages/default.yml","hash":"b3bcd8934327448a43d9bfada5dd11b1b8c1402e","modified":1564500942853},{"_id":"themes/next/languages/de.yml","hash":"fd02d9c2035798d5dc7c1a96b4c3e24b05b31a47","modified":1564500942853},{"_id":"themes/next/languages/id.yml","hash":"dccae33e2a5b3c9f11c0e05ec4a7201af1b25745","modified":1564500942853},{"_id":"themes/next/languages/en.yml","hash":"2f4b4776ca1a08cc266a19afb0d1350a3926f42c","modified":1564500942853},{"_id":"themes/next/languages/fr-FR.yml","hash":"efeeb55d5c4add54ad59a612fc0630ee1300388c","modified":1564500942853},{"_id":"themes/next/languages/it.yml","hash":"a215d016146b1bd92cef046042081cbe0c7f976f","modified":1564500942853},{"_id":"themes/next/languages/ko.yml","hash":"dc8f3e8c64eb7c4bb2385025b3006b8efec8b31d","modified":1564500942853},{"_id":"themes/next/languages/nl-NL.yml","hash":"213e7a002b82fb265f69dabafbbc382cfd460030","modified":1564500942853},{"_id":"themes/next/languages/ja.yml","hash":"37f954e47a3bc669620ca559e3edb3b0072a4be5","modified":1564500942853},{"_id":"themes/next/languages/pt-BR.yml","hash":"568d494a1f37726a5375b11452a45c71c3e2852d","modified":1564500942853},{"_id":"themes/next/languages/ru.yml","hash":"e33ee44e80f82e329900fc41eb0bb6823397a4d6","modified":1564500942853},{"_id":"themes/next/languages/zh-Hans.yml","hash":"66b9b42f143c3cb2f782a94abd4c4cbd5fd7f55f","modified":1564500942853},{"_id":"themes/next/languages/pt.yml","hash":"2efcd240c66ab1a122f061505ca0fb1e8819877b","modified":1564500942853},{"_id":"themes/next/scripts/merge-configs.js","hash":"38d86aab4fc12fb741ae52099be475196b9db972","modified":1564500942916},{"_id":"themes/next/scripts/merge.js","hash":"39b84b937b2a9608b94e5872349a47200e1800ff","modified":1564500942916},{"_id":"themes/next/source/baidu_verify_oo3AHvvCK7.html","hash":"c7a5d65b658f4c7be1dc2702a86138ee7b9ed6ff","modified":1564500942932},{"_id":"themes/next/source/google1bfaee946527fc4a.html","hash":"12f5515e76f58eef28153a53898a8c922e268d76","modified":1564500943010},{"_id":"themes/next/test/.jshintrc","hash":"c9fca43ae0d99718e45a6f5ce736a18ba5fc8fb6","modified":1564500943135},{"_id":"themes/next/languages/zh-tw.yml","hash":"432463b481e105073accda16c3e590e54c8e7b74","modified":1564500942869},{"_id":"themes/next/languages/vi.yml","hash":"a9b89ebd3e5933033d1386c7c56b66c44aca299a","modified":1564500942853},{"_id":"themes/next/languages/zh-hk.yml","hash":"fe0d45807d015082049f05b54714988c244888da","modified":1564500942853},{"_id":"themes/next/test/helpers.js","hash":"f25e7f3265eb5a6e1ccbb5e5012fa9bebf134105","modified":1564500943135},{"_id":"themes/next/test/intern.js","hash":"db90b1063356727d72be0d77054fdc32fa882a66","modified":1564500943135},{"_id":"themes/next/layout/index.swig","hash":"555a357ecf17128db4e29346c92bb6298e66547a","modified":1564500942916},{"_id":"themes/next/layout/category.swig","hash":"3cbb3f72429647411f9e85f2544bdf0e3ad2e6b2","modified":1564500942916},{"_id":"themes/next/layout/archive.swig","hash":"9a2c14874a75c7085d2bada5e39201d3fc4fd2b4","modified":1564500942916},{"_id":"themes/next/layout/page.swig","hash":"e8fcaa641d46930237675d2ad4b56964d9e262e9","modified":1564500942916},{"_id":"themes/next/layout/_layout.swig","hash":"dae4285be6d23255e58ea85d1b0f9abed208fdbd","modified":1564500942869},{"_id":"themes/next/layout/tag.swig","hash":"34e1c016cbdf94a31f9c5d494854ff46b2a182e9","modified":1564500942916},{"_id":"themes/next/layout/post.swig","hash":"7a6ce102ca82c3a80f776e555dddae1a9981e1ed","modified":1564500942916},{"_id":"themes/next/layout/schedule.swig","hash":"87ad6055df01fa2e63e51887d34a2d8f0fbd2f5a","modified":1564500942916},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1564500943010},{"_id":"source/_posts/Deep-Residual-Learning-for-Image-Recognition/resnet1.png","hash":"56e71e5ae901cc533f289e2f88f425e182924701","modified":1564500942728},{"_id":"source/_posts/Network-in-Network/nerworkInNetwork1.png","hash":"139cf459a66b7a31924cf8951c3fd01660319b19","modified":1564500942728},{"_id":"source/_posts/决策树-1基本概念/tree.png","hash":"b657e72f62236d975809681103d06325f2ae4a03","modified":1564500942728},{"_id":"source/_posts/机器学习模型的偏差与方差/biasvariance.png","hash":"34d619dd4750bd282e700da634d2b9ae6eb4a17b","modified":1564649070842},{"_id":"themes/next/scripts/tags/full-image.js","hash":"c9f833158c66bd72f627a0559cf96550e867aa72","modified":1564500942916},{"_id":"themes/next/scripts/tags/button.js","hash":"eddbb612c15ac27faf11c59c019ce188f33dec2c","modified":1564500942916},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"ac681b0d0d8d39ba3817336c0270c6787c2b6b70","modified":1564500942916},{"_id":"themes/next/scripts/tags/exturl.js","hash":"5022c0ba9f1d13192677cf1fd66005c57c3d0f53","modified":1564500942916},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"99b66949f18398689b904907af23c013be1b978f","modified":1564500942916},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"bcba2ff25cd7850ce6da322d8bd85a8dd00b5ceb","modified":1564500942916},{"_id":"themes/next/scripts/tags/tabs.js","hash":"aa7fc94a5ec27737458d9fe1a75c0db7593352fd","modified":1564500942932},{"_id":"themes/next/scripts/tags/label.js","hash":"6f00952d70aadece844ce7fd27adc52816cc7374","modified":1564500942916},{"_id":"themes/next/scripts/tags/note.js","hash":"f7eae135f35cdab23728e9d0d88b76e00715faa0","modified":1564500942916},{"_id":"source/_posts/逻辑回归/cost.png","hash":"fef1f81317aea942b7616a1afc70e8a01b17b5e6","modified":1564500942744},{"_id":"source/_posts/逻辑回归/sigmoid.png","hash":"0c2ba4e2c5f9e3914a2584175f809af150dbe8db","modified":1564500942744},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1564500943010},{"_id":"themes/next/source/css/main.styl","hash":"a91dbb7ef799f0a171b5e726c801139efe545176","modified":1564500943010},{"_id":"themes/next/source/images/avatar.jpg","hash":"2f021e5ba8521a15bbd853c71bde6d3ef27a1518","modified":1564500943010},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1564500943010},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1564500943010},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1564500943010},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1564500943010},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1564500943010},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1564500943010},{"_id":"themes/next/source/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1564500943010},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1564500943010},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1564500943010},{"_id":"themes/next/source/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1564500943010},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1564500943010},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1564500943010},{"_id":"themes/next/source/js/love.js","hash":"d4fdbd1262e5388c1ea82661420c0a0f2b743344","modified":1564500943025},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1564500943010},{"_id":"themes/next/layout/_custom/header.swig","hash":"ba8ab5a0280b953aa97435ff8946cbcbb2755a27","modified":1564500942869},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"ba8ab5a0280b953aa97435ff8946cbcbb2755a27","modified":1564500942869},{"_id":"themes/next/source/images/quote-r.svg","hash":"2a2a250b32a87c69dcc1b1976c74b747bedbfb41","modified":1564500943010},{"_id":"themes/next/source/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1564500943010},{"_id":"themes/next/source/images/quote-l.svg","hash":"cd108d6f44351cadf8e6742565217f88818a0458","modified":1564500943010},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"77c61e0baea3544df361b7338c3cd13dc84dde22","modified":1564500942869},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4adc65a602d1276615da3b887dcbf2ac68e7382b","modified":1564500942869},{"_id":"themes/next/layout/_partials/header.swig","hash":"c54b32263bc8d75918688fb21f795103b3f57f03","modified":1564500942869},{"_id":"themes/next/layout/_partials/footer.swig","hash":"23da79bffdd6df6bf162396b0c0efdba775114da","modified":1564500942869},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"1634fb887842698e01ff6e632597fe03c75d2d01","modified":1564500942869},{"_id":"themes/next/layout/_partials/search.swig","hash":"b4ebe4a52a3b51efe549dd1cdee846103664f5eb","modified":1564500942869},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"f83befdc740beb8dc88805efd7fbb0fef9ed19be","modified":1564500942869},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"8c56dd26157cbc580ae41d97ac34b90ab48ced3f","modified":1564500942869},{"_id":"themes/next/layout/_partials/head.swig","hash":"3d1cc5fb8b210ec09df68be0b653e3bd9841a32c","modified":1564500942869},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"1d37377a669ea9fdfb54afe7f0965b1597db751f","modified":1564500942869},{"_id":"themes/next/layout/_macro/reward.swig","hash":"357d86ec9586705bfbb2c40a8c7d247a407db21a","modified":1564500942869},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"e2e4eae391476da994045ed4c7faf5e05aca2cd7","modified":1564500942869},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"8301c9600bb3e47f7fb98b0e0332ef3c51bb1688","modified":1564500942900},{"_id":"themes/next/layout/_macro/my-copyright.swig","hash":"6b2005cb8bd6b7dfdfa8efd3ad50760f22019b0f","modified":1564500942869},{"_id":"themes/next/layout/_macro/post.swig","hash":"368709167c68f503221062ff31094d6531bded73","modified":1564500942869},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"ba75672183d94f1de7c8bd0eeee497a58c70e889","modified":1564500942900},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"fa882641da3bd83d9a58a8a97f9d4c62a9ee7b5c","modified":1564500942900},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"554ec568e9d2c71e4a624a8de3cb5929050811d6","modified":1564500942900},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"a0bd3388587fd943baae0d84ca779a707fbcad89","modified":1564500942900},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"c0f5a0955f69ca4ed9ee64a2d5f8aa75064935ad","modified":1564500942885},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"931808ad9b8d8390c0dcf9bdeb0954eeb9185d68","modified":1564500942885},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"9a188938d46931d5f3882a140aa1c48b3a893f0c","modified":1564500942900},{"_id":"source/_posts/Deep-Residual-Learning-for-Image-Recognition/resnet2.png","hash":"7e08d7c3ddcc720fe424c1b1ed5c365164c89d35","modified":1564500942728},{"_id":"source/_posts/Network-in-Network/nerworkInNetwork2.png","hash":"5c49d49b5b4cb70e62446a97df515f3623ebba98","modified":1564500942728},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"db15d7e1552aa2d2386a6b8a33b3b3a40bf9e43d","modified":1564500942900},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1564500942978},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1564500942978},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1564500942978},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1564500942994},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1564500943010},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"9be624634703be496a5d2535228bc568a8373af9","modified":1564500942885},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1564500942885},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1564500942885},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"07f7da320689f828f6e36a6123807964a45157a0","modified":1564500942978},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"7896c3ee107e1a8b9108b6019f1c070600a1e8cc","modified":1564500942978},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"3403fdd8efde1a0afd11ae8a5a97673f5903087f","modified":1564500942978},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"0e55cbd93852dc3f8ccb44df74d35d9918f847e0","modified":1564500942978},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"a25408534f8fe6e321db4bbf9dd03335d648fe17","modified":1564500942994},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"58e7dd5947817d9fc30770712fc39b2f52230d1e","modified":1564500942994},{"_id":"themes/next/source/js/src/affix.js","hash":"1b509c3b5b290a6f4607f0f06461a0c33acb69b1","modified":1564500943025},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"cb431b54ba9c692165a1f5a12e4c564a560f8058","modified":1564500943025},{"_id":"themes/next/source/js/src/exturl.js","hash":"a2a0f0de07e46211f74942a468f42ee270aa555c","modified":1564500943025},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"b35a7dc47b634197b93487cea8671a40a9fdffce","modified":1564500943025},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"0289031200c3d4c2bdd801ee10fff13bb2c353e4","modified":1564500943025},{"_id":"themes/next/source/js/src/love.js","hash":"d4fdbd1262e5388c1ea82661420c0a0f2b743344","modified":1564500943025},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"1512c751d219577d338ac0780fb2bbd9075d5298","modified":1564500943025},{"_id":"themes/next/source/js/src/motion.js","hash":"885176ed51d468f662fbf0fc09611f45c7e5a3b1","modified":1564500943025},{"_id":"themes/next/source/js/src/post-details.js","hash":"93a18271b4123dd8f94f09d1439b47c3c19a8712","modified":1564500943025},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"02cf91514e41200bc9df5d8bdbeb58575ec06074","modified":1564500943025},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"b7657be25fc52ec67c75ab5481bdcb483573338b","modified":1564500943025},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1564500943041},{"_id":"themes/next/source/js/src/utils.js","hash":"b3e9eca64aba59403334f3fa821f100d98d40337","modified":1564500943025},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"4069f918ccc312da86db6c51205fc6c6eaabb116","modified":1564500942994},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"b02737510e9b89aeed6b54f89f602a9c24b06ff2","modified":1564500943041},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"865d6c1328ab209a4376b9d2b7a7824369565f28","modified":1564500943088},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1564500943041},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"03ddbf76c1dd1afb93eed0b670d2eee747472ef1","modified":1564500943072},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"ee33b2798b1e714b904d663436c6b3521011d1fa","modified":1564500943072},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"71e7183634dc1b9449f590f15ebd7201add22ca7","modified":1564500943072},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"b4aefc910578d76b267e86dfffdd5121c8db9aec","modified":1564500943072},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"bf3eef9d647cd7c9b62feda3bc708c6cdd7c0877","modified":1564500943057},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"a9b3ee1e4db71a0e4ea6d5bed292d176dd68b261","modified":1564500943057},{"_id":"themes/next/source/css/_variables/base.styl","hash":"b1f6ea881a4938a54603d68282b0f8efb4d7915d","modified":1564500943010},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"68a9b9d53126405b0fa5f3324f1fb96dbcc547aa","modified":1564500943057},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"c31ff06a740955e44edd4403902e653ccabfd4db","modified":1564500943072},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"b930297cb98b8e1dbd5abe9bc1ed9d5935d18ce8","modified":1564500943088},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4ded6fee668544778e97e38c2b211fc56c848e77","modified":1564500943088},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"90fa628f156d8045357ff11eaf32e61abacf10e8","modified":1564500943088},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"e0acf1db27b0cc16128a59c46db1db406b5c4c58","modified":1564500943088},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"f4a570908f6c89c6edfb1c74959e733eaadea4f2","modified":1564500943088},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"bf773ad48a0b9aa77681a89d7569eefc0f7b7b18","modified":1564500943088},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"2d9a9f38c493fdf7c0b833bb9184b6a1645c11b2","modified":1564500943103},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"46a50b91c98b639c9a2b9265c5a1e66a5c656881","modified":1564500943103},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"8148492dd49aa876d32bb7d5b728d3f5bf6f5074","modified":1564500943119},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"6f474ea75c42442da7bbcf2e9143ce98258efd8d","modified":1564500943057},{"_id":"themes/next/source/lib/needsharebutton/README.md","hash":"b9c3545046609fc6310458cf6c5d004ee2c69c4e","modified":1564500943103},{"_id":"themes/next/source/lib/needsharebutton/LICENSE","hash":"336611e76f0638d3d8aeca6b1b97138d2a07523f","modified":1564500943088},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1564500943103},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1564500943103},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"ef80f26e3ae6fc59ecdbc1294c50636de9280018","modified":1564500943103},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1564500943103},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1564500943103},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1564500943103},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1564500943103},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1564500943103},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1564500943103},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1564500943103},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1564500943103},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1564500943103},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"8aaa675f577d5501f5f22d5ccb07c2b76310b690","modified":1564500943103},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"f98253ddd8b345a6826b05139911be12c70bcc0c","modified":1564500943103},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1564500943103},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"63da5e80ebb61bb66a2794d5936315ca44231f0c","modified":1564500943119},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"92d92860418c4216aa59eb4cb4a556290a7ad9c3","modified":1564500943119},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"bf172816a9c57f9040e3d19c24e181a142daf92b","modified":1564500943119},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"dde584994ac13dc601836e86f4cf490e418d9723","modified":1564500943135},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1564500943103},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"f5e487b0d213ca0bd94aa30bc23b240d65081627","modified":1564500942869},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"a223919d2e1bf17ca4d6abb2c86f2efca9883dc1","modified":1564500942869},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"dbbfb50f6502f6b81dcc9fee7b31f1e812da3464","modified":1564500943119},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"b2f0d247b213e4cf8de47af6a304d98070cc7256","modified":1564500942869},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"a8c7f9ca7c605d039a1f3bf4e4d3183700a3dd62","modified":1564500942885},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"b25002a83cbd2ca0c4a5df87ad5bff26477c0457","modified":1564500942885},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"9e3d133ac5bcc6cb51702c83b2611a49811abad1","modified":1564500942885},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"ff947f3561b229bc528cb1837d4ca19612219411","modified":1564500942885},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"d4fbffd7fa8f2090eb32a871872665d90a885fac","modified":1564500942885},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"0a9cdd6958395fcdffc80ab60f0c6301b63664a5","modified":1564500942885},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"7b11eac3a0685fa1ab2ab6ecff60afc4f15f0d16","modified":1564500942885},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"71397a5823e8ec8aad3b68aace13150623b3e19d","modified":1564500942885},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"a10b7f19d7b5725527514622899df413a34a89db","modified":1564500942885},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"ccc443b22bd4f8c7ac4145664686c756395b90e0","modified":1564500942885},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"7d94845f96197d9d84a405fa5d4ede75fb81b225","modified":1564500942885},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"753d262911c27baf663fcaf199267133528656af","modified":1564500942885},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"d9e2d9282f9be6e04eae105964abb81e512bffed","modified":1564500942885},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"b1e13df83fb2b1d5d513b30b7aa6158b0837daab","modified":1564500942885},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"5a8027328f060f965b3014060bebec1d7cf149c1","modified":1564500942900},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"e6d10ee4fb70b3ae1cd37e9e36e000306734aa2e","modified":1564500942885},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"45f3f629c2aacc381095750e1c8649041a71a84b","modified":1564500942885},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"f9a1647a8f1866deeb94052d1f87a5df99cb1e70","modified":1564500942900},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"b83a51bbe0f1e2ded9819070840b0ea145f003a6","modified":1564500942900},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"8a399df90dadba5ad4e781445b58f4765aeb701e","modified":1564500942900},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"1600f340e0225361580c44890568dc07dbcf2c89","modified":1564500942900},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"493bd5999a1061b981922be92d8277a0f9152447","modified":1564500942900},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"4dcc3213c033994d342d02b800b6229295433d30","modified":1564500942900},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"4c501ea0b9c494181eb3c607c5526a5754e7fbd8","modified":1564500942900},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"7e65ff8fe586cd655b0e9d1ad2912663ff9bd36c","modified":1564500942900},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"9246162d4bc7e949ce1d12d135cbbaf5dc3024ec","modified":1564500942900},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"4050553d44ba1396174161c9a6bb0f89fa779eca","modified":1564500942900},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"34599633658f3b0ffb487728b7766e1c7b551f5a","modified":1564500942900},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"9b84ab576982b2c3bb0291da49143bc77fba3cc6","modified":1564500942885},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"af7f3e43cbdc4f88c13f101f0f341af96ace3383","modified":1564500942900},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"d8c98938719284fa06492c114d99a1904652a555","modified":1564500942916},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a9a3995b9615adfb8d6b127c78c6771627bee19a","modified":1564500942885},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a9a3995b9615adfb8d6b127c78c6771627bee19a","modified":1564500942885},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"fe95dd3d166634c466e19aa756e65ad6e8254d3e","modified":1564500942916},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"93479642fd076a1257fecc25fcf5d20ccdefe509","modified":1564500942916},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"8f86f694c0749a18ab3ad6f6df75466ca137a4bc","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"ff4489cd582f518bba6909a301ac1292a38b4e96","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"8b32928686c327151e13d3ab100157f9a03cd59f","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"237d185ac62ec9877e300947fa0109c44fb8db19","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"4f2801fc4cf3f31bf2069f41db8c6ce0e3da9e39","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"7ad4081466b397e2a6204141bb7768b7c01bd93c","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"6eb4bcc3056bd279d000607e8b4dad50d368ca69","modified":1564500942963},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"b1025c421406d2c24cc92a02ae28c1915b01e240","modified":1564500942978},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"d0bfd1bef988c76f7d7dd72d88af6f0908a8b0db","modified":1564500942978},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"60fa84aa7731760f05f52dd7d8f79b5f74ac478d","modified":1564500942978},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"25d5e45a355ee2093f3b8b8eeac125ebf3905026","modified":1564500942978},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"26666c1f472bf5f3fb9bc62081cca22b4de15ccb","modified":1564500942978},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"09c965022c13b84ed8a661fee8ac2a6d550495ae","modified":1564500942994},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"9c99034f8e00d47e978b3959f51eb4a9ded0fcc8","modified":1564500942994},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9b913b73d31d21f057f97115ffab93cfa578b884","modified":1564500942994},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"1da5c800d025345f212a3bf1be035060f4e5e6ed","modified":1564500942978},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"91ca75492cd51f2553f4d294ed2f48239fcd55eb","modified":1564500942978},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"24ee4b356ff55fc6e58f26a929fa07750002cf29","modified":1564500942978},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"3f40e8a9fe8e7bd5cfc4cf4cbbbcb9539462e973","modified":1564500942978},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a17e2b871a335f290afb392a08f94fd35f59c715","modified":1564500942978},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"ea9069645696f86c5df64208490876fe150c8cae","modified":1564500942978},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"bce344d3a665b4c55230d2a91eac2ad16d6f32fd","modified":1564500942994},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"12662536c7a07fff548abe94171f34b768dd610f","modified":1564500942978},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"416988dca389e6e2fdfa51fa7f4ee07eb53f82fb","modified":1564500942994},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"4642e30010af8b2b037f5b43146b10a934941958","modified":1564500942994},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"1f6e2ce674735269599acc6d77b3ea18d31967fc","modified":1564500942994},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"ad2dcedf393ed1f3f5afd2508d24969c916d02fc","modified":1564500942994},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"748dbfbf9c08e719ddc775958003c64b00d39dab","modified":1564500942994},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"86197902dfd3bededba10ba62b8f9f22e0420bde","modified":1564500942994},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"09c965022c13b84ed8a661fee8ac2a6d550495ae","modified":1564500942994},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"e695e58f714129ca292c2e54cd62c251aca7f7fe","modified":1564500942994},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"f1d0b5d7af32c423eaa8bb93ab6a0b45655645dc","modified":1564500943025},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"31127dcbf4c7b4ada53ffbf1638b5fe325b7cbc0","modified":1564500942994},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"5dbc0d0c897e46760e5dbee416530d485c747bba","modified":1564500942994},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"16b03db23a52623348f37c04544f2792032c1fb6","modified":1564500943041},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1564500943041},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1564500943057},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1564500943057},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1564500943057},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1564500943057},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1564500943057},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"ae6318aeb62ad4ce7a7e9a4cdacd93ffb004f0fb","modified":1564500943057},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"6d586bfcfb7ae48f1b12f76eec82d3ad31947501","modified":1564500943041},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"82f33ad0842aa9c154d029e0dada2497d4eb1d57","modified":1564500943057},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"1573904b82807abbb32c97a3632c6c6808eaac50","modified":1564500943072},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"3655f1fdf1e584c4d8e8d39026093ca306a5a341","modified":1564500943072},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"88af80502c44cd52ca81ffe7dc7276b7eccb06cf","modified":1564500943072},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"d71602cbca33b9ecdb7ab291b7f86a49530f3601","modified":1564500943057},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"1d6aeda0480d0e4cb6198edf7719d601d4ae2ccc","modified":1564500943057},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1564500943072},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"41ea797c68dbcff2f6fb3aba1d1043a22e7cc0f6","modified":1564500943119},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"a817b6c158cbc5bab3582713de9fe18a18a80552","modified":1564500943119},{"_id":"themes/next/source/lib/needsharebutton/.github/stale.yml","hash":"dbd5e6bf89b76ad1f2b081578b239c7ae32755af","modified":1564500943088},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"2530de0f3125a912756f6c0e9090cd012134a4c5","modified":1564500942900},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"218cc936ba3518a3591b2c9eda46bc701edf7710","modified":1564500942900},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"4ac683b2bc8531c84d98f51b86957be0e6f830f3","modified":1564500943041},{"_id":"themes/next/source/lib/jquery/index.js","hash":"17a740d68a1c330876c198b6a4d9319f379f3af2","modified":1564500943088},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"6c26cdb36687d4f0a11dabf5290a909c3506be5c","modified":1564500943041},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"4237c6e9d59da349639de20e559e87c2c0218cfd","modified":1564500943119},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1564500943088},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d63e0cacc53dd375fcc113465a4328c59ff5f2c1","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"9f73c4696f0907aa451a855444f88fc0698fa472","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"53cde051e0337f4bf42fb8d6d7a79fa3fa6d4ef2","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"1a0d059799a298fe17c49a44298d32cebde93785","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"1727702eac5d326b5c81a667944a245016668231","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"0656e753f182c9f47fef7304c847b7587a85ef0d","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"167986d0f649516671ddf7193eebba7b421cd115","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"50450d9fdc8a2b2be8cfca51e3e1a01ffd636c0b","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"b6f3a06a94a6ee5470c956663164d58eda818a64","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"7fb593f90d74a99c21840679933b9ef6fdc16a61","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"f9760ecf186954cee3ba4a149be334e9ba296b89","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"7fe4d4d656e86276c17cb4e48a560cb6a4def703","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"4e3838d7ac81d9ad133960f0f7ed58a44a015285","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"8cf318644acc8b4978537c263290363e21c7f5af","modified":1564500942932},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"62fbbd32cf5a99ae550c45c763a2c4813a138d01","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/post/my-post-copyright.styl","hash":"e954bf95842945b196bbb0de7b8098950a780129","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"caf263d1928496688c0e1419801eafd7e6919ce5","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"875cbe88d5c7f6248990e2beb97c9828920e7e24","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"a200c0a1c5a895ac9dc41e0641a5dfcd766be99b","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"a6c6eb8adba0a090ad1f4b9124e866887f20d10d","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"cd9e214e502697f2f2db84eb721bac57a49b0fce","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"d0d7a5c90d62b685520d2b47fea8ba6019ff5402","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"ca88ea6999a61fb905eb6e72eba5f92d4ee31e6e","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"b2495ae5e04dcca610aacadc47881d9e716cd440","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"5a982d8ef3b3623ea5f59e63728990f5623c1b57","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"27deb3d3a243d30022055dac7dad851024099a8b","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"01567edaea6978628aa5521a122a85434c418bfd","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"ccb34c52be8adba5996c6b94f9e723bd07d34c16","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"7968343e41f8b94b318c36289dff1196c3eb1791","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"439f112487afa53da823b53f569d6ebd19deaaca","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"39f04c4c7237a4e10acd3002331992b79945d241","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"761eba9811b050b25d548cc0854de4824b41eb08","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"8dd9a1c6f4f6baa00c2cf01837e7617120cf9660","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"11c22f0fb3f6beb13e5a425ec064a4ff974c13b7","modified":1564500942947},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"1153bb71edf253765145559674390e16dd67c633","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"61f8cea3c01acd600e90e1bc2a07def405503748","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"a1521d48bb06d8d703753f52a198baa197af7da2","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"c8fe49a4bc014c24dead05b782a7082411a4abc5","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"5ef6343835f484a2c0770bd1eb9cc443609e4c39","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"e71652d3216e289c8548b1ea2357822c1476a425","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"a3bdd71237afc112b2aa255f278cab6baeb25351","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"2fe76476432b31993338cb45cdb3b29a518b6379","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"2ad1a2a9bbf6742d1b0762c4c623b68113d1e0fe","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"f825da191816eef69ea8efb498a7f756d5ebb498","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"2ab1322fe52ab5aafd49e68f5bd890e8380ee927","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"b7076e58d647265ee0ad2b461fe8ce72c9373bc5","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"b80604868e4f5cf20fccafd7ee415c20c804f700","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"a6e7d698702c2e383dde3fde2abde27951679084","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"154a87a32d2fead480d5e909c37f6c476671c5e6","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"9a409b798decdefdaf7a23f0b11004a8c27e82f3","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"bba4f3bdb7517cd85376df3e1209b570c0548c69","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"874278147115601d2abf15987f5f7a84ada1ac6b","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"5dbeed535d63a50265d96b396a5440f9bb31e4ba","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"10599e16414a8b7a76c4e79e6617b5fe3d4d1adf","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"28825ae15fa20ae3942cdaa7bcc1f3523ce59acc","modified":1564500942978},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"15975ba7456b96916b1dbac448a1a0d2c38b8f3d","modified":1564500942978},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"717cc7f82be9cc151e23a7678601ff2fd3a7fa1d","modified":1564500942963},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"16087276945fa038f199692e3eabb1c52b8ea633","modified":1564500942978},{"_id":"source/_posts/华为软挑/huawei.jpg","hash":"48a7fba1a2a8aa453e6431f56f4fc68ad13657c8","modified":1564500942744},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"9c8196394a89dfa40b87bf0019e80144365a9c93","modified":1564500942978},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"1f09be9bb38411f0629b58c3b23873589a6dbcaa","modified":1564500942994},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"a07aa12cc36ac5c819670c2a3c17d07ed7a08986","modified":1564500942994},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"1f09be9bb38411f0629b58c3b23873589a6dbcaa","modified":1564500942994},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1564500943025},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1564500943025},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1564500943041},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1564500943025},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"ee948b4489aedeb548a77c9e45d8c7c5732fd62d","modified":1564500943057},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"51139a4c79573d372a347ef01a493222a1eaf10a","modified":1564500943057},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"d22b1629cb23a6181bebb70d0cf653ffe4b835c8","modified":1564500943057},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1564500943057},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1564500943072},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1564500943088},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1564500943025},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae","modified":1564500943057},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"6394c48092085788a8c0ef72670b0652006231a1","modified":1564500943057},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1564500943072},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1564500943088},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"90a1b22129efc172e2dfcceeeb76bff58bc3192f","modified":1564500943041},{"_id":"themes/next/source/lib/three/three.min.js","hash":"26273b1cb4914850a89529b48091dc584f2c57b8","modified":1564500943119},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1564500943088},{"_id":"public/baidu_verify_oo3AHvvCK7.html","hash":"c7a5d65b658f4c7be1dc2702a86138ee7b9ed6ff","modified":1565665042200},{"_id":"public/google1bfaee946527fc4a.html","hash":"8ba55190696064cc3e6089dd25bd3f26c5d017ed","modified":1565665042200},{"_id":"public/search.xml","hash":"f7d915cd455150e2814404f07e244e14278bb91c","modified":1568182911392},{"_id":"public/sitemap.xml","hash":"99fd2a43b29ec30fcfbc24ce0d76c9b37505ba6d","modified":1568182911391},{"_id":"public/atom.xml","hash":"e961454fb7f86c7c5eb62cce2b75ca1bf14b3ba6","modified":1568182911452},{"_id":"public/baidusitemap.xml","hash":"756171407bcc6f9d16f1e8429bea2e8705d077e8","modified":1568182911405},{"_id":"public/about/index.html","hash":"840a46932edaca527d051af3ce7edda347e10e6d","modified":1565665049311},{"_id":"public/2019/08/09/pandas-重复值处理/index.html","hash":"be64a25e4e0fe16dfcb674d0e958e10dcad49e19","modified":1568182911768},{"_id":"public/2019/08/09/pandas-缺失值处理/index.html","hash":"0aa2e6e9324c243de2ac3769ef2272a734d7b9a8","modified":1568182911769},{"_id":"public/2019/08/01/机器学习模型的偏差与方差/index.html","hash":"c8b46b0a789780d91f68ee35e4f6b7086555d527","modified":1568182911771},{"_id":"public/2019/08/06/pandas-时间-日期处理/index.html","hash":"a785ea5a00b741119c1c06a36e7e71f68c2ad394","modified":1568182911772},{"_id":"public/tags/index.html","hash":"8e5a04a706967568051a5b7c960c95bfcb5b1d37","modified":1565665049316},{"_id":"public/categories/index.html","hash":"8702114149570e5527a9cedd8875c614a0302510","modified":1565665049316},{"_id":"public/2019/07/30/XGBoost/index.html","hash":"f3c80a0423c3cc5d2aa2ebeba2dea9a3371be442","modified":1568182911772},{"_id":"public/2019/07/22/pandas-数据结构/index.html","hash":"03e0285c98db74844944cede567acbc8e9a27fef","modified":1565665049316},{"_id":"public/2019/04/27/逻辑回归/index.html","hash":"a5566906e5ed7e7e81e32fc592bc9975be2f06ff","modified":1565665049317},{"_id":"public/2019/04/20/决策树-1基本概念/index.html","hash":"d55e96110b2041ab11e2c7fb104aa45c6b173d69","modified":1565665049317},{"_id":"public/2019/06/25/集成学习-Adaboost/index.html","hash":"a9564851d85c06db1bf7ac523f6dd88e209ef5d4","modified":1565665049317},{"_id":"public/2019/04/14/虚拟机类加载机制/index.html","hash":"02544dd73d87441bd8b75aeef17d3f899a9c2266","modified":1565665049317},{"_id":"public/2019/01/25/Deep-Residual-Learning-for-Image-Recognition/index.html","hash":"cf4faf2c5ac0503520cb743c20787f4b6187ee20","modified":1565665049317},{"_id":"public/2019/07/20/评价指标-ROC与AUC/index.html","hash":"1dfc945dc65e1b7f3bebc66bb87c3d91fe1c4955","modified":1568182911772},{"_id":"public/2019/01/20/C-梳理笔记/index.html","hash":"8e783eb04b8a56845cec9d253fcba784590b4906","modified":1565665049318},{"_id":"public/2019/04/01/华为软挑/index.html","hash":"b91dda368ad646d5442f7125cce1af77427c2693","modified":1565665049318},{"_id":"public/2019/01/24/Network-in-Network/index.html","hash":"b628452febaa8b50729ac7b318823d69d4e24936","modified":1565665049318},{"_id":"public/2019/01/19/git使用/index.html","hash":"b89ec5ed1995e768f1e201ab1c65d9757ee38692","modified":1565665049318},{"_id":"public/2019/01/18/欢迎来我的小屋！/index.html","hash":"696f448a136b357fe9affaec1ce3bc0473b410da","modified":1565665049318},{"_id":"public/archives/index.html","hash":"3a32ce5513214792a2f7547a9cddf16b2df0817e","modified":1568182911772},{"_id":"public/archives/2019/index.html","hash":"3e6fa0c85d9791d72f783a6a083b9722bbd92f7e","modified":1568182911772},{"_id":"public/archives/2019/page/2/index.html","hash":"6b5af0ee1896deb7174adf3e49649a5712f6cf8d","modified":1565665049319},{"_id":"public/archives/2019/06/index.html","hash":"5171d23f72039bc113ebb78fbb6f276f4df62c3f","modified":1565665049319},{"_id":"public/archives/2019/01/index.html","hash":"a3f331cf996ef18de4bb90c1daeca5a3574ff835","modified":1565665049319},{"_id":"public/archives/page/2/index.html","hash":"4d1abc57d402b948160936a8c08ed5cc1bb36a25","modified":1565665049319},{"_id":"public/archives/2019/04/index.html","hash":"5d9326ed02a68f6f45d0acf51c645153de2dcbf2","modified":1565665049319},{"_id":"public/archives/2019/07/index.html","hash":"f1287aff4c7b64b9fd7dad1a0c5b263a97024b68","modified":1568182911772},{"_id":"public/archives/2019/08/index.html","hash":"448f5cc7ab8e410f665fcb7a0591eb7c455e14f6","modified":1568182911772},{"_id":"public/categories/计算机视觉论文阅读/index.html","hash":"9f4dbd6574a0307d91a1f2e6f627c9e6eb268a46","modified":1565665049320},{"_id":"public/categories/XGBoost/index.html","hash":"bba47399d185e15b638c91654596db6831994e3c","modified":1565665049320},{"_id":"public/categories/git/index.html","hash":"184d4f0fa91cc73de1738cb9c8f0fea510841707","modified":1565665049320},{"_id":"public/categories/pandas系列教程/index.html","hash":"f4320b0f03d3140d68423a5945f7e06765d089ab","modified":1568182911773},{"_id":"public/categories/机器学习方法/index.html","hash":"3f8c681488eb707bdbe4a1030bc754a31b401833","modified":1565665049320},{"_id":"public/categories/闲聊/index.html","hash":"af3b478f51365b31cad037656037bc3dc53d9f5a","modified":1565665049320},{"_id":"public/index.html","hash":"af1dab64e91e98ca44a7ceebb96eb71917b79800","modified":1568182911773},{"_id":"public/page/2/index.html","hash":"e26829aeb353d322491c4dde83288257d09d3057","modified":1565665049321},{"_id":"public/categories/深入理解Java-虚拟机/index.html","hash":"bd2413d23fd9726d1d9c1d361afc669e5c1927c0","modified":1565665049321},{"_id":"public/categories/C/index.html","hash":"7b6583159de638bb77d28ffead9a0284a1b3d424","modified":1565665049321},{"_id":"public/categories/竞赛/index.html","hash":"8aa52aa9c2ae640092830283732177d54e2ef68c","modified":1565665049321},{"_id":"public/tags/深度学习论文/index.html","hash":"0c69da21a0a3afe7b7e2acd39b76cf604fcab1fa","modified":1565665049321},{"_id":"public/tags/git/index.html","hash":"3f0adb8843f569201cf1d38d4981d095add57c0d","modified":1565665049322},{"_id":"public/tags/pandas/index.html","hash":"4862b9036f1851fae0122748bd829c46fced0dde","modified":1568182911774},{"_id":"public/tags/决策树/index.html","hash":"bb281c2bfe22c50ba44b6aa9ab6d5c8d9c57316a","modified":1565665049322},{"_id":"public/tags/XGBoost/index.html","hash":"623d83e7e54a0f909b799cb068893733698f1e41","modified":1565665049322},{"_id":"public/tags/ROC/index.html","hash":"3e58e8bbdedcfd1588e837b9eb1ba7a9a95534e0","modified":1565665049322},{"_id":"public/tags/闲聊/index.html","hash":"27bece3e3a41798cbbb48ff5fdc28a3100de2a65","modified":1565665049322},{"_id":"public/tags/Java类加载机制/index.html","hash":"260466efbcd2e1b20fbda95d4162130e5ab3ae28","modified":1565665049322},{"_id":"public/tags/方差与偏差/index.html","hash":"3d614a6ca64ef2f843ea9c86f310928af4177d64","modified":1565665049323},{"_id":"public/tags/集成学习/index.html","hash":"82c7d40dd72908d5916d9c1852adec7d826c4dbc","modified":1565665049323},{"_id":"public/tags/逻辑回归/index.html","hash":"8983791fba2eb44f6bd4ea77dc8331ce4619eceb","modified":1565665049323},{"_id":"public/tags/华为软挑初赛/index.html","hash":"43f8ba2c9acaa7f852d8dab153756bb3a534e0be","modified":1565665049323},{"_id":"public/tags/C/index.html","hash":"e43a0731d86238bafa80c500db36b5b87e79d20d","modified":1565665049323},{"_id":"public/2019/08/13/pandas-分层和多级索引/index.html","hash":"f6543201ec4470d5e84024115d5a251c1da50500","modified":1568182911771},{"_id":"public/2019/07/25/pandas-索引和选择数据/index.html","hash":"9dc25c28e639d48c6b904a58e24a5a7f43d6b675","modified":1565665049339},{"_id":"public/tags/pandas-MultiIndex/index.html","hash":"7be4bc1997743b4c64bf7445472959d55e5288b5","modified":1568182911774},{"_id":"public/CNAME","hash":"3d80c81638dc40478d251e1deab3820104ce8789","modified":1565665049339},{"_id":"public/images/cc-by-nc-nd.svg","hash":"bc3588c9b2d7c68830524783120ff6cf957cf668","modified":1565665049339},{"_id":"public/images/algolia_logo.svg","hash":"45eeea0b5fba833e21e38ea10ed5ab385ceb4f01","modified":1565665049339},{"_id":"public/images/cc-by-nc-sa.svg","hash":"6f55543d1fb9cbc436c101d24f802dec7b41efc3","modified":1565665049340},{"_id":"public/images/cc-by-nc.svg","hash":"6f076713fb9bf934aa2c1046bdf2cf2e37bc1eab","modified":1565665049343},{"_id":"public/images/avatar.jpg","hash":"2f021e5ba8521a15bbd853c71bde6d3ef27a1518","modified":1565665049343},{"_id":"public/images/cc-by-sa.svg","hash":"70c1535f43e54e5ff35ca81419e77e4c0c301398","modified":1565665049343},{"_id":"public/images/cc-by-nd.svg","hash":"42cd73da328077ccc92f859bb8f3cf621b3484f8","modified":1565665049343},{"_id":"public/images/cc-zero.svg","hash":"9bfb52b2f63527a7049247bf00d44e6dc1170e7d","modified":1565665049343},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1565665049343},{"_id":"public/images/cc-by.svg","hash":"e92a33c32d1dac8ed94849b2b4e6456e887efe70","modified":1565665049344},{"_id":"public/robots.txt","hash":"a05b35a4ee0eea6e94f0d1721fd090cbf097b20a","modified":1565665049344},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1565665049344},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1565665049344},{"_id":"public/images/quote-r.svg","hash":"2a2a250b32a87c69dcc1b1976c74b747bedbfb41","modified":1565665049344},{"_id":"public/images/logo.svg","hash":"169f56fd82941591dad3abd734a50ec7259be950","modified":1565665049344},{"_id":"public/images/quote-l.svg","hash":"cd108d6f44351cadf8e6742565217f88818a0458","modified":1565665049344},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1565665049344},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1565665049344},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1565665049345},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"ee33b2798b1e714b904d663436c6b3521011d1fa","modified":1565665049345},{"_id":"public/lib/fastclick/LICENSE","hash":"6f474ea75c42442da7bbcf2e9143ce98258efd8d","modified":1565665049345},{"_id":"public/lib/needsharebutton/LICENSE","hash":"336611e76f0638d3d8aeca6b1b97138d2a07523f","modified":1565665049345},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1565665049345},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1565665049345},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1565665049345},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1565665049345},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1565665049345},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"1573904b82807abbb32c97a3632c6c6808eaac50","modified":1565665049346},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1565665049346},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1565665049346},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1565665049346},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1565665049346},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1565665049346},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1565665049346},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1565665049347},{"_id":"public/2019/04/20/决策树-1基本概念/tree.png","hash":"b657e72f62236d975809681103d06325f2ae4a03","modified":1565665049347},{"_id":"public/2019/01/25/Deep-Residual-Learning-for-Image-Recognition/resnet1.png","hash":"56e71e5ae901cc533f289e2f88f425e182924701","modified":1565665050510},{"_id":"public/2019/08/01/机器学习模型的偏差与方差/biasvariance.png","hash":"34d619dd4750bd282e700da634d2b9ae6eb4a17b","modified":1565665050514},{"_id":"public/2019/04/27/逻辑回归/cost.png","hash":"fef1f81317aea942b7616a1afc70e8a01b17b5e6","modified":1565665050518},{"_id":"public/2019/01/24/Network-in-Network/nerworkInNetwork1.png","hash":"139cf459a66b7a31924cf8951c3fd01660319b19","modified":1565665050518},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1565665050518},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1565665050518},{"_id":"public/js/love.js","hash":"26d97a907cb239fda30ab966fb1ec318bf3e24bd","modified":1565665050527},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1565665050527},{"_id":"public/js/src/love.js","hash":"26d97a907cb239fda30ab966fb1ec318bf3e24bd","modified":1565665050529},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1565665050529},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1565665050529},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1565665050529},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1565665050529},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1565665050529},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1565665050529},{"_id":"public/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1565665050530},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1565665050530},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1565665050530},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1565665050530},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1565665050530},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1565665050530},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1565665050530},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1565665050530},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1565665050530},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1565665050530},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1565665050531},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1565665050531},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1565665050531},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1565665050531},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1565665050531},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1565665050531},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1565665050531},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1565665050531},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1565665050531},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1565665050531},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1565665050532},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1565665050532},{"_id":"public/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1565665050532},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1565665050532},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1565665050532},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1565665050532},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1565665050532},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1565665050532},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1565665050532},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1565665050533},{"_id":"public/lib/jquery_lazyload/README.html","hash":"a08fccd381c8fdb70ba8974b208254c5ba23a95f","modified":1565665050533},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"06811ca2f722dead021493457f27cdc264ef928d","modified":1565665050533},{"_id":"public/lib/fastclick/README.html","hash":"c07b353b4efa132290ec4479102a55d80ac6d300","modified":1565665050533},{"_id":"public/lib/needsharebutton/README.html","hash":"a02a3905ce9ab80b2c5e68d99ad98a9f3ce315cc","modified":1565665050533},{"_id":"public/css/main.css","hash":"b39e96272f8b5495e9efc0fef5d0643b37bc7deb","modified":1565665050533},{"_id":"public/2019/01/25/Deep-Residual-Learning-for-Image-Recognition/resnet2.png","hash":"7e08d7c3ddcc720fe424c1b1ed5c365164c89d35","modified":1565665050533},{"_id":"public/2019/04/27/逻辑回归/sigmoid.png","hash":"0c2ba4e2c5f9e3914a2584175f809af150dbe8db","modified":1565665050533},{"_id":"public/2019/01/24/Network-in-Network/nerworkInNetwork2.png","hash":"5c49d49b5b4cb70e62446a97df515f3623ebba98","modified":1565665050533},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1565665050533},{"_id":"public/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1565665050548},{"_id":"public/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1565665050548},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1565665050549},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1565665050550},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1565665050550},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1565665050550},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1565665050550},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1565665050550},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1565665050551},{"_id":"public/lib/needsharebutton/needsharebutton.js","hash":"75dee2bb4796ca66693831d769d9a105eed8c290","modified":1565665050559},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1565665050559},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1565665050559},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1565665050564},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1565665050564},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1565665050572},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1565665050572},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1565665050574},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1565665050574},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1565665050574},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1565665050574},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1565665050574},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1565665050579},{"_id":"public/lib/needsharebutton/needsharebutton.css","hash":"f151bb5ba4a2cd334061bac27a1a155969b62cdb","modified":1565665050587},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1565665050587},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1565665050587},{"_id":"public/2019/04/01/华为软挑/huawei.jpg","hash":"48a7fba1a2a8aa453e6431f56f4fc68ad13657c8","modified":1565665050589},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"b5483b11f8ba213e733b5b8af9927a04fec996f6","modified":1565665050592},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1565665050594},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1565665050594},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1565665050598},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1565665050613},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1565665050634},{"_id":"source/_posts/pandas-2索引和选择数据.md","hash":"c6fa4c0dd171e9fa543d1d20ad8d20fe09cae19e","modified":1568182721751},{"_id":"source/_posts/pandas-1数据结构.md","hash":"67f964cb60bf661d2b8c2dacdf31b20be31adb98","modified":1568182763669},{"_id":"public/2019/07/25/pandas-2索引和选择数据/index.html","hash":"e121da691de57994eccb30a8662cdfe9e1748392","modified":1568182911777},{"_id":"public/2019/07/22/pandas-1数据结构/index.html","hash":"099e06986b3f03b5b94bd34518ad2fcbc3579aa1","modified":1568182911777}],"Category":[{"name":"计算机视觉论文阅读","_id":"cjz98jgyl0006y0plecowj4r7"},{"name":"git","_id":"cjz98jgz4000hy0pl639vgtf1"},{"name":"pandas系列教程","_id":"cjz98jgz9000oy0plycefi2ci"},{"name":"XGBoost","_id":"cjz98jgzm0017y0pljw2zoxwq"},{"name":"机器学习方法","_id":"cjz98jgzs001ky0pl08ae2i9a"},{"name":"闲聊","_id":"cjz98jgzv001sy0plyts3n8hh"},{"name":"深入理解Java 虚拟机","_id":"cjz98jgzy0024y0plsnfpzkkj"},{"name":"竞赛","_id":"cjz98jha3002dy0plbe6uwv0e"},{"name":"C++","_id":"cjz98jhcc002ly0plly183n2m"}],"Data":[],"Page":[{"layout":"false","_content":"google-site-verification: google1bfaee946527fc4a.html","source":"google1bfaee946527fc4a.html","raw":"layout: false\n---\ngoogle-site-verification: google1bfaee946527fc4a.html","date":"2019-07-30T15:35:42.744Z","updated":"2019-07-30T15:35:42.744Z","path":"google1bfaee946527fc4a.html","title":"","comments":1,"_id":"cjz98jgrs0000y0plzg4l4ghu","content":"google-site-verification: google1bfaee946527fc4a.html","site":{"data":{}},"excerpt":"","more":"google-site-verification: google1bfaee946527fc4a.html"},{"layout":"false","_content":"oo3AHvvCK7","source":"baidu_verify_oo3AHvvCK7.html","raw":"layout: false\n---\noo3AHvvCK7","date":"2019-07-30T15:35:42.744Z","updated":"2019-07-30T15:35:42.744Z","path":"baidu_verify_oo3AHvvCK7.html","title":"","comments":1,"_id":"cjz98jgrv0001y0plte4klevs","content":"oo3AHvvCK7","site":{"data":{}},"excerpt":"","more":"oo3AHvvCK7"},{"title":"about","date":"2019-01-24T05:42:12.000Z","_content":"\n关于我。。","source":"about/index.md","raw":"---\ntitle: about\ndate: 2019-01-24 13:42:12\n---\n\n关于我。。","updated":"2019-07-30T15:35:42.744Z","path":"about/index.html","comments":1,"layout":"page","_id":"cjz98jgyf0003y0plgf1uxqxi","content":"<p>关于我。。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>关于我。。</p>\n"},{"title":"tags","date":"2019-01-18T02:13:35.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2019-01-18 10:13:35\ntype: \"tags\" #新添加的内容\n---\n","updated":"2019-07-30T15:35:42.744Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjz98jgyi0005y0pl0eaoay03","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"文章分类","date":"2019-01-18T02:11:26.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: 文章分类\ndate: 2019-01-18 10:11:26\ntype: \"categories\"\n---\n","updated":"2019-07-30T15:35:42.744Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cjz98jgyq0009y0pldzsqerrm","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Network in Network","date":"2019-01-24T07:08:27.000Z","copyright":true,"top":null,"_content":"`2014年` 论文地址：  [https://arxiv.org/abs/1312.4400](https://arxiv.org/abs/1312.4400 \"论文地址\")\n\n## 论文核心\n\nNIN特点: \n\n- 微型网络: \n\t- 增强模型在感受野（receptive field）内对局部区域的辨别能力;  \n\n\n- GAP全局平均池化: \n\t- 强化了特征图与分类的对应关系;\n\t- GAP本身是结构化的正则化器，能避免整体结构的过拟合；\n\n\t\n\n\n> 　　卷积层使用线性滤波器（卷积核）来扫描输入，后面接一个非线性激活函数。而卷积核是广义线性模型（generalized linear model ）GLM，抽象程度低（该特征对同一概念的变体是不变的）,用更有效的 `非线性函数逼近器` 代替 `GLM` 可以增强局部模型的抽象能力。当样本的隐含概念（latent concept）线性可分时，GLM可以达到很好的抽象程度，例如：这些概念的变体都在GLM分割平面的同一边，而<font color=red>传统的CNN就默认了这个假设——认为隐含概念（latent concept）是线性可分的</font>。然而，同一概念的数据通常是非线性流形的（nonlinear manifold），捕捉这些概念的表达通常都是输入的高维非线性函数。在NIN中，GLM用“微型网络”结构替代，该结构是一个`非线性函数逼近器`。  \n> \n> 　　本文作者选择多层感知器实例化微型网络，该感知器是一个通用函数逼近器，也是一个通过反向传播训练的神经网络。\n\n![logo](Network-in-Network/nerworkInNetwork1.png)\n该图是 单独的 `mlpconv 层`。\n这里有没有尝试过其他微型网络结构？？？？（可创新吗）\n- \n## NIN 网络结构\n![logo](Network-in-Network/nerworkInNetwork2.png)\n\n　　NIN 的整体结构是一系列 `mlpconve层` 的堆叠，最上层接一个 `GAP层` 和 `分类层`。 `mlpconv层` 间的子层可以被相加，像CNN和maxout网络一样。上图展示了一个包含三个mlpconv层的NIN。每个mlpconv层，包含一个三层的感知器，NIN和微型网络的层数都是灵活的，可以根据具体任务微调。\n\n　　这里没有采用传统CNN的 `全连接层` 进行分类，而是直接通过 `全局平均池化层（GAP）`输出最后一个 `mlpconv层特征图`的空间平均值作为类别的置信度值，然后将得到的向量输入 `softmax层`。","source":"_posts/Network-in-Network.md","raw":"---\ntitle: Network in Network\ndate: 2019-01-24 15:08:27\ncategories: \n- 计算机视觉论文阅读\ntags: 深度学习论文\ncopyright: true\ntop:\n---\n`2014年` 论文地址：  [https://arxiv.org/abs/1312.4400](https://arxiv.org/abs/1312.4400 \"论文地址\")\n\n## 论文核心\n\nNIN特点: \n\n- 微型网络: \n\t- 增强模型在感受野（receptive field）内对局部区域的辨别能力;  \n\n\n- GAP全局平均池化: \n\t- 强化了特征图与分类的对应关系;\n\t- GAP本身是结构化的正则化器，能避免整体结构的过拟合；\n\n\t\n\n\n> 　　卷积层使用线性滤波器（卷积核）来扫描输入，后面接一个非线性激活函数。而卷积核是广义线性模型（generalized linear model ）GLM，抽象程度低（该特征对同一概念的变体是不变的）,用更有效的 `非线性函数逼近器` 代替 `GLM` 可以增强局部模型的抽象能力。当样本的隐含概念（latent concept）线性可分时，GLM可以达到很好的抽象程度，例如：这些概念的变体都在GLM分割平面的同一边，而<font color=red>传统的CNN就默认了这个假设——认为隐含概念（latent concept）是线性可分的</font>。然而，同一概念的数据通常是非线性流形的（nonlinear manifold），捕捉这些概念的表达通常都是输入的高维非线性函数。在NIN中，GLM用“微型网络”结构替代，该结构是一个`非线性函数逼近器`。  \n> \n> 　　本文作者选择多层感知器实例化微型网络，该感知器是一个通用函数逼近器，也是一个通过反向传播训练的神经网络。\n\n![logo](Network-in-Network/nerworkInNetwork1.png)\n该图是 单独的 `mlpconv 层`。\n这里有没有尝试过其他微型网络结构？？？？（可创新吗）\n- \n## NIN 网络结构\n![logo](Network-in-Network/nerworkInNetwork2.png)\n\n　　NIN 的整体结构是一系列 `mlpconve层` 的堆叠，最上层接一个 `GAP层` 和 `分类层`。 `mlpconv层` 间的子层可以被相加，像CNN和maxout网络一样。上图展示了一个包含三个mlpconv层的NIN。每个mlpconv层，包含一个三层的感知器，NIN和微型网络的层数都是灵活的，可以根据具体任务微调。\n\n　　这里没有采用传统CNN的 `全连接层` 进行分类，而是直接通过 `全局平均池化层（GAP）`输出最后一个 `mlpconv层特征图`的空间平均值作为类别的置信度值，然后将得到的向量输入 `softmax层`。","slug":"Network-in-Network","published":1,"updated":"2019-07-30T15:35:42.728Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz98jgy70002y0pll2wunuym","content":"<p><code>2014年</code> 论文地址：  <a href=\"https://arxiv.org/abs/1312.4400\" title=\"论文地址\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/abs/1312.4400</a></p>\n<h2 id=\"论文核心\"><a href=\"#论文核心\" class=\"headerlink\" title=\"论文核心\"></a>论文核心</h2><p>NIN特点: </p>\n<ul>\n<li>微型网络: <ul>\n<li>增强模型在感受野（receptive field）内对局部区域的辨别能力;  </li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>GAP全局平均池化: <ul>\n<li>强化了特征图与分类的对应关系;</li>\n<li>GAP本身是结构化的正则化器，能避免整体结构的过拟合；</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>　　卷积层使用线性滤波器（卷积核）来扫描输入，后面接一个非线性激活函数。而卷积核是广义线性模型（generalized linear model ）GLM，抽象程度低（该特征对同一概念的变体是不变的）,用更有效的 <code>非线性函数逼近器</code> 代替 <code>GLM</code> 可以增强局部模型的抽象能力。当样本的隐含概念（latent concept）线性可分时，GLM可以达到很好的抽象程度，例如：这些概念的变体都在GLM分割平面的同一边，而<font color=\"red\">传统的CNN就默认了这个假设——认为隐含概念（latent concept）是线性可分的</font>。然而，同一概念的数据通常是非线性流形的（nonlinear manifold），捕捉这些概念的表达通常都是输入的高维非线性函数。在NIN中，GLM用“微型网络”结构替代，该结构是一个<code>非线性函数逼近器</code>。  </p>\n<p>　　本文作者选择多层感知器实例化微型网络，该感知器是一个通用函数逼近器，也是一个通过反向传播训练的神经网络。</p>\n</blockquote>\n<p><img src=\"/2019/01/24/Network-in-Network/nerworkInNetwork1.png\" alt=\"logo\"><br>该图是 单独的 <code>mlpconv 层</code>。<br>这里有没有尝试过其他微型网络结构？？？？（可创新吗）</p>\n<ul>\n<li><h2 id=\"NIN-网络结构\"><a href=\"#NIN-网络结构\" class=\"headerlink\" title=\"NIN 网络结构\"></a>NIN 网络结构</h2><img src=\"/2019/01/24/Network-in-Network/nerworkInNetwork2.png\" alt=\"logo\"></li>\n</ul>\n<p>　　NIN 的整体结构是一系列 <code>mlpconve层</code> 的堆叠，最上层接一个 <code>GAP层</code> 和 <code>分类层</code>。 <code>mlpconv层</code> 间的子层可以被相加，像CNN和maxout网络一样。上图展示了一个包含三个mlpconv层的NIN。每个mlpconv层，包含一个三层的感知器，NIN和微型网络的层数都是灵活的，可以根据具体任务微调。</p>\n<p>　　这里没有采用传统CNN的 <code>全连接层</code> 进行分类，而是直接通过 <code>全局平均池化层（GAP）</code>输出最后一个 <code>mlpconv层特征图</code>的空间平均值作为类别的置信度值，然后将得到的向量输入 <code>softmax层</code>。</p>\n","site":{"data":{}},"excerpt":"","more":"<p><code>2014年</code> 论文地址：  <a href=\"https://arxiv.org/abs/1312.4400\" title=\"论文地址\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/abs/1312.4400</a></p>\n<h2 id=\"论文核心\"><a href=\"#论文核心\" class=\"headerlink\" title=\"论文核心\"></a>论文核心</h2><p>NIN特点: </p>\n<ul>\n<li>微型网络: <ul>\n<li>增强模型在感受野（receptive field）内对局部区域的辨别能力;  </li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>GAP全局平均池化: <ul>\n<li>强化了特征图与分类的对应关系;</li>\n<li>GAP本身是结构化的正则化器，能避免整体结构的过拟合；</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>　　卷积层使用线性滤波器（卷积核）来扫描输入，后面接一个非线性激活函数。而卷积核是广义线性模型（generalized linear model ）GLM，抽象程度低（该特征对同一概念的变体是不变的）,用更有效的 <code>非线性函数逼近器</code> 代替 <code>GLM</code> 可以增强局部模型的抽象能力。当样本的隐含概念（latent concept）线性可分时，GLM可以达到很好的抽象程度，例如：这些概念的变体都在GLM分割平面的同一边，而<font color=\"red\">传统的CNN就默认了这个假设——认为隐含概念（latent concept）是线性可分的</font>。然而，同一概念的数据通常是非线性流形的（nonlinear manifold），捕捉这些概念的表达通常都是输入的高维非线性函数。在NIN中，GLM用“微型网络”结构替代，该结构是一个<code>非线性函数逼近器</code>。  </p>\n<p>　　本文作者选择多层感知器实例化微型网络，该感知器是一个通用函数逼近器，也是一个通过反向传播训练的神经网络。</p>\n</blockquote>\n<p><img src=\"/2019/01/24/Network-in-Network/nerworkInNetwork1.png\" alt=\"logo\"><br>该图是 单独的 <code>mlpconv 层</code>。<br>这里有没有尝试过其他微型网络结构？？？？（可创新吗）</p>\n<ul>\n<li><h2 id=\"NIN-网络结构\"><a href=\"#NIN-网络结构\" class=\"headerlink\" title=\"NIN 网络结构\"></a>NIN 网络结构</h2><img src=\"/2019/01/24/Network-in-Network/nerworkInNetwork2.png\" alt=\"logo\"></li>\n</ul>\n<p>　　NIN 的整体结构是一系列 <code>mlpconve层</code> 的堆叠，最上层接一个 <code>GAP层</code> 和 <code>分类层</code>。 <code>mlpconv层</code> 间的子层可以被相加，像CNN和maxout网络一样。上图展示了一个包含三个mlpconv层的NIN。每个mlpconv层，包含一个三层的感知器，NIN和微型网络的层数都是灵活的，可以根据具体任务微调。</p>\n<p>　　这里没有采用传统CNN的 <code>全连接层</code> 进行分类，而是直接通过 <code>全局平均池化层（GAP）</code>输出最后一个 <code>mlpconv层特征图</code>的空间平均值作为类别的置信度值，然后将得到的向量输入 <code>softmax层</code>。</p>\n"},{"title":"Deep Residual Learning for Image Recognition","date":"2019-01-25T14:19:29.000Z","copyright":true,"top":null,"_content":"`2015年` 论文地址：  [https://arxiv.org/pdf/1512.03385.pdf](https://arxiv.org/pdf/1512.03385.pdf\"论文地址\")\n\n## 通常情况下\n\n1. 神经网络层越深，特征的抽象程度越高，模型的表达能力越强，语义信息越丰富；\n2. 同时，网络越深，`退化问题` 越难解决;\n\n## 退化问题是网络加深的障碍\n　　简单的增加深度，会导致 `梯度弥散` 或者 `梯度爆炸` ,可以通过标准初始化和中间层正则化（batchNorm）解决；但是随着继续增加深度，训练集准确率饱和，甚至下降（` 退化问题 `，不属于过拟合）。\n\n![logo](Deep-Residual-Learning-for-Image-Recognition/resnet1.png)\n\n　　神经网络就像一个｀Function Set｀，网络是输入 x 到输出 out 的映射关系 F，`out = F(x)` ，所以网络层越深，这个 `Set` 包含的函数越复杂，那能够拟合的情况就更多（意思是解决的问题就更多），上图是作者在`CIFAR-10` 数据集上的对比实验，56层网络是在20层网络上的重复叠加（最差也应该是前22层的恒等映射），但是较深网络训练集的误差却比浅层网络的误差更大。这不是过拟合了，过深网络出现了 `退化问题`。\n\n## 本文效果（很大程度上解决了退化问题）：\n\n1. 作者在ImageNet上实验了一个152层的残差网络，比VGG深8倍，取得了3.57%的错误率。\n2. 作者通过一系列实验证明了表示的深度（即网络的深度）对很多视觉识别任务都至关重要。仅仅由于使用了非常深的网络，作者就在COCO目标检测数据集上获得了28%的相对提升。\n\n## 本文怎么解决退化问题？\n\n### Resnet 结构分析\n\n#### ResNet 短连接块\n![logo](Deep-Residual-Learning-for-Image-Recognition/resnet2.png)\n作者在《Identity Mapping in Deep Residual Networks 》一文中，推导了为什么短连接更容易训练，也提出了新的短连接块结构。\n#### 为什么 ResNet build block 更容易训练？ \n##### 前向传播中帮助网络中一些层更容易实现恒等映射：\n\n　　***出现了第一幅图的退化问题，这里假设深层网络的后边层都变成了<font color=red >恒等映射 </font>，那网络就退化成了浅层网络***（因为网络很深，所以其中肯定包括了多余的层，这些层会形成<font color=red >恒等映射 </font>关系），原来的直接多个层堆叠的非线性层去直接学习<font color=red> 恒等映射 </font>优化起来复杂，而加了上图的 `短连接`块之后，学习<font color=red> 恒等映射 </font>变容易了。\n##### 反向传播中\n>　　因为网络中存在`恒等映射的短连接通道`，假设不加residual模块的输出为h(x)。x=10,h(x)=11,h(x)简化为线性运算Wh​, Wh明显为1.1，加了redidual模块后，F(x)=1, H(x)=F(x)+x=11，F也简化为线性运算,对应的WF为0.1。当标签中的真实值为12，反向传播的损失为1，而对于F中的参数和h中参数回传的损失实际上是一样大的而且梯度都是x的值，但是对于F的参数就从0.1到1.1扩大了十倍多，而h的参数是从1.1到2.1扩大不到2倍，因此redidual模块会明显减小模块中参数的值从而让网络中的参数对反向传导的损失值有更敏感的响应能力，虽然根本上没有解决回传的损失小得问题，但是却让参数减小，相对而言增加了回传损失的效果，也产生了一定的正则化作用。 \n[https://blog.csdn.net/weixin_43624538/article/details/85049699?from=timeline&isappinstalled=0](https://blog.csdn.net/weixin_43624538/article/details/85049699?from=timeline&isappinstalled=0\"该部分参考这里\")\n\n\n","source":"_posts/Deep-Residual-Learning-for-Image-Recognition.md","raw":"---\ntitle: Deep Residual Learning for Image Recognition\ndate: 2019-01-25 22:19:29\ncategories: 计算机视觉论文阅读\ntags: 深度学习论文\ncopyright: true\ntop:\n---\n`2015年` 论文地址：  [https://arxiv.org/pdf/1512.03385.pdf](https://arxiv.org/pdf/1512.03385.pdf\"论文地址\")\n\n## 通常情况下\n\n1. 神经网络层越深，特征的抽象程度越高，模型的表达能力越强，语义信息越丰富；\n2. 同时，网络越深，`退化问题` 越难解决;\n\n## 退化问题是网络加深的障碍\n　　简单的增加深度，会导致 `梯度弥散` 或者 `梯度爆炸` ,可以通过标准初始化和中间层正则化（batchNorm）解决；但是随着继续增加深度，训练集准确率饱和，甚至下降（` 退化问题 `，不属于过拟合）。\n\n![logo](Deep-Residual-Learning-for-Image-Recognition/resnet1.png)\n\n　　神经网络就像一个｀Function Set｀，网络是输入 x 到输出 out 的映射关系 F，`out = F(x)` ，所以网络层越深，这个 `Set` 包含的函数越复杂，那能够拟合的情况就更多（意思是解决的问题就更多），上图是作者在`CIFAR-10` 数据集上的对比实验，56层网络是在20层网络上的重复叠加（最差也应该是前22层的恒等映射），但是较深网络训练集的误差却比浅层网络的误差更大。这不是过拟合了，过深网络出现了 `退化问题`。\n\n## 本文效果（很大程度上解决了退化问题）：\n\n1. 作者在ImageNet上实验了一个152层的残差网络，比VGG深8倍，取得了3.57%的错误率。\n2. 作者通过一系列实验证明了表示的深度（即网络的深度）对很多视觉识别任务都至关重要。仅仅由于使用了非常深的网络，作者就在COCO目标检测数据集上获得了28%的相对提升。\n\n## 本文怎么解决退化问题？\n\n### Resnet 结构分析\n\n#### ResNet 短连接块\n![logo](Deep-Residual-Learning-for-Image-Recognition/resnet2.png)\n作者在《Identity Mapping in Deep Residual Networks 》一文中，推导了为什么短连接更容易训练，也提出了新的短连接块结构。\n#### 为什么 ResNet build block 更容易训练？ \n##### 前向传播中帮助网络中一些层更容易实现恒等映射：\n\n　　***出现了第一幅图的退化问题，这里假设深层网络的后边层都变成了<font color=red >恒等映射 </font>，那网络就退化成了浅层网络***（因为网络很深，所以其中肯定包括了多余的层，这些层会形成<font color=red >恒等映射 </font>关系），原来的直接多个层堆叠的非线性层去直接学习<font color=red> 恒等映射 </font>优化起来复杂，而加了上图的 `短连接`块之后，学习<font color=red> 恒等映射 </font>变容易了。\n##### 反向传播中\n>　　因为网络中存在`恒等映射的短连接通道`，假设不加residual模块的输出为h(x)。x=10,h(x)=11,h(x)简化为线性运算Wh​, Wh明显为1.1，加了redidual模块后，F(x)=1, H(x)=F(x)+x=11，F也简化为线性运算,对应的WF为0.1。当标签中的真实值为12，反向传播的损失为1，而对于F中的参数和h中参数回传的损失实际上是一样大的而且梯度都是x的值，但是对于F的参数就从0.1到1.1扩大了十倍多，而h的参数是从1.1到2.1扩大不到2倍，因此redidual模块会明显减小模块中参数的值从而让网络中的参数对反向传导的损失值有更敏感的响应能力，虽然根本上没有解决回传的损失小得问题，但是却让参数减小，相对而言增加了回传损失的效果，也产生了一定的正则化作用。 \n[https://blog.csdn.net/weixin_43624538/article/details/85049699?from=timeline&isappinstalled=0](https://blog.csdn.net/weixin_43624538/article/details/85049699?from=timeline&isappinstalled=0\"该部分参考这里\")\n\n\n","slug":"Deep-Residual-Learning-for-Image-Recognition","published":1,"updated":"2019-07-30T15:35:42.728Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz98jgyg0004y0plwd1hr2c5","content":"<p><code>2015年</code> 论文地址：  <a href=\"https://arxiv.org/pdf/1512.03385.pdf&quot;论文地址&quot;\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/pdf/1512.03385.pdf</a></p>\n<h2 id=\"通常情况下\"><a href=\"#通常情况下\" class=\"headerlink\" title=\"通常情况下\"></a>通常情况下</h2><ol>\n<li>神经网络层越深，特征的抽象程度越高，模型的表达能力越强，语义信息越丰富；</li>\n<li>同时，网络越深，<code>退化问题</code> 越难解决;</li>\n</ol>\n<h2 id=\"退化问题是网络加深的障碍\"><a href=\"#退化问题是网络加深的障碍\" class=\"headerlink\" title=\"退化问题是网络加深的障碍\"></a>退化问题是网络加深的障碍</h2><p>　　简单的增加深度，会导致 <code>梯度弥散</code> 或者 <code>梯度爆炸</code> ,可以通过标准初始化和中间层正则化（batchNorm）解决；但是随着继续增加深度，训练集准确率饱和，甚至下降（<code>退化问题</code>，不属于过拟合）。</p>\n<p><img src=\"/2019/01/25/Deep-Residual-Learning-for-Image-Recognition/resnet1.png\" alt=\"logo\"></p>\n<p>　　神经网络就像一个｀Function Set｀，网络是输入 x 到输出 out 的映射关系 F，<code>out = F(x)</code> ，所以网络层越深，这个 <code>Set</code> 包含的函数越复杂，那能够拟合的情况就更多（意思是解决的问题就更多），上图是作者在<code>CIFAR-10</code> 数据集上的对比实验，56层网络是在20层网络上的重复叠加（最差也应该是前22层的恒等映射），但是较深网络训练集的误差却比浅层网络的误差更大。这不是过拟合了，过深网络出现了 <code>退化问题</code>。</p>\n<h2 id=\"本文效果（很大程度上解决了退化问题）：\"><a href=\"#本文效果（很大程度上解决了退化问题）：\" class=\"headerlink\" title=\"本文效果（很大程度上解决了退化问题）：\"></a>本文效果（很大程度上解决了退化问题）：</h2><ol>\n<li>作者在ImageNet上实验了一个152层的残差网络，比VGG深8倍，取得了3.57%的错误率。</li>\n<li>作者通过一系列实验证明了表示的深度（即网络的深度）对很多视觉识别任务都至关重要。仅仅由于使用了非常深的网络，作者就在COCO目标检测数据集上获得了28%的相对提升。</li>\n</ol>\n<h2 id=\"本文怎么解决退化问题？\"><a href=\"#本文怎么解决退化问题？\" class=\"headerlink\" title=\"本文怎么解决退化问题？\"></a>本文怎么解决退化问题？</h2><h3 id=\"Resnet-结构分析\"><a href=\"#Resnet-结构分析\" class=\"headerlink\" title=\"Resnet 结构分析\"></a>Resnet 结构分析</h3><h4 id=\"ResNet-短连接块\"><a href=\"#ResNet-短连接块\" class=\"headerlink\" title=\"ResNet 短连接块\"></a>ResNet 短连接块</h4><p><img src=\"/2019/01/25/Deep-Residual-Learning-for-Image-Recognition/resnet2.png\" alt=\"logo\"><br>作者在《Identity Mapping in Deep Residual Networks 》一文中，推导了为什么短连接更容易训练，也提出了新的短连接块结构。</p>\n<h4 id=\"为什么-ResNet-build-block-更容易训练？\"><a href=\"#为什么-ResNet-build-block-更容易训练？\" class=\"headerlink\" title=\"为什么 ResNet build block 更容易训练？\"></a>为什么 ResNet build block 更容易训练？</h4><h5 id=\"前向传播中帮助网络中一些层更容易实现恒等映射：\"><a href=\"#前向传播中帮助网络中一些层更容易实现恒等映射：\" class=\"headerlink\" title=\"前向传播中帮助网络中一些层更容易实现恒等映射：\"></a>前向传播中帮助网络中一些层更容易实现恒等映射：</h5><p>　　<strong><em>出现了第一幅图的退化问题，这里假设深层网络的后边层都变成了<font color=\"red\">恒等映射 </font>，那网络就退化成了浅层网络</em></strong>（因为网络很深，所以其中肯定包括了多余的层，这些层会形成<font color=\"red\">恒等映射 </font>关系），原来的直接多个层堆叠的非线性层去直接学习<font color=\"red\"> 恒等映射 </font>优化起来复杂，而加了上图的 <code>短连接</code>块之后，学习<font color=\"red\"> 恒等映射 </font>变容易了。</p>\n<h5 id=\"反向传播中\"><a href=\"#反向传播中\" class=\"headerlink\" title=\"反向传播中\"></a>反向传播中</h5><blockquote>\n<p>　　因为网络中存在<code>恒等映射的短连接通道</code>，假设不加residual模块的输出为h(x)。x=10,h(x)=11,h(x)简化为线性运算Wh​, Wh明显为1.1，加了redidual模块后，F(x)=1, H(x)=F(x)+x=11，F也简化为线性运算,对应的WF为0.1。当标签中的真实值为12，反向传播的损失为1，而对于F中的参数和h中参数回传的损失实际上是一样大的而且梯度都是x的值，但是对于F的参数就从0.1到1.1扩大了十倍多，而h的参数是从1.1到2.1扩大不到2倍，因此redidual模块会明显减小模块中参数的值从而让网络中的参数对反向传导的损失值有更敏感的响应能力，虽然根本上没有解决回传的损失小得问题，但是却让参数减小，相对而言增加了回传损失的效果，也产生了一定的正则化作用。<br><a href=\"https://blog.csdn.net/weixin_43624538/article/details/85049699?from=timeline&amp;isappinstalled=0&quot;该部分参考这里&quot;\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_43624538/article/details/85049699?from=timeline&amp;isappinstalled=0</a></p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<p><code>2015年</code> 论文地址：  <a href=\"https://arxiv.org/pdf/1512.03385.pdf&quot;论文地址&quot;\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/pdf/1512.03385.pdf</a></p>\n<h2 id=\"通常情况下\"><a href=\"#通常情况下\" class=\"headerlink\" title=\"通常情况下\"></a>通常情况下</h2><ol>\n<li>神经网络层越深，特征的抽象程度越高，模型的表达能力越强，语义信息越丰富；</li>\n<li>同时，网络越深，<code>退化问题</code> 越难解决;</li>\n</ol>\n<h2 id=\"退化问题是网络加深的障碍\"><a href=\"#退化问题是网络加深的障碍\" class=\"headerlink\" title=\"退化问题是网络加深的障碍\"></a>退化问题是网络加深的障碍</h2><p>　　简单的增加深度，会导致 <code>梯度弥散</code> 或者 <code>梯度爆炸</code> ,可以通过标准初始化和中间层正则化（batchNorm）解决；但是随着继续增加深度，训练集准确率饱和，甚至下降（<code>退化问题</code>，不属于过拟合）。</p>\n<p><img src=\"/2019/01/25/Deep-Residual-Learning-for-Image-Recognition/resnet1.png\" alt=\"logo\"></p>\n<p>　　神经网络就像一个｀Function Set｀，网络是输入 x 到输出 out 的映射关系 F，<code>out = F(x)</code> ，所以网络层越深，这个 <code>Set</code> 包含的函数越复杂，那能够拟合的情况就更多（意思是解决的问题就更多），上图是作者在<code>CIFAR-10</code> 数据集上的对比实验，56层网络是在20层网络上的重复叠加（最差也应该是前22层的恒等映射），但是较深网络训练集的误差却比浅层网络的误差更大。这不是过拟合了，过深网络出现了 <code>退化问题</code>。</p>\n<h2 id=\"本文效果（很大程度上解决了退化问题）：\"><a href=\"#本文效果（很大程度上解决了退化问题）：\" class=\"headerlink\" title=\"本文效果（很大程度上解决了退化问题）：\"></a>本文效果（很大程度上解决了退化问题）：</h2><ol>\n<li>作者在ImageNet上实验了一个152层的残差网络，比VGG深8倍，取得了3.57%的错误率。</li>\n<li>作者通过一系列实验证明了表示的深度（即网络的深度）对很多视觉识别任务都至关重要。仅仅由于使用了非常深的网络，作者就在COCO目标检测数据集上获得了28%的相对提升。</li>\n</ol>\n<h2 id=\"本文怎么解决退化问题？\"><a href=\"#本文怎么解决退化问题？\" class=\"headerlink\" title=\"本文怎么解决退化问题？\"></a>本文怎么解决退化问题？</h2><h3 id=\"Resnet-结构分析\"><a href=\"#Resnet-结构分析\" class=\"headerlink\" title=\"Resnet 结构分析\"></a>Resnet 结构分析</h3><h4 id=\"ResNet-短连接块\"><a href=\"#ResNet-短连接块\" class=\"headerlink\" title=\"ResNet 短连接块\"></a>ResNet 短连接块</h4><p><img src=\"/2019/01/25/Deep-Residual-Learning-for-Image-Recognition/resnet2.png\" alt=\"logo\"><br>作者在《Identity Mapping in Deep Residual Networks 》一文中，推导了为什么短连接更容易训练，也提出了新的短连接块结构。</p>\n<h4 id=\"为什么-ResNet-build-block-更容易训练？\"><a href=\"#为什么-ResNet-build-block-更容易训练？\" class=\"headerlink\" title=\"为什么 ResNet build block 更容易训练？\"></a>为什么 ResNet build block 更容易训练？</h4><h5 id=\"前向传播中帮助网络中一些层更容易实现恒等映射：\"><a href=\"#前向传播中帮助网络中一些层更容易实现恒等映射：\" class=\"headerlink\" title=\"前向传播中帮助网络中一些层更容易实现恒等映射：\"></a>前向传播中帮助网络中一些层更容易实现恒等映射：</h5><p>　　<strong><em>出现了第一幅图的退化问题，这里假设深层网络的后边层都变成了<font color=\"red\">恒等映射 </font>，那网络就退化成了浅层网络</em></strong>（因为网络很深，所以其中肯定包括了多余的层，这些层会形成<font color=\"red\">恒等映射 </font>关系），原来的直接多个层堆叠的非线性层去直接学习<font color=\"red\"> 恒等映射 </font>优化起来复杂，而加了上图的 <code>短连接</code>块之后，学习<font color=\"red\"> 恒等映射 </font>变容易了。</p>\n<h5 id=\"反向传播中\"><a href=\"#反向传播中\" class=\"headerlink\" title=\"反向传播中\"></a>反向传播中</h5><blockquote>\n<p>　　因为网络中存在<code>恒等映射的短连接通道</code>，假设不加residual模块的输出为h(x)。x=10,h(x)=11,h(x)简化为线性运算Wh​, Wh明显为1.1，加了redidual模块后，F(x)=1, H(x)=F(x)+x=11，F也简化为线性运算,对应的WF为0.1。当标签中的真实值为12，反向传播的损失为1，而对于F中的参数和h中参数回传的损失实际上是一样大的而且梯度都是x的值，但是对于F的参数就从0.1到1.1扩大了十倍多，而h的参数是从1.1到2.1扩大不到2倍，因此redidual模块会明显减小模块中参数的值从而让网络中的参数对反向传导的损失值有更敏感的响应能力，虽然根本上没有解决回传的损失小得问题，但是却让参数减小，相对而言增加了回传损失的效果，也产生了一定的正则化作用。<br><a href=\"https://blog.csdn.net/weixin_43624538/article/details/85049699?from=timeline&amp;isappinstalled=0&quot;该部分参考这里&quot;\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/weixin_43624538/article/details/85049699?from=timeline&amp;isappinstalled=0</a></p>\n</blockquote>\n"},{"title":"eclipse-and-github","date":"2019-01-19T14:28:19.000Z","_content":"# 内容概要\n\n\n- `本地`  首次上传到  `github`\n- `本地`  更新到   `github`\n- `github` 首次下载到  `本地`\n- `github`  更新到  `本地`\n\n## 本地首次上传到 **github**\n1. 进入 `github官网`，选择 `New repository`\n\n\n2. 复制地址  `http:XXXXXXXXXX.git`\n\n\n3. `本地` 右键自己的项目文件夹，选择 `git bash here`\n\n\n4. 克隆 `github` 仓库到本地(执行如下命令), 会在本地产生一个 github 上仓库同名的文件夹 `XXX`，<code>将工程所有内容移入文件夹内</code>\n\n\t`git clone http:XXXXXXXXXX.git`\n\n5.  `cd XXX`, 进入该目录，执行以下操作：\n\n\t\n\tgit add .  \n\n\t// git status   \n\n\tgit commit -m \"此次提交的备注信息\"\n\n\tgit push -u origin  master\n\n\n## 本地更新到 github\n\n方法与上节中的5一致。\n\n\n## 首次下载到本地\n\n`git clone http:XXXXXXXXXX.git`\n\n## 更新到本地\n\n`git pull`\n\t\n\n\n","source":"_posts/git使用.md","raw":"---\ntitle: eclipse-and-github\ndate: 2019-01-19 22:28:19\ncategories: git\ntags: git\n---\n# 内容概要\n\n\n- `本地`  首次上传到  `github`\n- `本地`  更新到   `github`\n- `github` 首次下载到  `本地`\n- `github`  更新到  `本地`\n\n## 本地首次上传到 **github**\n1. 进入 `github官网`，选择 `New repository`\n\n\n2. 复制地址  `http:XXXXXXXXXX.git`\n\n\n3. `本地` 右键自己的项目文件夹，选择 `git bash here`\n\n\n4. 克隆 `github` 仓库到本地(执行如下命令), 会在本地产生一个 github 上仓库同名的文件夹 `XXX`，<code>将工程所有内容移入文件夹内</code>\n\n\t`git clone http:XXXXXXXXXX.git`\n\n5.  `cd XXX`, 进入该目录，执行以下操作：\n\n\t\n\tgit add .  \n\n\t// git status   \n\n\tgit commit -m \"此次提交的备注信息\"\n\n\tgit push -u origin  master\n\n\n## 本地更新到 github\n\n方法与上节中的5一致。\n\n\n## 首次下载到本地\n\n`git clone http:XXXXXXXXXX.git`\n\n## 更新到本地\n\n`git pull`\n\t\n\n\n","slug":"git使用","published":1,"updated":"2019-07-30T16:39:10.819Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz98jgyo0008y0plrz0vr4al","content":"<h1 id=\"内容概要\"><a href=\"#内容概要\" class=\"headerlink\" title=\"内容概要\"></a>内容概要</h1><ul>\n<li><code>本地</code>  首次上传到  <code>github</code></li>\n<li><code>本地</code>  更新到   <code>github</code></li>\n<li><code>github</code> 首次下载到  <code>本地</code></li>\n<li><code>github</code>  更新到  <code>本地</code></li>\n</ul>\n<h2 id=\"本地首次上传到-github\"><a href=\"#本地首次上传到-github\" class=\"headerlink\" title=\"本地首次上传到 github\"></a>本地首次上传到 <strong>github</strong></h2><ol>\n<li>进入 <code>github官网</code>，选择 <code>New repository</code></li>\n</ol>\n<ol>\n<li>复制地址  <code>http:XXXXXXXXXX.git</code></li>\n</ol>\n<ol>\n<li><code>本地</code> 右键自己的项目文件夹，选择 <code>git bash here</code></li>\n</ol>\n<ol>\n<li><p>克隆 <code>github</code> 仓库到本地(执行如下命令), 会在本地产生一个 github 上仓库同名的文件夹 <code>XXX</code>，<code>将工程所有内容移入文件夹内</code></p>\n<p> <code>git clone http:XXXXXXXXXX.git</code></p>\n</li>\n<li><p><code>cd XXX</code>, 进入该目录，执行以下操作：</p>\n</li>\n</ol>\n<pre><code>git add .  \n\n// git status   \n\ngit commit -m &quot;此次提交的备注信息&quot;\n\ngit push -u origin  master\n</code></pre><h2 id=\"本地更新到-github\"><a href=\"#本地更新到-github\" class=\"headerlink\" title=\"本地更新到 github\"></a>本地更新到 github</h2><p>方法与上节中的5一致。</p>\n<h2 id=\"首次下载到本地\"><a href=\"#首次下载到本地\" class=\"headerlink\" title=\"首次下载到本地\"></a>首次下载到本地</h2><p><code>git clone http:XXXXXXXXXX.git</code></p>\n<h2 id=\"更新到本地\"><a href=\"#更新到本地\" class=\"headerlink\" title=\"更新到本地\"></a>更新到本地</h2><p><code>git pull</code></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"内容概要\"><a href=\"#内容概要\" class=\"headerlink\" title=\"内容概要\"></a>内容概要</h1><ul>\n<li><code>本地</code>  首次上传到  <code>github</code></li>\n<li><code>本地</code>  更新到   <code>github</code></li>\n<li><code>github</code> 首次下载到  <code>本地</code></li>\n<li><code>github</code>  更新到  <code>本地</code></li>\n</ul>\n<h2 id=\"本地首次上传到-github\"><a href=\"#本地首次上传到-github\" class=\"headerlink\" title=\"本地首次上传到 github\"></a>本地首次上传到 <strong>github</strong></h2><ol>\n<li>进入 <code>github官网</code>，选择 <code>New repository</code></li>\n</ol>\n<ol>\n<li>复制地址  <code>http:XXXXXXXXXX.git</code></li>\n</ol>\n<ol>\n<li><code>本地</code> 右键自己的项目文件夹，选择 <code>git bash here</code></li>\n</ol>\n<ol>\n<li><p>克隆 <code>github</code> 仓库到本地(执行如下命令), 会在本地产生一个 github 上仓库同名的文件夹 <code>XXX</code>，<code>将工程所有内容移入文件夹内</code></p>\n<p> <code>git clone http:XXXXXXXXXX.git</code></p>\n</li>\n<li><p><code>cd XXX</code>, 进入该目录，执行以下操作：</p>\n</li>\n</ol>\n<pre><code>git add .  \n\n// git status   \n\ngit commit -m &quot;此次提交的备注信息&quot;\n\ngit push -u origin  master\n</code></pre><h2 id=\"本地更新到-github\"><a href=\"#本地更新到-github\" class=\"headerlink\" title=\"本地更新到 github\"></a>本地更新到 github</h2><p>方法与上节中的5一致。</p>\n<h2 id=\"首次下载到本地\"><a href=\"#首次下载到本地\" class=\"headerlink\" title=\"首次下载到本地\"></a>首次下载到本地</h2><p><code>git clone http:XXXXXXXXXX.git</code></p>\n<h2 id=\"更新到本地\"><a href=\"#更新到本地\" class=\"headerlink\" title=\"更新到本地\"></a>更新到本地</h2><p><code>git pull</code></p>\n"},{"title":"pandas-8分层和多级索引","mathjax":true,"date":"2019-08-13T02:54:12.000Z","_content":"\n# pandas -8 分层和多级索引\n\n> Multi-level indexing. 在 “[pandas -2 索引和选择数据](http://www.elgong.top/2019/07/25/pandas-%E7%B4%A2%E5%BC%95%E5%92%8C%E9%80%89%E6%8B%A9%E6%95%B0%E6%8D%AE/)” 一节中, 已经提到了如何选择行列元素, 而Series 和 Dataframe 是低维度的数据结构，对于更高维度的数据，可以通过分层和多级索引来实现。\n\n## 分层索引的创建\n\n> 创建分层索引的方式有很多, 这里直接摘抄自官方的文档，可以通过元组，列表，Dataframe, arrays 等方式生成分层索引。\n\n> 同时要知道，通过 groupby 分组操作之后得到的也是这种分层结构。\n\n```\n    //  1. 元组\nIn: \n\n    arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo','qux', 'qux'], ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n    tuples = list(zip(*arrays))\nOut: \n    [('bar', 'one'),\n     ('bar', 'two'),\n     ('baz', 'one'),\n     ('baz', 'two'),\n     ('foo', 'one'),\n     ('foo', 'two'),\n     ('qux', 'one'),\n     ('qux', 'two')]\n\nIn:\n    index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n    df = pd.Series(np.random.randn(8), index=index)\n    \nOut:\n    first  second\n    bar    one       0.469112\n           two      -0.282863\n    baz    one      -1.509059\n           two      -1.135632\n    foo    one       1.212112\n           two      -0.173215\n    qux    one       0.119209\n           two      -1.044236\n    dtype: float64\n    \n    \n    // 2. dataftame\n    \n    index = pd.MultiIndex.from_frame(df)\n    \n    \n    // 3. arrays\n    \nIn: \n    arrays = [np.array(['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux']),\n              np.array(['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two'])]\n\n\n     s = pd.Series(np.random.randn(8), index=arrays)\n\n\n```\n## 从DataFrame 产生 MultiIndex\n\n```\n    df = df.set_index(['col1','col2'])\n```\n\n## MultiIndex 转化成 列\n\n```\n    df = df.reset_index()\n```\n## 选择不同层\n\n> 查看不同层的索引值。\n\n```\nIn:\n    index.get_level_values(0)\n    \n    index.get_level_values(\"name\")\n    \nOut:\n    Index(['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'], dtype='object', name='first')\n\n```\n\n> 根据不同层索引\n\n```\n    df[\"bar\"]\n    df[\"one\"]\n    df[\"bar\"][\"one\"]\n    \n    // 元组\n    df.loc[('bar', 'two')]\n\n```\n\n<font color=0xff111>  注意, 切片时不会改变 多层索引。 </font>\n","source":"_posts/pandas-分层和多级索引.md","raw":"---\ntitle: pandas-8分层和多级索引\nmathjax: true\ndate: 2019-08-13 10:54:12\ncategories: pandas系列教程\ntags: pandas-MultiIndex\n---\n\n# pandas -8 分层和多级索引\n\n> Multi-level indexing. 在 “[pandas -2 索引和选择数据](http://www.elgong.top/2019/07/25/pandas-%E7%B4%A2%E5%BC%95%E5%92%8C%E9%80%89%E6%8B%A9%E6%95%B0%E6%8D%AE/)” 一节中, 已经提到了如何选择行列元素, 而Series 和 Dataframe 是低维度的数据结构，对于更高维度的数据，可以通过分层和多级索引来实现。\n\n## 分层索引的创建\n\n> 创建分层索引的方式有很多, 这里直接摘抄自官方的文档，可以通过元组，列表，Dataframe, arrays 等方式生成分层索引。\n\n> 同时要知道，通过 groupby 分组操作之后得到的也是这种分层结构。\n\n```\n    //  1. 元组\nIn: \n\n    arrays = [['bar', 'bar', 'baz', 'baz', 'foo', 'foo','qux', 'qux'], ['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two']]\n    tuples = list(zip(*arrays))\nOut: \n    [('bar', 'one'),\n     ('bar', 'two'),\n     ('baz', 'one'),\n     ('baz', 'two'),\n     ('foo', 'one'),\n     ('foo', 'two'),\n     ('qux', 'one'),\n     ('qux', 'two')]\n\nIn:\n    index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n    df = pd.Series(np.random.randn(8), index=index)\n    \nOut:\n    first  second\n    bar    one       0.469112\n           two      -0.282863\n    baz    one      -1.509059\n           two      -1.135632\n    foo    one       1.212112\n           two      -0.173215\n    qux    one       0.119209\n           two      -1.044236\n    dtype: float64\n    \n    \n    // 2. dataftame\n    \n    index = pd.MultiIndex.from_frame(df)\n    \n    \n    // 3. arrays\n    \nIn: \n    arrays = [np.array(['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux']),\n              np.array(['one', 'two', 'one', 'two', 'one', 'two', 'one', 'two'])]\n\n\n     s = pd.Series(np.random.randn(8), index=arrays)\n\n\n```\n## 从DataFrame 产生 MultiIndex\n\n```\n    df = df.set_index(['col1','col2'])\n```\n\n## MultiIndex 转化成 列\n\n```\n    df = df.reset_index()\n```\n## 选择不同层\n\n> 查看不同层的索引值。\n\n```\nIn:\n    index.get_level_values(0)\n    \n    index.get_level_values(\"name\")\n    \nOut:\n    Index(['bar', 'bar', 'baz', 'baz', 'foo', 'foo', 'qux', 'qux'], dtype='object', name='first')\n\n```\n\n> 根据不同层索引\n\n```\n    df[\"bar\"]\n    df[\"one\"]\n    df[\"bar\"][\"one\"]\n    \n    // 元组\n    df.loc[('bar', 'two')]\n\n```\n\n<font color=0xff111>  注意, 切片时不会改变 多层索引。 </font>\n","slug":"pandas-分层和多级索引","published":1,"updated":"2019-09-11T06:20:49.779Z","_id":"cjz98jgyr000ay0plhh3k9491","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"pandas-8-分层和多级索引\"><a href=\"#pandas-8-分层和多级索引\" class=\"headerlink\" title=\"pandas -8 分层和多级索引\"></a>pandas -8 分层和多级索引</h1><blockquote>\n<p>Multi-level indexing. 在 “<a href=\"http://www.elgong.top/2019/07/25/pandas-%E7%B4%A2%E5%BC%95%E5%92%8C%E9%80%89%E6%8B%A9%E6%95%B0%E6%8D%AE/\">pandas -2 索引和选择数据</a>” 一节中, 已经提到了如何选择行列元素, 而Series 和 Dataframe 是低维度的数据结构，对于更高维度的数据，可以通过分层和多级索引来实现。</p>\n</blockquote>\n<h2 id=\"分层索引的创建\"><a href=\"#分层索引的创建\" class=\"headerlink\" title=\"分层索引的创建\"></a>分层索引的创建</h2><blockquote>\n<p>创建分层索引的方式有很多, 这里直接摘抄自官方的文档，可以通过元组，列表，Dataframe, arrays 等方式生成分层索引。</p>\n<p>同时要知道，通过 groupby 分组操作之后得到的也是这种分层结构。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">    //  1. 元组</span><br><span class=\"line\">In: </span><br><span class=\"line\"></span><br><span class=\"line\">    arrays = [[&apos;bar&apos;, &apos;bar&apos;, &apos;baz&apos;, &apos;baz&apos;, &apos;foo&apos;, &apos;foo&apos;,&apos;qux&apos;, &apos;qux&apos;], [&apos;one&apos;, &apos;two&apos;, &apos;one&apos;, &apos;two&apos;, &apos;one&apos;, &apos;two&apos;, &apos;one&apos;, &apos;two&apos;]]</span><br><span class=\"line\">    tuples = list(zip(*arrays))</span><br><span class=\"line\">Out: </span><br><span class=\"line\">    [(&apos;bar&apos;, &apos;one&apos;),</span><br><span class=\"line\">     (&apos;bar&apos;, &apos;two&apos;),</span><br><span class=\"line\">     (&apos;baz&apos;, &apos;one&apos;),</span><br><span class=\"line\">     (&apos;baz&apos;, &apos;two&apos;),</span><br><span class=\"line\">     (&apos;foo&apos;, &apos;one&apos;),</span><br><span class=\"line\">     (&apos;foo&apos;, &apos;two&apos;),</span><br><span class=\"line\">     (&apos;qux&apos;, &apos;one&apos;),</span><br><span class=\"line\">     (&apos;qux&apos;, &apos;two&apos;)]</span><br><span class=\"line\"></span><br><span class=\"line\">In:</span><br><span class=\"line\">    index = pd.MultiIndex.from_tuples(tuples, names=[&apos;first&apos;, &apos;second&apos;])</span><br><span class=\"line\">    df = pd.Series(np.random.randn(8), index=index)</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">    first  second</span><br><span class=\"line\">    bar    one       0.469112</span><br><span class=\"line\">           two      -0.282863</span><br><span class=\"line\">    baz    one      -1.509059</span><br><span class=\"line\">           two      -1.135632</span><br><span class=\"line\">    foo    one       1.212112</span><br><span class=\"line\">           two      -0.173215</span><br><span class=\"line\">    qux    one       0.119209</span><br><span class=\"line\">           two      -1.044236</span><br><span class=\"line\">    dtype: float64</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">    // 2. dataftame</span><br><span class=\"line\">    </span><br><span class=\"line\">    index = pd.MultiIndex.from_frame(df)</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">    // 3. arrays</span><br><span class=\"line\">    </span><br><span class=\"line\">In: </span><br><span class=\"line\">    arrays = [np.array([&apos;bar&apos;, &apos;bar&apos;, &apos;baz&apos;, &apos;baz&apos;, &apos;foo&apos;, &apos;foo&apos;, &apos;qux&apos;, &apos;qux&apos;]),</span><br><span class=\"line\">              np.array([&apos;one&apos;, &apos;two&apos;, &apos;one&apos;, &apos;two&apos;, &apos;one&apos;, &apos;two&apos;, &apos;one&apos;, &apos;two&apos;])]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">     s = pd.Series(np.random.randn(8), index=arrays)</span><br></pre></td></tr></table></figure>\n<h2 id=\"从DataFrame-产生-MultiIndex\"><a href=\"#从DataFrame-产生-MultiIndex\" class=\"headerlink\" title=\"从DataFrame 产生 MultiIndex\"></a>从DataFrame 产生 MultiIndex</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df = df.set_index([&apos;col1&apos;,&apos;col2&apos;])</span><br></pre></td></tr></table></figure>\n<h2 id=\"MultiIndex-转化成-列\"><a href=\"#MultiIndex-转化成-列\" class=\"headerlink\" title=\"MultiIndex 转化成 列\"></a>MultiIndex 转化成 列</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df = df.reset_index()</span><br></pre></td></tr></table></figure>\n<h2 id=\"选择不同层\"><a href=\"#选择不同层\" class=\"headerlink\" title=\"选择不同层\"></a>选择不同层</h2><blockquote>\n<p>查看不同层的索引值。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In:</span><br><span class=\"line\">    index.get_level_values(0)</span><br><span class=\"line\">    </span><br><span class=\"line\">    index.get_level_values(&quot;name&quot;)</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">    Index([&apos;bar&apos;, &apos;bar&apos;, &apos;baz&apos;, &apos;baz&apos;, &apos;foo&apos;, &apos;foo&apos;, &apos;qux&apos;, &apos;qux&apos;], dtype=&apos;object&apos;, name=&apos;first&apos;)</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>根据不同层索引</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df[&quot;bar&quot;]</span><br><span class=\"line\">df[&quot;one&quot;]</span><br><span class=\"line\">df[&quot;bar&quot;][&quot;one&quot;]</span><br><span class=\"line\"></span><br><span class=\"line\">// 元组</span><br><span class=\"line\">df.loc[(&apos;bar&apos;, &apos;two&apos;)]</span><br></pre></td></tr></table></figure>\n<font color=\"0xff111\">  注意, 切片时不会改变 多层索引。 </font>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"pandas-8-分层和多级索引\"><a href=\"#pandas-8-分层和多级索引\" class=\"headerlink\" title=\"pandas -8 分层和多级索引\"></a>pandas -8 分层和多级索引</h1><blockquote>\n<p>Multi-level indexing. 在 “<a href=\"http://www.elgong.top/2019/07/25/pandas-%E7%B4%A2%E5%BC%95%E5%92%8C%E9%80%89%E6%8B%A9%E6%95%B0%E6%8D%AE/\">pandas -2 索引和选择数据</a>” 一节中, 已经提到了如何选择行列元素, 而Series 和 Dataframe 是低维度的数据结构，对于更高维度的数据，可以通过分层和多级索引来实现。</p>\n</blockquote>\n<h2 id=\"分层索引的创建\"><a href=\"#分层索引的创建\" class=\"headerlink\" title=\"分层索引的创建\"></a>分层索引的创建</h2><blockquote>\n<p>创建分层索引的方式有很多, 这里直接摘抄自官方的文档，可以通过元组，列表，Dataframe, arrays 等方式生成分层索引。</p>\n<p>同时要知道，通过 groupby 分组操作之后得到的也是这种分层结构。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">    //  1. 元组</span><br><span class=\"line\">In: </span><br><span class=\"line\"></span><br><span class=\"line\">    arrays = [[&apos;bar&apos;, &apos;bar&apos;, &apos;baz&apos;, &apos;baz&apos;, &apos;foo&apos;, &apos;foo&apos;,&apos;qux&apos;, &apos;qux&apos;], [&apos;one&apos;, &apos;two&apos;, &apos;one&apos;, &apos;two&apos;, &apos;one&apos;, &apos;two&apos;, &apos;one&apos;, &apos;two&apos;]]</span><br><span class=\"line\">    tuples = list(zip(*arrays))</span><br><span class=\"line\">Out: </span><br><span class=\"line\">    [(&apos;bar&apos;, &apos;one&apos;),</span><br><span class=\"line\">     (&apos;bar&apos;, &apos;two&apos;),</span><br><span class=\"line\">     (&apos;baz&apos;, &apos;one&apos;),</span><br><span class=\"line\">     (&apos;baz&apos;, &apos;two&apos;),</span><br><span class=\"line\">     (&apos;foo&apos;, &apos;one&apos;),</span><br><span class=\"line\">     (&apos;foo&apos;, &apos;two&apos;),</span><br><span class=\"line\">     (&apos;qux&apos;, &apos;one&apos;),</span><br><span class=\"line\">     (&apos;qux&apos;, &apos;two&apos;)]</span><br><span class=\"line\"></span><br><span class=\"line\">In:</span><br><span class=\"line\">    index = pd.MultiIndex.from_tuples(tuples, names=[&apos;first&apos;, &apos;second&apos;])</span><br><span class=\"line\">    df = pd.Series(np.random.randn(8), index=index)</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">    first  second</span><br><span class=\"line\">    bar    one       0.469112</span><br><span class=\"line\">           two      -0.282863</span><br><span class=\"line\">    baz    one      -1.509059</span><br><span class=\"line\">           two      -1.135632</span><br><span class=\"line\">    foo    one       1.212112</span><br><span class=\"line\">           two      -0.173215</span><br><span class=\"line\">    qux    one       0.119209</span><br><span class=\"line\">           two      -1.044236</span><br><span class=\"line\">    dtype: float64</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">    // 2. dataftame</span><br><span class=\"line\">    </span><br><span class=\"line\">    index = pd.MultiIndex.from_frame(df)</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">    // 3. arrays</span><br><span class=\"line\">    </span><br><span class=\"line\">In: </span><br><span class=\"line\">    arrays = [np.array([&apos;bar&apos;, &apos;bar&apos;, &apos;baz&apos;, &apos;baz&apos;, &apos;foo&apos;, &apos;foo&apos;, &apos;qux&apos;, &apos;qux&apos;]),</span><br><span class=\"line\">              np.array([&apos;one&apos;, &apos;two&apos;, &apos;one&apos;, &apos;two&apos;, &apos;one&apos;, &apos;two&apos;, &apos;one&apos;, &apos;two&apos;])]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">     s = pd.Series(np.random.randn(8), index=arrays)</span><br></pre></td></tr></table></figure>\n<h2 id=\"从DataFrame-产生-MultiIndex\"><a href=\"#从DataFrame-产生-MultiIndex\" class=\"headerlink\" title=\"从DataFrame 产生 MultiIndex\"></a>从DataFrame 产生 MultiIndex</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df = df.set_index([&apos;col1&apos;,&apos;col2&apos;])</span><br></pre></td></tr></table></figure>\n<h2 id=\"MultiIndex-转化成-列\"><a href=\"#MultiIndex-转化成-列\" class=\"headerlink\" title=\"MultiIndex 转化成 列\"></a>MultiIndex 转化成 列</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df = df.reset_index()</span><br></pre></td></tr></table></figure>\n<h2 id=\"选择不同层\"><a href=\"#选择不同层\" class=\"headerlink\" title=\"选择不同层\"></a>选择不同层</h2><blockquote>\n<p>查看不同层的索引值。</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In:</span><br><span class=\"line\">    index.get_level_values(0)</span><br><span class=\"line\">    </span><br><span class=\"line\">    index.get_level_values(&quot;name&quot;)</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">    Index([&apos;bar&apos;, &apos;bar&apos;, &apos;baz&apos;, &apos;baz&apos;, &apos;foo&apos;, &apos;foo&apos;, &apos;qux&apos;, &apos;qux&apos;], dtype=&apos;object&apos;, name=&apos;first&apos;)</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>根据不同层索引</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df[&quot;bar&quot;]</span><br><span class=\"line\">df[&quot;one&quot;]</span><br><span class=\"line\">df[&quot;bar&quot;][&quot;one&quot;]</span><br><span class=\"line\"></span><br><span class=\"line\">// 元组</span><br><span class=\"line\">df.loc[(&apos;bar&apos;, &apos;two&apos;)]</span><br></pre></td></tr></table></figure>\n<font color=\"0xff111\">  注意, 切片时不会改变 多层索引。 </font>\n"},{"title":"pandas-5缺失值处理","mathjax":true,"date":"2019-08-09T01:33:30.000Z","_content":"\n# pandas -5 缺失值处理\n\n> 统计数据中存在缺失值是十分常见的问题, 而对于缺失值的处理，是数据挖掘的一个重要环节。pandas 有一系列的方法处理缺失值。\n\n## 缺失值的类型\n\n判断方法只记住万能的 `pd.isnull` 即可。\n\n> 数值\n\n\n      pd.isna\n      pd.isnull\n      np.isnan\n\n> 字符串\n\n\n      pd.isna\n      pd.isnull\n\n\n\n> 时间\n\n      pd.isna\n      pd.isnull\n      np.isnat\n\n\n## 缺失值的统计\n\n\n      df.isnull().sum()\n\n## 丢掉缺失值\n\n\n\t  // 某列有缺失值, 删除\n\t  df[ pd.isnull(df[\"columns\"])]\n\t  \n\t  // Series \n\t  df.columns.dropna()\n\t  \n\t  // DataFrame\n\t  // axis: axis=0 （默认）表示操作行，axis=1 表示操作列;\n\t\n\t  // how : any 表示一行/列有任意元素为空时即丢弃，all 一行/列所有值都为空时才丢弃。\n\t\n\t  // subset: 参数表示删除时只考虑的索引或列名。\n\t\n\t  // thresh: 比如 thresh=3，会在一行/列中至少有 3 个非空值时将其保留。\n\t  df.dropna(axis=0, how=\"any\", subset=[\"city\", \"sex\"])\n\n\n\n## 填充缺失值\n\n> 数据量少的情况下，直接丢掉不可取，可以适当补充数据。\n\n\n\n\t   // 前值填充 ffill     后值填充  bfill\n\t   df.columns.fillna(method = \"ffill\")\n\t   \n\t   // 实值填充\n\t   df.fillna(0)\n\t   \n\t   // 均值填充\n\t   df[\"columns\"].fillna(df[\"columns\"].mean(), inplace=True)\n\t   \n\t   // 众数\n\t   mode()[0]\n\t   \n\t   // 中位数\n\t   median()\n\n\n\n","source":"_posts/pandas-缺失值处理.md","raw":"---\ntitle: pandas-5缺失值处理\nmathjax: true\ndate: 2019-08-09 09:33:30\ncategories: pandas系列教程\ntags: pandas\n\n---\n\n# pandas -5 缺失值处理\n\n> 统计数据中存在缺失值是十分常见的问题, 而对于缺失值的处理，是数据挖掘的一个重要环节。pandas 有一系列的方法处理缺失值。\n\n## 缺失值的类型\n\n判断方法只记住万能的 `pd.isnull` 即可。\n\n> 数值\n\n\n      pd.isna\n      pd.isnull\n      np.isnan\n\n> 字符串\n\n\n      pd.isna\n      pd.isnull\n\n\n\n> 时间\n\n      pd.isna\n      pd.isnull\n      np.isnat\n\n\n## 缺失值的统计\n\n\n      df.isnull().sum()\n\n## 丢掉缺失值\n\n\n\t  // 某列有缺失值, 删除\n\t  df[ pd.isnull(df[\"columns\"])]\n\t  \n\t  // Series \n\t  df.columns.dropna()\n\t  \n\t  // DataFrame\n\t  // axis: axis=0 （默认）表示操作行，axis=1 表示操作列;\n\t\n\t  // how : any 表示一行/列有任意元素为空时即丢弃，all 一行/列所有值都为空时才丢弃。\n\t\n\t  // subset: 参数表示删除时只考虑的索引或列名。\n\t\n\t  // thresh: 比如 thresh=3，会在一行/列中至少有 3 个非空值时将其保留。\n\t  df.dropna(axis=0, how=\"any\", subset=[\"city\", \"sex\"])\n\n\n\n## 填充缺失值\n\n> 数据量少的情况下，直接丢掉不可取，可以适当补充数据。\n\n\n\n\t   // 前值填充 ffill     后值填充  bfill\n\t   df.columns.fillna(method = \"ffill\")\n\t   \n\t   // 实值填充\n\t   df.fillna(0)\n\t   \n\t   // 均值填充\n\t   df[\"columns\"].fillna(df[\"columns\"].mean(), inplace=True)\n\t   \n\t   // 众数\n\t   mode()[0]\n\t   \n\t   // 中位数\n\t   median()\n\n\n\n","slug":"pandas-缺失值处理","published":1,"updated":"2019-09-11T06:20:27.595Z","_id":"cjz98jgz0000fy0pl5w26g9dm","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"pandas-5-缺失值处理\"><a href=\"#pandas-5-缺失值处理\" class=\"headerlink\" title=\"pandas -5 缺失值处理\"></a>pandas -5 缺失值处理</h1><blockquote>\n<p>统计数据中存在缺失值是十分常见的问题, 而对于缺失值的处理，是数据挖掘的一个重要环节。pandas 有一系列的方法处理缺失值。</p>\n</blockquote>\n<h2 id=\"缺失值的类型\"><a href=\"#缺失值的类型\" class=\"headerlink\" title=\"缺失值的类型\"></a>缺失值的类型</h2><p>判断方法只记住万能的 <code>pd.isnull</code> 即可。</p>\n<blockquote>\n<p>数值</p>\n</blockquote>\n<pre><code>  pd.isna\n  pd.isnull\n  np.isnan\n</code></pre><blockquote>\n<p>字符串</p>\n</blockquote>\n<pre><code>  pd.isna\n  pd.isnull\n</code></pre><blockquote>\n<p>时间</p>\n</blockquote>\n<pre><code>  pd.isna\n  pd.isnull\n  np.isnat\n</code></pre><h2 id=\"缺失值的统计\"><a href=\"#缺失值的统计\" class=\"headerlink\" title=\"缺失值的统计\"></a>缺失值的统计</h2><pre><code>  df.isnull().sum()\n</code></pre><h2 id=\"丢掉缺失值\"><a href=\"#丢掉缺失值\" class=\"headerlink\" title=\"丢掉缺失值\"></a>丢掉缺失值</h2><pre><code>  // 某列有缺失值, 删除\n  df[ pd.isnull(df[&quot;columns&quot;])]\n\n  // Series \n  df.columns.dropna()\n\n  // DataFrame\n  // axis: axis=0 （默认）表示操作行，axis=1 表示操作列;\n\n  // how : any 表示一行/列有任意元素为空时即丢弃，all 一行/列所有值都为空时才丢弃。\n\n  // subset: 参数表示删除时只考虑的索引或列名。\n\n  // thresh: 比如 thresh=3，会在一行/列中至少有 3 个非空值时将其保留。\n  df.dropna(axis=0, how=&quot;any&quot;, subset=[&quot;city&quot;, &quot;sex&quot;])\n</code></pre><h2 id=\"填充缺失值\"><a href=\"#填充缺失值\" class=\"headerlink\" title=\"填充缺失值\"></a>填充缺失值</h2><blockquote>\n<p>数据量少的情况下，直接丢掉不可取，可以适当补充数据。</p>\n</blockquote>\n<pre><code>   // 前值填充 ffill     后值填充  bfill\n   df.columns.fillna(method = &quot;ffill&quot;)\n\n   // 实值填充\n   df.fillna(0)\n\n   // 均值填充\n   df[&quot;columns&quot;].fillna(df[&quot;columns&quot;].mean(), inplace=True)\n\n   // 众数\n   mode()[0]\n\n   // 中位数\n   median()\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"pandas-5-缺失值处理\"><a href=\"#pandas-5-缺失值处理\" class=\"headerlink\" title=\"pandas -5 缺失值处理\"></a>pandas -5 缺失值处理</h1><blockquote>\n<p>统计数据中存在缺失值是十分常见的问题, 而对于缺失值的处理，是数据挖掘的一个重要环节。pandas 有一系列的方法处理缺失值。</p>\n</blockquote>\n<h2 id=\"缺失值的类型\"><a href=\"#缺失值的类型\" class=\"headerlink\" title=\"缺失值的类型\"></a>缺失值的类型</h2><p>判断方法只记住万能的 <code>pd.isnull</code> 即可。</p>\n<blockquote>\n<p>数值</p>\n</blockquote>\n<pre><code>  pd.isna\n  pd.isnull\n  np.isnan\n</code></pre><blockquote>\n<p>字符串</p>\n</blockquote>\n<pre><code>  pd.isna\n  pd.isnull\n</code></pre><blockquote>\n<p>时间</p>\n</blockquote>\n<pre><code>  pd.isna\n  pd.isnull\n  np.isnat\n</code></pre><h2 id=\"缺失值的统计\"><a href=\"#缺失值的统计\" class=\"headerlink\" title=\"缺失值的统计\"></a>缺失值的统计</h2><pre><code>  df.isnull().sum()\n</code></pre><h2 id=\"丢掉缺失值\"><a href=\"#丢掉缺失值\" class=\"headerlink\" title=\"丢掉缺失值\"></a>丢掉缺失值</h2><pre><code>  // 某列有缺失值, 删除\n  df[ pd.isnull(df[&quot;columns&quot;])]\n\n  // Series \n  df.columns.dropna()\n\n  // DataFrame\n  // axis: axis=0 （默认）表示操作行，axis=1 表示操作列;\n\n  // how : any 表示一行/列有任意元素为空时即丢弃，all 一行/列所有值都为空时才丢弃。\n\n  // subset: 参数表示删除时只考虑的索引或列名。\n\n  // thresh: 比如 thresh=3，会在一行/列中至少有 3 个非空值时将其保留。\n  df.dropna(axis=0, how=&quot;any&quot;, subset=[&quot;city&quot;, &quot;sex&quot;])\n</code></pre><h2 id=\"填充缺失值\"><a href=\"#填充缺失值\" class=\"headerlink\" title=\"填充缺失值\"></a>填充缺失值</h2><blockquote>\n<p>数据量少的情况下，直接丢掉不可取，可以适当补充数据。</p>\n</blockquote>\n<pre><code>   // 前值填充 ffill     后值填充  bfill\n   df.columns.fillna(method = &quot;ffill&quot;)\n\n   // 实值填充\n   df.fillna(0)\n\n   // 均值填充\n   df[&quot;columns&quot;].fillna(df[&quot;columns&quot;].mean(), inplace=True)\n\n   // 众数\n   mode()[0]\n\n   // 中位数\n   median()\n</code></pre>"},{"title":"XGBoost","mathjax":true,"date":"2019-07-30T14:02:00.000Z","_content":"\n# xgboost 学习笔记\n\n> 主要内容均来自官方文档，官方文档是英文版，所以简单的翻译了一下，方便日后查看。\n[详细内容见官方手册](https://xgboost.readthedocs.io/en/latest/python/python_intro.html)\n## 安装 XGBoost\n\n```\nubuntu -python3:\n    pip3 install xgboost\n \n导入:\n    import xgboost as xgb\n    \n```\n\n## 数据接口\n\n`XGBoost` 可以从以下结构中加载数据：\n- LibSVM text format file\n- CSV\n- Numpy 2D array\n- Scipy 2D sparse array\n- Pandas\n- XGBoost binary buffer file.\n\n加载的数据都放在 `DMatrix`对象中，下面是具体加载的过程演示：\n\n- LibSVM text format file\n```python\n    dtrain = xgb.DMatrix('train.svm.txt')\n    dtest = xgb.DMatrix('test.svm.buffer')\n```\n\n- CSV\n```python\n    // 需要指定标签所在的列\n    dtrain = xgb.DMatrix('train.csv?format=csv&label_column=0')\n    dtest = xgb.DMatrix('test.csv?format=csv&label_column=0')\n```\n<font color=\"#FF0000\"> \n\n XGBoost 不支持种类特征，需要先加载为Numpy数组，然后进行 `one-hot` 编码;推荐使用pandas 加载数据.\n</font> \n\n- Numpy\n```python\n    data = np.random.rand(5, 10)  # 5个样本，每个样本10个特征\n    label = np.random.randint(2, size=5)  # 二值标签\n    \n    dtrain = xgb.DMatrix(data, label=label)\n```\n\n- Scipy\n```python\n    csr = scipy.sparse.csr_matrix((dat, (row, col)))\n    dtrain = xgb.DMatrix(csr)\n```\n\n- Pandas\n```python\n    data = pandas.DataFrame(np.arange(12).reshape((4,3)), columns=['a', 'b', 'c'])\n    label = pandas.DataFrame(np.random.randint(2, size=4))\n    dtrain = xgb.DMatrix(data, label=label)\n```\n\n- 保存为 XGBoost 二进制文件\n```python\n    dtrain = xgb.DMatrix('train.svm.txt')\n    dtrain.save_binary('train.buffer')\n\n```\n- 缺失值处理\n```python\n    dtrain = xgb.DMatrix(data, label=label, missing=-999.0)\n```\n\n- 样本权重\n```\n    w = np.random.rand(5, 1)\n    dtrain = xgb.DMatrix(data, label=label, missing=-999.0, weight=w)\n```\n\n## 参数设置\n\n> XGBoost 可以通过列表或者字典来设置参数，例如：\n\n- Booster 参数\n```python\n    param = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}\n    param['nthread'] = 4\n    param['eval_metric'] = 'auc'\n```\n\n- 指定多个评估指标\n```python\n    param['eval_metric'] = ['auc', 'ams@0']\n\n```\n\n- 指定验证集来监视性能\n```python\n    evallist = [(dtest, 'eval'), (dtrain, 'train')]\n```\n\n## 训练\n\n- 模型训练\n```\n    num_round = 10\n    bst = xgb.train(param, dtrain, num_round, evallist)\n```\n\n- 模型保存\n```python\n    bst.save_model('0001.model')\n```\n\n- 保存模型和特征\n```python\n    # dump model\n    bst.dump_model('dump.raw.txt')\n    # dump model with feature map\n    bst.dump_model('dump.raw.txt', 'featmap.txt')\n```\n\n- 模型加载\n```\n    bst = xgb.Booster({'nthread': 4})  # init model\n    bst.load_model('model.bin')  # load data\n```\n\n\n## 早停\n\n> 如果你有验证集，则可以使用早停机制来寻找最佳的 `num_round`, 需要将 验证集传入 `evals`,如果传入多个，则使用最后一个。\n```\n    train(..., evals=evals, early_stopping_rounds=10)\n```\n如果模型在 `early_stopping_rounds`次，监控的参数 `param['eval_metric']` 都没有提升，则会停止训练，`train` 返回的是最后一次训练的模型，而不是最佳模型，最佳模型可以通过一下方式找到：\n\n- `bst.best_score`\n- `bst.best_iteration`\n- `bst.best_ntree_limit`  # 使用最佳模型\n\n同样的，监控多个参数时，最后一个参数起早停的作用。\n\n## 预测\n\n已经训练好的模型，或者已经加载的模型可以拿来预测新数据：\n```\n    data = np.random.rand(7, 10)\n    dtest = xgb.DMatrix(data)\n    ypred = bst.predict(dtest)\n```\n\n使用最佳的迭代次数的模型：\n```\n    ypred = bst.predict(dtest, ntree_limit=bst.best_ntree_limit)\n```\n\n\n## 绘制\n\n你可以使用绘图模块来画出树结构：\n\n- 绘制参数重要性\n\n```\n    xgb.plot_importance(bst)\n```\n\n- 绘制目标树\n\n```\n    xgb.plot_tree(bst, num_trees=2)\n```\n\n- Ipython 中绘制树\n\n```\n    xgb.to_graphviz(bst, num_trees=2)\n```","source":"_posts/XGBoost.md","raw":"---\ntitle: XGBoost\nmathjax: true\ndate: 2019-07-30 22:02:00\ncategories: XGBoost\ntags: XGBoost\n---\n\n# xgboost 学习笔记\n\n> 主要内容均来自官方文档，官方文档是英文版，所以简单的翻译了一下，方便日后查看。\n[详细内容见官方手册](https://xgboost.readthedocs.io/en/latest/python/python_intro.html)\n## 安装 XGBoost\n\n```\nubuntu -python3:\n    pip3 install xgboost\n \n导入:\n    import xgboost as xgb\n    \n```\n\n## 数据接口\n\n`XGBoost` 可以从以下结构中加载数据：\n- LibSVM text format file\n- CSV\n- Numpy 2D array\n- Scipy 2D sparse array\n- Pandas\n- XGBoost binary buffer file.\n\n加载的数据都放在 `DMatrix`对象中，下面是具体加载的过程演示：\n\n- LibSVM text format file\n```python\n    dtrain = xgb.DMatrix('train.svm.txt')\n    dtest = xgb.DMatrix('test.svm.buffer')\n```\n\n- CSV\n```python\n    // 需要指定标签所在的列\n    dtrain = xgb.DMatrix('train.csv?format=csv&label_column=0')\n    dtest = xgb.DMatrix('test.csv?format=csv&label_column=0')\n```\n<font color=\"#FF0000\"> \n\n XGBoost 不支持种类特征，需要先加载为Numpy数组，然后进行 `one-hot` 编码;推荐使用pandas 加载数据.\n</font> \n\n- Numpy\n```python\n    data = np.random.rand(5, 10)  # 5个样本，每个样本10个特征\n    label = np.random.randint(2, size=5)  # 二值标签\n    \n    dtrain = xgb.DMatrix(data, label=label)\n```\n\n- Scipy\n```python\n    csr = scipy.sparse.csr_matrix((dat, (row, col)))\n    dtrain = xgb.DMatrix(csr)\n```\n\n- Pandas\n```python\n    data = pandas.DataFrame(np.arange(12).reshape((4,3)), columns=['a', 'b', 'c'])\n    label = pandas.DataFrame(np.random.randint(2, size=4))\n    dtrain = xgb.DMatrix(data, label=label)\n```\n\n- 保存为 XGBoost 二进制文件\n```python\n    dtrain = xgb.DMatrix('train.svm.txt')\n    dtrain.save_binary('train.buffer')\n\n```\n- 缺失值处理\n```python\n    dtrain = xgb.DMatrix(data, label=label, missing=-999.0)\n```\n\n- 样本权重\n```\n    w = np.random.rand(5, 1)\n    dtrain = xgb.DMatrix(data, label=label, missing=-999.0, weight=w)\n```\n\n## 参数设置\n\n> XGBoost 可以通过列表或者字典来设置参数，例如：\n\n- Booster 参数\n```python\n    param = {'max_depth': 2, 'eta': 1, 'objective': 'binary:logistic'}\n    param['nthread'] = 4\n    param['eval_metric'] = 'auc'\n```\n\n- 指定多个评估指标\n```python\n    param['eval_metric'] = ['auc', 'ams@0']\n\n```\n\n- 指定验证集来监视性能\n```python\n    evallist = [(dtest, 'eval'), (dtrain, 'train')]\n```\n\n## 训练\n\n- 模型训练\n```\n    num_round = 10\n    bst = xgb.train(param, dtrain, num_round, evallist)\n```\n\n- 模型保存\n```python\n    bst.save_model('0001.model')\n```\n\n- 保存模型和特征\n```python\n    # dump model\n    bst.dump_model('dump.raw.txt')\n    # dump model with feature map\n    bst.dump_model('dump.raw.txt', 'featmap.txt')\n```\n\n- 模型加载\n```\n    bst = xgb.Booster({'nthread': 4})  # init model\n    bst.load_model('model.bin')  # load data\n```\n\n\n## 早停\n\n> 如果你有验证集，则可以使用早停机制来寻找最佳的 `num_round`, 需要将 验证集传入 `evals`,如果传入多个，则使用最后一个。\n```\n    train(..., evals=evals, early_stopping_rounds=10)\n```\n如果模型在 `early_stopping_rounds`次，监控的参数 `param['eval_metric']` 都没有提升，则会停止训练，`train` 返回的是最后一次训练的模型，而不是最佳模型，最佳模型可以通过一下方式找到：\n\n- `bst.best_score`\n- `bst.best_iteration`\n- `bst.best_ntree_limit`  # 使用最佳模型\n\n同样的，监控多个参数时，最后一个参数起早停的作用。\n\n## 预测\n\n已经训练好的模型，或者已经加载的模型可以拿来预测新数据：\n```\n    data = np.random.rand(7, 10)\n    dtest = xgb.DMatrix(data)\n    ypred = bst.predict(dtest)\n```\n\n使用最佳的迭代次数的模型：\n```\n    ypred = bst.predict(dtest, ntree_limit=bst.best_ntree_limit)\n```\n\n\n## 绘制\n\n你可以使用绘图模块来画出树结构：\n\n- 绘制参数重要性\n\n```\n    xgb.plot_importance(bst)\n```\n\n- 绘制目标树\n\n```\n    xgb.plot_tree(bst, num_trees=2)\n```\n\n- Ipython 中绘制树\n\n```\n    xgb.to_graphviz(bst, num_trees=2)\n```","slug":"XGBoost","published":1,"updated":"2019-07-30T16:39:56.988Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz98jgz3000gy0plwbgr2it5","content":"<h1 id=\"xgboost-学习笔记\"><a href=\"#xgboost-学习笔记\" class=\"headerlink\" title=\"xgboost 学习笔记\"></a>xgboost 学习笔记</h1><blockquote>\n<p>主要内容均来自官方文档，官方文档是英文版，所以简单的翻译了一下，方便日后查看。<br><a href=\"https://xgboost.readthedocs.io/en/latest/python/python_intro.html\" target=\"_blank\" rel=\"noopener\">详细内容见官方手册</a></p>\n<h2 id=\"安装-XGBoost\"><a href=\"#安装-XGBoost\" class=\"headerlink\" title=\"安装 XGBoost\"></a>安装 XGBoost</h2></blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ubuntu -python3:</span><br><span class=\"line\">    pip3 install xgboost</span><br><span class=\"line\"> </span><br><span class=\"line\">导入:</span><br><span class=\"line\">    import xgboost as xgb</span><br></pre></td></tr></table></figure>\n<h2 id=\"数据接口\"><a href=\"#数据接口\" class=\"headerlink\" title=\"数据接口\"></a>数据接口</h2><p><code>XGBoost</code> 可以从以下结构中加载数据：</p>\n<ul>\n<li>LibSVM text format file</li>\n<li>CSV</li>\n<li>Numpy 2D array</li>\n<li>Scipy 2D sparse array</li>\n<li>Pandas</li>\n<li>XGBoost binary buffer file.</li>\n</ul>\n<p>加载的数据都放在 <code>DMatrix</code>对象中，下面是具体加载的过程演示：</p>\n<ul>\n<li><p>LibSVM text format file</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dtrain = xgb.DMatrix(<span class=\"string\">'train.svm.txt'</span>)</span><br><span class=\"line\">dtest = xgb.DMatrix(<span class=\"string\">'test.svm.buffer'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>CSV</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 需要指定标签所在的列</span><br><span class=\"line\">dtrain = xgb.DMatrix(<span class=\"string\">'train.csv?format=csv&amp;label_column=0'</span>)</span><br><span class=\"line\">dtest = xgb.DMatrix(<span class=\"string\">'test.csv?format=csv&amp;label_column=0'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<font color=\"#FF0000\"> \n\n XGBoost 不支持种类特征，需要先加载为Numpy数组，然后进行 `one-hot` 编码;推荐使用pandas 加载数据.\n</font> \n\n<ul>\n<li><p>Numpy</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data = np.random.rand(<span class=\"number\">5</span>, <span class=\"number\">10</span>)  <span class=\"comment\"># 5个样本，每个样本10个特征</span></span><br><span class=\"line\">label = np.random.randint(<span class=\"number\">2</span>, size=<span class=\"number\">5</span>)  <span class=\"comment\"># 二值标签</span></span><br><span class=\"line\"></span><br><span class=\"line\">dtrain = xgb.DMatrix(data, label=label)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Scipy</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">csr = scipy.sparse.csr_matrix((dat, (row, col)))</span><br><span class=\"line\">dtrain = xgb.DMatrix(csr)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Pandas</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data = pandas.DataFrame(np.arange(<span class=\"number\">12</span>).reshape((<span class=\"number\">4</span>,<span class=\"number\">3</span>)), columns=[<span class=\"string\">'a'</span>, <span class=\"string\">'b'</span>, <span class=\"string\">'c'</span>])</span><br><span class=\"line\">label = pandas.DataFrame(np.random.randint(<span class=\"number\">2</span>, size=<span class=\"number\">4</span>))</span><br><span class=\"line\">dtrain = xgb.DMatrix(data, label=label)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>保存为 XGBoost 二进制文件</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dtrain = xgb.DMatrix(<span class=\"string\">'train.svm.txt'</span>)</span><br><span class=\"line\">dtrain.save_binary(<span class=\"string\">'train.buffer'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>缺失值处理</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dtrain = xgb.DMatrix(data, label=label, missing=<span class=\"number\">-999.0</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>样本权重</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">w = np.random.rand(5, 1)</span><br><span class=\"line\">dtrain = xgb.DMatrix(data, label=label, missing=-999.0, weight=w)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"参数设置\"><a href=\"#参数设置\" class=\"headerlink\" title=\"参数设置\"></a>参数设置</h2><blockquote>\n<p>XGBoost 可以通过列表或者字典来设置参数，例如：</p>\n</blockquote>\n<ul>\n<li><p>Booster 参数</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">param = &#123;<span class=\"string\">'max_depth'</span>: <span class=\"number\">2</span>, <span class=\"string\">'eta'</span>: <span class=\"number\">1</span>, <span class=\"string\">'objective'</span>: <span class=\"string\">'binary:logistic'</span>&#125;</span><br><span class=\"line\">param[<span class=\"string\">'nthread'</span>] = <span class=\"number\">4</span></span><br><span class=\"line\">param[<span class=\"string\">'eval_metric'</span>] = <span class=\"string\">'auc'</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>指定多个评估指标</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">param[<span class=\"string\">'eval_metric'</span>] = [<span class=\"string\">'auc'</span>, <span class=\"string\">'ams@0'</span>]</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>指定验证集来监视性能</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">evallist = [(dtest, <span class=\"string\">'eval'</span>), (dtrain, <span class=\"string\">'train'</span>)]</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"训练\"><a href=\"#训练\" class=\"headerlink\" title=\"训练\"></a>训练</h2><ul>\n<li><p>模型训练</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">num_round = 10</span><br><span class=\"line\">bst = xgb.train(param, dtrain, num_round, evallist)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>模型保存</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bst.save_model(<span class=\"string\">'0001.model'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>保存模型和特征</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># dump model</span></span><br><span class=\"line\">bst.dump_model(<span class=\"string\">'dump.raw.txt'</span>)</span><br><span class=\"line\"><span class=\"comment\"># dump model with feature map</span></span><br><span class=\"line\">bst.dump_model(<span class=\"string\">'dump.raw.txt'</span>, <span class=\"string\">'featmap.txt'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>模型加载</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bst = xgb.Booster(&#123;&apos;nthread&apos;: 4&#125;)  # init model</span><br><span class=\"line\">bst.load_model(&apos;model.bin&apos;)  # load data</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"早停\"><a href=\"#早停\" class=\"headerlink\" title=\"早停\"></a>早停</h2><blockquote>\n<p>如果你有验证集，则可以使用早停机制来寻找最佳的 <code>num_round</code>, 需要将 验证集传入 <code>evals</code>,如果传入多个，则使用最后一个。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train(..., evals=evals, early_stopping_rounds=10)</span><br></pre></td></tr></table></figure></p>\n</blockquote>\n<p>如果模型在 <code>early_stopping_rounds</code>次，监控的参数 <code>param[&#39;eval_metric&#39;]</code> 都没有提升，则会停止训练，<code>train</code> 返回的是最后一次训练的模型，而不是最佳模型，最佳模型可以通过一下方式找到：</p>\n<ul>\n<li><code>bst.best_score</code></li>\n<li><code>bst.best_iteration</code></li>\n<li><code>bst.best_ntree_limit</code>  # 使用最佳模型</li>\n</ul>\n<p>同样的，监控多个参数时，最后一个参数起早停的作用。</p>\n<h2 id=\"预测\"><a href=\"#预测\" class=\"headerlink\" title=\"预测\"></a>预测</h2><p>已经训练好的模型，或者已经加载的模型可以拿来预测新数据：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data = np.random.rand(7, 10)</span><br><span class=\"line\">dtest = xgb.DMatrix(data)</span><br><span class=\"line\">ypred = bst.predict(dtest)</span><br></pre></td></tr></table></figure></p>\n<p>使用最佳的迭代次数的模型：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ypred = bst.predict(dtest, ntree_limit=bst.best_ntree_limit)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"绘制\"><a href=\"#绘制\" class=\"headerlink\" title=\"绘制\"></a>绘制</h2><p>你可以使用绘图模块来画出树结构：</p>\n<ul>\n<li>绘制参数重要性</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xgb.plot_importance(bst)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>绘制目标树</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xgb.plot_tree(bst, num_trees=2)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>Ipython 中绘制树</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xgb.to_graphviz(bst, num_trees=2)</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"xgboost-学习笔记\"><a href=\"#xgboost-学习笔记\" class=\"headerlink\" title=\"xgboost 学习笔记\"></a>xgboost 学习笔记</h1><blockquote>\n<p>主要内容均来自官方文档，官方文档是英文版，所以简单的翻译了一下，方便日后查看。<br><a href=\"https://xgboost.readthedocs.io/en/latest/python/python_intro.html\" target=\"_blank\" rel=\"noopener\">详细内容见官方手册</a></p>\n<h2 id=\"安装-XGBoost\"><a href=\"#安装-XGBoost\" class=\"headerlink\" title=\"安装 XGBoost\"></a>安装 XGBoost</h2></blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ubuntu -python3:</span><br><span class=\"line\">    pip3 install xgboost</span><br><span class=\"line\"> </span><br><span class=\"line\">导入:</span><br><span class=\"line\">    import xgboost as xgb</span><br></pre></td></tr></table></figure>\n<h2 id=\"数据接口\"><a href=\"#数据接口\" class=\"headerlink\" title=\"数据接口\"></a>数据接口</h2><p><code>XGBoost</code> 可以从以下结构中加载数据：</p>\n<ul>\n<li>LibSVM text format file</li>\n<li>CSV</li>\n<li>Numpy 2D array</li>\n<li>Scipy 2D sparse array</li>\n<li>Pandas</li>\n<li>XGBoost binary buffer file.</li>\n</ul>\n<p>加载的数据都放在 <code>DMatrix</code>对象中，下面是具体加载的过程演示：</p>\n<ul>\n<li><p>LibSVM text format file</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dtrain = xgb.DMatrix(<span class=\"string\">'train.svm.txt'</span>)</span><br><span class=\"line\">dtest = xgb.DMatrix(<span class=\"string\">'test.svm.buffer'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>CSV</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 需要指定标签所在的列</span><br><span class=\"line\">dtrain = xgb.DMatrix(<span class=\"string\">'train.csv?format=csv&amp;label_column=0'</span>)</span><br><span class=\"line\">dtest = xgb.DMatrix(<span class=\"string\">'test.csv?format=csv&amp;label_column=0'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<font color=\"#FF0000\"> \n\n XGBoost 不支持种类特征，需要先加载为Numpy数组，然后进行 `one-hot` 编码;推荐使用pandas 加载数据.\n</font> \n\n<ul>\n<li><p>Numpy</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data = np.random.rand(<span class=\"number\">5</span>, <span class=\"number\">10</span>)  <span class=\"comment\"># 5个样本，每个样本10个特征</span></span><br><span class=\"line\">label = np.random.randint(<span class=\"number\">2</span>, size=<span class=\"number\">5</span>)  <span class=\"comment\"># 二值标签</span></span><br><span class=\"line\"></span><br><span class=\"line\">dtrain = xgb.DMatrix(data, label=label)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Scipy</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">csr = scipy.sparse.csr_matrix((dat, (row, col)))</span><br><span class=\"line\">dtrain = xgb.DMatrix(csr)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Pandas</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data = pandas.DataFrame(np.arange(<span class=\"number\">12</span>).reshape((<span class=\"number\">4</span>,<span class=\"number\">3</span>)), columns=[<span class=\"string\">'a'</span>, <span class=\"string\">'b'</span>, <span class=\"string\">'c'</span>])</span><br><span class=\"line\">label = pandas.DataFrame(np.random.randint(<span class=\"number\">2</span>, size=<span class=\"number\">4</span>))</span><br><span class=\"line\">dtrain = xgb.DMatrix(data, label=label)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>保存为 XGBoost 二进制文件</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dtrain = xgb.DMatrix(<span class=\"string\">'train.svm.txt'</span>)</span><br><span class=\"line\">dtrain.save_binary(<span class=\"string\">'train.buffer'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>缺失值处理</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">dtrain = xgb.DMatrix(data, label=label, missing=<span class=\"number\">-999.0</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>样本权重</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">w = np.random.rand(5, 1)</span><br><span class=\"line\">dtrain = xgb.DMatrix(data, label=label, missing=-999.0, weight=w)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"参数设置\"><a href=\"#参数设置\" class=\"headerlink\" title=\"参数设置\"></a>参数设置</h2><blockquote>\n<p>XGBoost 可以通过列表或者字典来设置参数，例如：</p>\n</blockquote>\n<ul>\n<li><p>Booster 参数</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">param = &#123;<span class=\"string\">'max_depth'</span>: <span class=\"number\">2</span>, <span class=\"string\">'eta'</span>: <span class=\"number\">1</span>, <span class=\"string\">'objective'</span>: <span class=\"string\">'binary:logistic'</span>&#125;</span><br><span class=\"line\">param[<span class=\"string\">'nthread'</span>] = <span class=\"number\">4</span></span><br><span class=\"line\">param[<span class=\"string\">'eval_metric'</span>] = <span class=\"string\">'auc'</span></span><br></pre></td></tr></table></figure>\n</li>\n<li><p>指定多个评估指标</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">param[<span class=\"string\">'eval_metric'</span>] = [<span class=\"string\">'auc'</span>, <span class=\"string\">'ams@0'</span>]</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>指定验证集来监视性能</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">evallist = [(dtest, <span class=\"string\">'eval'</span>), (dtrain, <span class=\"string\">'train'</span>)]</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"训练\"><a href=\"#训练\" class=\"headerlink\" title=\"训练\"></a>训练</h2><ul>\n<li><p>模型训练</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">num_round = 10</span><br><span class=\"line\">bst = xgb.train(param, dtrain, num_round, evallist)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>模型保存</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bst.save_model(<span class=\"string\">'0001.model'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>保存模型和特征</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># dump model</span></span><br><span class=\"line\">bst.dump_model(<span class=\"string\">'dump.raw.txt'</span>)</span><br><span class=\"line\"><span class=\"comment\"># dump model with feature map</span></span><br><span class=\"line\">bst.dump_model(<span class=\"string\">'dump.raw.txt'</span>, <span class=\"string\">'featmap.txt'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>模型加载</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bst = xgb.Booster(&#123;&apos;nthread&apos;: 4&#125;)  # init model</span><br><span class=\"line\">bst.load_model(&apos;model.bin&apos;)  # load data</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"早停\"><a href=\"#早停\" class=\"headerlink\" title=\"早停\"></a>早停</h2><blockquote>\n<p>如果你有验证集，则可以使用早停机制来寻找最佳的 <code>num_round</code>, 需要将 验证集传入 <code>evals</code>,如果传入多个，则使用最后一个。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">train(..., evals=evals, early_stopping_rounds=10)</span><br></pre></td></tr></table></figure></p>\n</blockquote>\n<p>如果模型在 <code>early_stopping_rounds</code>次，监控的参数 <code>param[&#39;eval_metric&#39;]</code> 都没有提升，则会停止训练，<code>train</code> 返回的是最后一次训练的模型，而不是最佳模型，最佳模型可以通过一下方式找到：</p>\n<ul>\n<li><code>bst.best_score</code></li>\n<li><code>bst.best_iteration</code></li>\n<li><code>bst.best_ntree_limit</code>  # 使用最佳模型</li>\n</ul>\n<p>同样的，监控多个参数时，最后一个参数起早停的作用。</p>\n<h2 id=\"预测\"><a href=\"#预测\" class=\"headerlink\" title=\"预测\"></a>预测</h2><p>已经训练好的模型，或者已经加载的模型可以拿来预测新数据：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">data = np.random.rand(7, 10)</span><br><span class=\"line\">dtest = xgb.DMatrix(data)</span><br><span class=\"line\">ypred = bst.predict(dtest)</span><br></pre></td></tr></table></figure></p>\n<p>使用最佳的迭代次数的模型：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ypred = bst.predict(dtest, ntree_limit=bst.best_ntree_limit)</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"绘制\"><a href=\"#绘制\" class=\"headerlink\" title=\"绘制\"></a>绘制</h2><p>你可以使用绘图模块来画出树结构：</p>\n<ul>\n<li>绘制参数重要性</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xgb.plot_importance(bst)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>绘制目标树</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xgb.plot_tree(bst, num_trees=2)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>Ipython 中绘制树</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xgb.to_graphviz(bst, num_trees=2)</span><br></pre></td></tr></table></figure>"},{"title":"pandas-7时间&日期处理","mathjax":true,"date":"2019-08-06T00:42:00.000Z","_content":"\n# pandas -7 时间&日期处理\n\n\n## pandas 常出现的时间格式\n\n- 字符串类型 `object`\n\n> 一般是字符串类型，pandas 储存string时 使用 narray， 每一个object 是一个指针\n\n- datetime 类型 `datetime64`\n\n\n- timedelta 类型\n\n> 表示时间差的数据类型\n\n## 类型转换\n\n1. ` object` 2 `datetime`\n\n```\n    // 方法1\n    df[1] = pd.to_datetime(df[1], format='%d.%m.%Y')\n    \n    # 指定format，速度会加快很多。\n    \n    // 方法2\n    dateStr = \"2019-02-03\"\n    \n    myDate = datetime.strptime(dateStr, \"\"%Y-%m-%d\"\")\n\n```\n2. `datetime` 2 `object`\n\n```\n    df[\"time_list\"] = df[\"time_list\"].strftime(\"%Y-%m-%d\")\n    \n    // Y 2019\n    // y  19\n    \n```\n\n## datetime 相关操作\n\n```\n    // 查看列元素的年，月，日，星期（整数型）\n    df[\"time\"].dt.year\n    df[\"time\"].dt.month\n    df[\"time\"].dt.day\n    df[\"time\"].dt.weekday  # 星期一是0\n    \n    // 一年中的第几天,第几周\n    df[\"time\"].dt.dayofyear\n    df[\"time\"].dt.weekofyear\n    // 查看列元素 某年的数据数量\n    df[df[\"time\"].dt.year == 2019].shape\n    \n    \n```\n## 时间运算\n\n1. 计算时间差\n\n```\n    // 计算时间差， 结果为timedelta\n    df[\"时间差\"] = df[\"时间1\"] - df[\"时间2\"]\n    \n    // 转换成 天数差\n    df[\"时间差\"].days\n```\n\n2. 计算未来日期\n\n```\n    // N天后的日期\n    // 天  days,   时 hours， 周 weeks\n    df[\"时间\"] = df[\"时间1\"] - timedelta(days=10)\n```\n\n\n\n\n","source":"_posts/pandas-时间-日期处理.md","raw":"---\ntitle: pandas-7时间&日期处理\nmathjax: true\ndate: 2019-08-06 08:42:00\ncategories: pandas系列教程\ntags: pandas\n---\n\n# pandas -7 时间&日期处理\n\n\n## pandas 常出现的时间格式\n\n- 字符串类型 `object`\n\n> 一般是字符串类型，pandas 储存string时 使用 narray， 每一个object 是一个指针\n\n- datetime 类型 `datetime64`\n\n\n- timedelta 类型\n\n> 表示时间差的数据类型\n\n## 类型转换\n\n1. ` object` 2 `datetime`\n\n```\n    // 方法1\n    df[1] = pd.to_datetime(df[1], format='%d.%m.%Y')\n    \n    # 指定format，速度会加快很多。\n    \n    // 方法2\n    dateStr = \"2019-02-03\"\n    \n    myDate = datetime.strptime(dateStr, \"\"%Y-%m-%d\"\")\n\n```\n2. `datetime` 2 `object`\n\n```\n    df[\"time_list\"] = df[\"time_list\"].strftime(\"%Y-%m-%d\")\n    \n    // Y 2019\n    // y  19\n    \n```\n\n## datetime 相关操作\n\n```\n    // 查看列元素的年，月，日，星期（整数型）\n    df[\"time\"].dt.year\n    df[\"time\"].dt.month\n    df[\"time\"].dt.day\n    df[\"time\"].dt.weekday  # 星期一是0\n    \n    // 一年中的第几天,第几周\n    df[\"time\"].dt.dayofyear\n    df[\"time\"].dt.weekofyear\n    // 查看列元素 某年的数据数量\n    df[df[\"time\"].dt.year == 2019].shape\n    \n    \n```\n## 时间运算\n\n1. 计算时间差\n\n```\n    // 计算时间差， 结果为timedelta\n    df[\"时间差\"] = df[\"时间1\"] - df[\"时间2\"]\n    \n    // 转换成 天数差\n    df[\"时间差\"].days\n```\n\n2. 计算未来日期\n\n```\n    // N天后的日期\n    // 天  days,   时 hours， 周 weeks\n    df[\"时间\"] = df[\"时间1\"] - timedelta(days=10)\n```\n\n\n\n\n","slug":"pandas-时间-日期处理","published":1,"updated":"2019-09-11T06:20:37.932Z","_id":"cjz98jgz6000ly0plme5zjmqa","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"pandas-7-时间-amp-日期处理\"><a href=\"#pandas-7-时间-amp-日期处理\" class=\"headerlink\" title=\"pandas -7 时间&amp;日期处理\"></a>pandas -7 时间&amp;日期处理</h1><h2 id=\"pandas-常出现的时间格式\"><a href=\"#pandas-常出现的时间格式\" class=\"headerlink\" title=\"pandas 常出现的时间格式\"></a>pandas 常出现的时间格式</h2><ul>\n<li>字符串类型 <code>object</code></li>\n</ul>\n<blockquote>\n<p>一般是字符串类型，pandas 储存string时 使用 narray， 每一个object 是一个指针</p>\n</blockquote>\n<ul>\n<li>datetime 类型 <code>datetime64</code></li>\n</ul>\n<ul>\n<li>timedelta 类型</li>\n</ul>\n<blockquote>\n<p>表示时间差的数据类型</p>\n</blockquote>\n<h2 id=\"类型转换\"><a href=\"#类型转换\" class=\"headerlink\" title=\"类型转换\"></a>类型转换</h2><ol>\n<li><code>object</code> 2 <code>datetime</code></li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 方法1</span><br><span class=\"line\">df[1] = pd.to_datetime(df[1], format=&apos;%d.%m.%Y&apos;)</span><br><span class=\"line\"></span><br><span class=\"line\"># 指定format，速度会加快很多。</span><br><span class=\"line\"></span><br><span class=\"line\">// 方法2</span><br><span class=\"line\">dateStr = &quot;2019-02-03&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">myDate = datetime.strptime(dateStr, &quot;&quot;%Y-%m-%d&quot;&quot;)</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>datetime</code> 2 <code>object</code></li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df[&quot;time_list&quot;] = df[&quot;time_list&quot;].strftime(&quot;%Y-%m-%d&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">// Y 2019</span><br><span class=\"line\">// y  19</span><br></pre></td></tr></table></figure>\n<h2 id=\"datetime-相关操作\"><a href=\"#datetime-相关操作\" class=\"headerlink\" title=\"datetime 相关操作\"></a>datetime 相关操作</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 查看列元素的年，月，日，星期（整数型）</span><br><span class=\"line\">df[&quot;time&quot;].dt.year</span><br><span class=\"line\">df[&quot;time&quot;].dt.month</span><br><span class=\"line\">df[&quot;time&quot;].dt.day</span><br><span class=\"line\">df[&quot;time&quot;].dt.weekday  # 星期一是0</span><br><span class=\"line\"></span><br><span class=\"line\">// 一年中的第几天,第几周</span><br><span class=\"line\">df[&quot;time&quot;].dt.dayofyear</span><br><span class=\"line\">df[&quot;time&quot;].dt.weekofyear</span><br><span class=\"line\">// 查看列元素 某年的数据数量</span><br><span class=\"line\">df[df[&quot;time&quot;].dt.year == 2019].shape</span><br></pre></td></tr></table></figure>\n<h2 id=\"时间运算\"><a href=\"#时间运算\" class=\"headerlink\" title=\"时间运算\"></a>时间运算</h2><ol>\n<li>计算时间差</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 计算时间差， 结果为timedelta</span><br><span class=\"line\">df[&quot;时间差&quot;] = df[&quot;时间1&quot;] - df[&quot;时间2&quot;]</span><br><span class=\"line\"></span><br><span class=\"line\">// 转换成 天数差</span><br><span class=\"line\">df[&quot;时间差&quot;].days</span><br></pre></td></tr></table></figure>\n<ol>\n<li>计算未来日期</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// N天后的日期</span><br><span class=\"line\">// 天  days,   时 hours， 周 weeks</span><br><span class=\"line\">df[&quot;时间&quot;] = df[&quot;时间1&quot;] - timedelta(days=10)</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"pandas-7-时间-amp-日期处理\"><a href=\"#pandas-7-时间-amp-日期处理\" class=\"headerlink\" title=\"pandas -7 时间&amp;日期处理\"></a>pandas -7 时间&amp;日期处理</h1><h2 id=\"pandas-常出现的时间格式\"><a href=\"#pandas-常出现的时间格式\" class=\"headerlink\" title=\"pandas 常出现的时间格式\"></a>pandas 常出现的时间格式</h2><ul>\n<li>字符串类型 <code>object</code></li>\n</ul>\n<blockquote>\n<p>一般是字符串类型，pandas 储存string时 使用 narray， 每一个object 是一个指针</p>\n</blockquote>\n<ul>\n<li>datetime 类型 <code>datetime64</code></li>\n</ul>\n<ul>\n<li>timedelta 类型</li>\n</ul>\n<blockquote>\n<p>表示时间差的数据类型</p>\n</blockquote>\n<h2 id=\"类型转换\"><a href=\"#类型转换\" class=\"headerlink\" title=\"类型转换\"></a>类型转换</h2><ol>\n<li><code>object</code> 2 <code>datetime</code></li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 方法1</span><br><span class=\"line\">df[1] = pd.to_datetime(df[1], format=&apos;%d.%m.%Y&apos;)</span><br><span class=\"line\"></span><br><span class=\"line\"># 指定format，速度会加快很多。</span><br><span class=\"line\"></span><br><span class=\"line\">// 方法2</span><br><span class=\"line\">dateStr = &quot;2019-02-03&quot;</span><br><span class=\"line\"></span><br><span class=\"line\">myDate = datetime.strptime(dateStr, &quot;&quot;%Y-%m-%d&quot;&quot;)</span><br></pre></td></tr></table></figure>\n<ol>\n<li><code>datetime</code> 2 <code>object</code></li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df[&quot;time_list&quot;] = df[&quot;time_list&quot;].strftime(&quot;%Y-%m-%d&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">// Y 2019</span><br><span class=\"line\">// y  19</span><br></pre></td></tr></table></figure>\n<h2 id=\"datetime-相关操作\"><a href=\"#datetime-相关操作\" class=\"headerlink\" title=\"datetime 相关操作\"></a>datetime 相关操作</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 查看列元素的年，月，日，星期（整数型）</span><br><span class=\"line\">df[&quot;time&quot;].dt.year</span><br><span class=\"line\">df[&quot;time&quot;].dt.month</span><br><span class=\"line\">df[&quot;time&quot;].dt.day</span><br><span class=\"line\">df[&quot;time&quot;].dt.weekday  # 星期一是0</span><br><span class=\"line\"></span><br><span class=\"line\">// 一年中的第几天,第几周</span><br><span class=\"line\">df[&quot;time&quot;].dt.dayofyear</span><br><span class=\"line\">df[&quot;time&quot;].dt.weekofyear</span><br><span class=\"line\">// 查看列元素 某年的数据数量</span><br><span class=\"line\">df[df[&quot;time&quot;].dt.year == 2019].shape</span><br></pre></td></tr></table></figure>\n<h2 id=\"时间运算\"><a href=\"#时间运算\" class=\"headerlink\" title=\"时间运算\"></a>时间运算</h2><ol>\n<li>计算时间差</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 计算时间差， 结果为timedelta</span><br><span class=\"line\">df[&quot;时间差&quot;] = df[&quot;时间1&quot;] - df[&quot;时间2&quot;]</span><br><span class=\"line\"></span><br><span class=\"line\">// 转换成 天数差</span><br><span class=\"line\">df[&quot;时间差&quot;].days</span><br></pre></td></tr></table></figure>\n<ol>\n<li>计算未来日期</li>\n</ol>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// N天后的日期</span><br><span class=\"line\">// 天  days,   时 hours， 周 weeks</span><br><span class=\"line\">df[&quot;时间&quot;] = df[&quot;时间1&quot;] - timedelta(days=10)</span><br></pre></td></tr></table></figure>\n"},{"title":"决策树-1基本概念","date":"2019-04-20T10:09:10.000Z","top":true,"_content":"\n\n# 决策树1- 基本概念\n\n## 决策树\n\n![logo](决策树-1基本概念/tree.png)\n\n上图来自西瓜书，是决策树的一种树形。生成决策树的过程，不断的**根据样本的属性( 样本的某个特征 )划分样本子集**。每个结点选择当前最优的属性作为划分依据，将样本集合不断的划分成更小的子集合，直到子集合中样本类别一致时或者没有可以划分的属性值时，则停止划分，标记为叶结点(叶节点代表一个类别)。\n\n简单的介绍一下决策树的组成元素:\n\n1. 根节点:  所有的训练样本\n2. 内部节点:   对应某一个划分属性\n3. 叶节点：   对应某一种决策结果\n4. 判定测试序列：   某个样本在节点中传递的路径\n\n所有节点都包含着不同数量的样本。\n\n> 以上是分类树的例子，决策树也可以用作回归任务，如CART算法。决策树是GBDT,Xgboost等更高级结构的基础，所以尽量要掌握决策树的原理。\n\n\n## 决策树算法的基本流程\n\n假设有一个数据集，其中的每个样本有多种特征，每个特征有不同的取值。通过这个数据集来生成一个决策树的一般流程可以归纳为:\n\n- 特征选择\n\n> 特征选择就是决策树分叉时，依据新节点的\"纯度\"，选择最优的划分属性;\n\n- 决策树生成\n\n> 树不断的分叉，直到样本的属性用光，或者树的深度达到了预定值，则结束分叉;\n\n- 剪枝\n\n> 如果一直树杈分下去，一定能够使得所有的样本都正确的归类，但这样会产生对训练集的过拟合，泛化能力变差，可以通过剪枝操作来改善泛化能力。\n\n通过这三步，就可以生成一颗决策树了。下面来学习一下具体怎么进行特征的选择和剪枝。\n\n\n## 如何选择最优的划分属性(分类树)?\n\n> 决策树不断分叉的原因，是尽可能的让不同类别的样本划分到不同的节点，同类别的样本划分到同一个节点。而选择最优的划分属性（特征）的过程，相当于是遍历计算出所有特征的结果，找到能使分叉后子集合最 \"纯\" 的特征，就是最优的划分属性了。\n所以，该如何定义 \"纯\" ，需要借助信息论中 \"信息熵\" 的概念了。\n\n**熵** :  表示随机变量不确定性的度量,也就是混乱程度的一种度量。\n\n假定数据集 `D` 中第 `K` 类样本所占的比例为 $$p_{k}$$,则信息熵定义为:\n\n$$\n\\operatorname{Ent}(D)=-\\sum_{k=1}^{N} p_{k} \\log _{2} p_{k}\n$$\n\n数据集包含的<font color=\"#FF0000\">类别越少时越纯，`Ent(D)`也越小。</font> \n\n### 法1: 信息增益\n\n==ID3算法用到信息增益==\n\n> 直白的讲就是决策树分叉前的信息熵减去分叉后的信息熵。\n\n> 信息增益最大的特征就是最佳划分属性。\n\n假定分叉前样本集 `D` 中的特征 `a` 有 `V`个可能的取值 $$\\left\\{a^{1}, a^{2}, \\ldots, a^{V}\\right\\}$$ ,当选择 `a` 做划分属性时，会分`V`个节点，每个节点上的子样本集合为 $$D^{v}$$,同时为不同节点赋权重(按照样本的比例)，于是信息增益为: \n\n$$\\operatorname{Gain}(D, a)=\\operatorname{Ent}(D)-\\sum_{v=1}^{V} \\frac{\\left|D^{v}\\right|}{|D|} \\operatorname{Ent}\\left(D^{v}\\right)$$\n\n减数部分也叫<font color=\"#FF0000\"> 条件熵 </font>\n\n<font color=\"#FF0000\">缺点:</font> 分叉时偏好取值较多的属性。\n\n<font color=\"#FF0000\">原因分析:</font>\n\n1. 取值多的特征，样本更分散，所有得到的新节点\"纯度\" 趋于更高，熵更低，而划分前的增益不变的情况下，该特征增益更大。\n2. 比如，当特征的可能取值数量正好等于样本数量，那条件熵几乎为0，该特征一定会被选择。\n\n### 法2: 信息增益率\n\n==C4.5算法用到信息增率==\n\n> 相当于在法1基础上，增加了惩罚系数，可取值越多，系数越大。\n\n$$Gain\\_ratio\\left( D,a \\right) =\\frac{Gain\\left( D,a \\right)}{IV\\left( a \\right)}$$\n\n$$\\mathrm{IV}(a)=-\\sum_{v=1}^{V} \\frac{\\left|D^{v}\\right|}{|D|} \\log _{2} \\frac{\\left|D^{v}\\right|}{|D|}$$\n\n\n`IV(a)` 是属性 `a` 的 \"固有值\"，内部属性。\n\n<font color=\"#FF0000\">缺点:</font> 分叉时偏好取值较少的属性。\n\n\n### 法3：基尼指数\n\n==CART决策树算法用到基尼指数==\n\n> 反应从节点样本集合中随机抽取两个样本，类别不一致的概率。CART决策树默认为二叉树。\n\n基尼值的定义:\n\n$$\n\\operatorname{Gini}(D)=\\sum_{k=1}^{|y|} \\sum_{k^{\\prime}=k} p_{k} p_{k^{\\prime}}\n$$\n\n\n$$=\\sum_{k=1}^{|y|} p_{k}\\left(1-P_{k}\\right)$$\n\n$$=1-\\sum_{k=1}^{|\\mathcal{Y}|} p_{k}^{2}$$\n\n\n选择特征 `A` 的情况下，针对 `A` 所有可能取值 `a`, 分别计算基尼指数：\n\n$$Gini\\_index\\left( D,a \\right) =\\sum_{v=1}^V{\\frac{\\left| D^v \\right|}{|D|}}\\text{}Gini\\left( D^v \\right) $$\n\n选择基尼指数最小的特征和切分点，作为最优划分属性。\n\n\n\n三种决策树模型：\n\n算法 | 特征选择标准\n---|---\nID3 | 信息增益\nC4.5 | 信息增益率\nCART | 基尼指数\n\n\n\n## 对抗过拟合 -- 剪枝处理\n\n> 分支太多，容易过拟合，泛化能力变差。所以要适当剪枝，常用方法是**预剪枝**和**后剪枝**\n\n> 剪枝操作包括的点也很多，这里只是简单描述一下，详细的参考未来的博客。[www.elgong.top](www.elgong.top)\n\n### 预剪枝\n\n\n1. 预剪枝是在决策树生成的过程中，对每个结点在划分前先估计，根据划分前后验证集的精度，来决定是否划分；\n\n\n2. 只能估计当前结点可划分性，不能预测到未来节点划分的必要性，是贪心算法；\n\n\n3. 容易造成欠拟合。\n\n### 后剪枝\n\n1. 先生成完整的树，再从叶结点往回计算，根据验证集精度是否提升决定是否剪枝；\n\n\n2. 泛化能力往往优于预剪枝，欠拟合风险小；\n\n\n3. 时间开销大。\n\n\n## 属性为连续值时？\n\n> C4.5 算法采用二分法将连续值离散化\n\n> 与离散属性不同，连续的属性可以在后代节点中再次使用\n\n\n\n## 当数据中含有缺失值时？\n\n处理方法：\n\n通过无缺失数据计算出三个参数：\n\n1. 无缺失样本占总样本比例 \n2. 无缺失样中 `K类别` 占比 `pk`\n3. 无缺失样本中 `v 属性`样本占比 `rv`\n\n对单样本增加一个权值 `Wx`, 无缺失样本的`Wx = 1`，  有缺失样本的`Wx = rv*Wx `。\n\n在计算分支时，**同一样本以不同的概率划分到不同的子节点中**\n\n- 当样本的属性已知：则把该样本划分进对应的子节点，权值=1；\n\n\n- 当样本的该属性缺失：则把该样本同时划入所有的子节点，样本权值需要更新为`Wx = rv*Wx。\n\n\n## 决策树的优缺点\n\n==优点==：\n\n- 便于理解和可视化；\n- 训练需要的数据少，不需要对数据进行规范化；\n- 可同时处理数值型，类别型数据；\n- 是白盒模型，可解释；\n\n==缺点==：\n\n- 容易产生过于复杂的模型 -> 泛化能力差 （剪枝，限制叶节点所需要的最小样本数，最大深度）\n- 决策树不稳定，微小变化会产生不同的树（集成多棵树可以缓解）\n- 难学NP问题（启发式学习）\n- 异或，奇偶，很难被学习到\n\n\n\n","source":"_posts/决策树-1基本概念.md","raw":"---\ntitle: 决策树-1基本概念\ndate: 2019-04-20 18:09:10\ncategories: 机器学习方法\ntags: 决策树\ntop: True\n---\n\n\n# 决策树1- 基本概念\n\n## 决策树\n\n![logo](决策树-1基本概念/tree.png)\n\n上图来自西瓜书，是决策树的一种树形。生成决策树的过程，不断的**根据样本的属性( 样本的某个特征 )划分样本子集**。每个结点选择当前最优的属性作为划分依据，将样本集合不断的划分成更小的子集合，直到子集合中样本类别一致时或者没有可以划分的属性值时，则停止划分，标记为叶结点(叶节点代表一个类别)。\n\n简单的介绍一下决策树的组成元素:\n\n1. 根节点:  所有的训练样本\n2. 内部节点:   对应某一个划分属性\n3. 叶节点：   对应某一种决策结果\n4. 判定测试序列：   某个样本在节点中传递的路径\n\n所有节点都包含着不同数量的样本。\n\n> 以上是分类树的例子，决策树也可以用作回归任务，如CART算法。决策树是GBDT,Xgboost等更高级结构的基础，所以尽量要掌握决策树的原理。\n\n\n## 决策树算法的基本流程\n\n假设有一个数据集，其中的每个样本有多种特征，每个特征有不同的取值。通过这个数据集来生成一个决策树的一般流程可以归纳为:\n\n- 特征选择\n\n> 特征选择就是决策树分叉时，依据新节点的\"纯度\"，选择最优的划分属性;\n\n- 决策树生成\n\n> 树不断的分叉，直到样本的属性用光，或者树的深度达到了预定值，则结束分叉;\n\n- 剪枝\n\n> 如果一直树杈分下去，一定能够使得所有的样本都正确的归类，但这样会产生对训练集的过拟合，泛化能力变差，可以通过剪枝操作来改善泛化能力。\n\n通过这三步，就可以生成一颗决策树了。下面来学习一下具体怎么进行特征的选择和剪枝。\n\n\n## 如何选择最优的划分属性(分类树)?\n\n> 决策树不断分叉的原因，是尽可能的让不同类别的样本划分到不同的节点，同类别的样本划分到同一个节点。而选择最优的划分属性（特征）的过程，相当于是遍历计算出所有特征的结果，找到能使分叉后子集合最 \"纯\" 的特征，就是最优的划分属性了。\n所以，该如何定义 \"纯\" ，需要借助信息论中 \"信息熵\" 的概念了。\n\n**熵** :  表示随机变量不确定性的度量,也就是混乱程度的一种度量。\n\n假定数据集 `D` 中第 `K` 类样本所占的比例为 $$p_{k}$$,则信息熵定义为:\n\n$$\n\\operatorname{Ent}(D)=-\\sum_{k=1}^{N} p_{k} \\log _{2} p_{k}\n$$\n\n数据集包含的<font color=\"#FF0000\">类别越少时越纯，`Ent(D)`也越小。</font> \n\n### 法1: 信息增益\n\n==ID3算法用到信息增益==\n\n> 直白的讲就是决策树分叉前的信息熵减去分叉后的信息熵。\n\n> 信息增益最大的特征就是最佳划分属性。\n\n假定分叉前样本集 `D` 中的特征 `a` 有 `V`个可能的取值 $$\\left\\{a^{1}, a^{2}, \\ldots, a^{V}\\right\\}$$ ,当选择 `a` 做划分属性时，会分`V`个节点，每个节点上的子样本集合为 $$D^{v}$$,同时为不同节点赋权重(按照样本的比例)，于是信息增益为: \n\n$$\\operatorname{Gain}(D, a)=\\operatorname{Ent}(D)-\\sum_{v=1}^{V} \\frac{\\left|D^{v}\\right|}{|D|} \\operatorname{Ent}\\left(D^{v}\\right)$$\n\n减数部分也叫<font color=\"#FF0000\"> 条件熵 </font>\n\n<font color=\"#FF0000\">缺点:</font> 分叉时偏好取值较多的属性。\n\n<font color=\"#FF0000\">原因分析:</font>\n\n1. 取值多的特征，样本更分散，所有得到的新节点\"纯度\" 趋于更高，熵更低，而划分前的增益不变的情况下，该特征增益更大。\n2. 比如，当特征的可能取值数量正好等于样本数量，那条件熵几乎为0，该特征一定会被选择。\n\n### 法2: 信息增益率\n\n==C4.5算法用到信息增率==\n\n> 相当于在法1基础上，增加了惩罚系数，可取值越多，系数越大。\n\n$$Gain\\_ratio\\left( D,a \\right) =\\frac{Gain\\left( D,a \\right)}{IV\\left( a \\right)}$$\n\n$$\\mathrm{IV}(a)=-\\sum_{v=1}^{V} \\frac{\\left|D^{v}\\right|}{|D|} \\log _{2} \\frac{\\left|D^{v}\\right|}{|D|}$$\n\n\n`IV(a)` 是属性 `a` 的 \"固有值\"，内部属性。\n\n<font color=\"#FF0000\">缺点:</font> 分叉时偏好取值较少的属性。\n\n\n### 法3：基尼指数\n\n==CART决策树算法用到基尼指数==\n\n> 反应从节点样本集合中随机抽取两个样本，类别不一致的概率。CART决策树默认为二叉树。\n\n基尼值的定义:\n\n$$\n\\operatorname{Gini}(D)=\\sum_{k=1}^{|y|} \\sum_{k^{\\prime}=k} p_{k} p_{k^{\\prime}}\n$$\n\n\n$$=\\sum_{k=1}^{|y|} p_{k}\\left(1-P_{k}\\right)$$\n\n$$=1-\\sum_{k=1}^{|\\mathcal{Y}|} p_{k}^{2}$$\n\n\n选择特征 `A` 的情况下，针对 `A` 所有可能取值 `a`, 分别计算基尼指数：\n\n$$Gini\\_index\\left( D,a \\right) =\\sum_{v=1}^V{\\frac{\\left| D^v \\right|}{|D|}}\\text{}Gini\\left( D^v \\right) $$\n\n选择基尼指数最小的特征和切分点，作为最优划分属性。\n\n\n\n三种决策树模型：\n\n算法 | 特征选择标准\n---|---\nID3 | 信息增益\nC4.5 | 信息增益率\nCART | 基尼指数\n\n\n\n## 对抗过拟合 -- 剪枝处理\n\n> 分支太多，容易过拟合，泛化能力变差。所以要适当剪枝，常用方法是**预剪枝**和**后剪枝**\n\n> 剪枝操作包括的点也很多，这里只是简单描述一下，详细的参考未来的博客。[www.elgong.top](www.elgong.top)\n\n### 预剪枝\n\n\n1. 预剪枝是在决策树生成的过程中，对每个结点在划分前先估计，根据划分前后验证集的精度，来决定是否划分；\n\n\n2. 只能估计当前结点可划分性，不能预测到未来节点划分的必要性，是贪心算法；\n\n\n3. 容易造成欠拟合。\n\n### 后剪枝\n\n1. 先生成完整的树，再从叶结点往回计算，根据验证集精度是否提升决定是否剪枝；\n\n\n2. 泛化能力往往优于预剪枝，欠拟合风险小；\n\n\n3. 时间开销大。\n\n\n## 属性为连续值时？\n\n> C4.5 算法采用二分法将连续值离散化\n\n> 与离散属性不同，连续的属性可以在后代节点中再次使用\n\n\n\n## 当数据中含有缺失值时？\n\n处理方法：\n\n通过无缺失数据计算出三个参数：\n\n1. 无缺失样本占总样本比例 \n2. 无缺失样中 `K类别` 占比 `pk`\n3. 无缺失样本中 `v 属性`样本占比 `rv`\n\n对单样本增加一个权值 `Wx`, 无缺失样本的`Wx = 1`，  有缺失样本的`Wx = rv*Wx `。\n\n在计算分支时，**同一样本以不同的概率划分到不同的子节点中**\n\n- 当样本的属性已知：则把该样本划分进对应的子节点，权值=1；\n\n\n- 当样本的该属性缺失：则把该样本同时划入所有的子节点，样本权值需要更新为`Wx = rv*Wx。\n\n\n## 决策树的优缺点\n\n==优点==：\n\n- 便于理解和可视化；\n- 训练需要的数据少，不需要对数据进行规范化；\n- 可同时处理数值型，类别型数据；\n- 是白盒模型，可解释；\n\n==缺点==：\n\n- 容易产生过于复杂的模型 -> 泛化能力差 （剪枝，限制叶节点所需要的最小样本数，最大深度）\n- 决策树不稳定，微小变化会产生不同的树（集成多棵树可以缓解）\n- 难学NP问题（启发式学习）\n- 异或，奇偶，很难被学习到\n\n\n\n","slug":"决策树-1基本概念","published":1,"updated":"2019-08-04T13:00:28.036Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz98jgza000qy0pl7i4mlotz","content":"<h1 id=\"决策树1-基本概念\"><a href=\"#决策树1-基本概念\" class=\"headerlink\" title=\"决策树1- 基本概念\"></a>决策树1- 基本概念</h1><h2 id=\"决策树\"><a href=\"#决策树\" class=\"headerlink\" title=\"决策树\"></a>决策树</h2><p><img src=\"/2019/04/20/决策树-1基本概念/tree.png\" alt=\"logo\"></p>\n<p>上图来自西瓜书，是决策树的一种树形。生成决策树的过程，不断的<strong>根据样本的属性( 样本的某个特征 )划分样本子集</strong>。每个结点选择当前最优的属性作为划分依据，将样本集合不断的划分成更小的子集合，直到子集合中样本类别一致时或者没有可以划分的属性值时，则停止划分，标记为叶结点(叶节点代表一个类别)。</p>\n<p>简单的介绍一下决策树的组成元素:</p>\n<ol>\n<li>根节点:  所有的训练样本</li>\n<li>内部节点:   对应某一个划分属性</li>\n<li>叶节点：   对应某一种决策结果</li>\n<li>判定测试序列：   某个样本在节点中传递的路径</li>\n</ol>\n<p>所有节点都包含着不同数量的样本。</p>\n<blockquote>\n<p>以上是分类树的例子，决策树也可以用作回归任务，如CART算法。决策树是GBDT,Xgboost等更高级结构的基础，所以尽量要掌握决策树的原理。</p>\n</blockquote>\n<h2 id=\"决策树算法的基本流程\"><a href=\"#决策树算法的基本流程\" class=\"headerlink\" title=\"决策树算法的基本流程\"></a>决策树算法的基本流程</h2><p>假设有一个数据集，其中的每个样本有多种特征，每个特征有不同的取值。通过这个数据集来生成一个决策树的一般流程可以归纳为:</p>\n<ul>\n<li>特征选择</li>\n</ul>\n<blockquote>\n<p>特征选择就是决策树分叉时，依据新节点的”纯度”，选择最优的划分属性;</p>\n</blockquote>\n<ul>\n<li>决策树生成</li>\n</ul>\n<blockquote>\n<p>树不断的分叉，直到样本的属性用光，或者树的深度达到了预定值，则结束分叉;</p>\n</blockquote>\n<ul>\n<li>剪枝</li>\n</ul>\n<blockquote>\n<p>如果一直树杈分下去，一定能够使得所有的样本都正确的归类，但这样会产生对训练集的过拟合，泛化能力变差，可以通过剪枝操作来改善泛化能力。</p>\n</blockquote>\n<p>通过这三步，就可以生成一颗决策树了。下面来学习一下具体怎么进行特征的选择和剪枝。</p>\n<h2 id=\"如何选择最优的划分属性-分类树\"><a href=\"#如何选择最优的划分属性-分类树\" class=\"headerlink\" title=\"如何选择最优的划分属性(分类树)?\"></a>如何选择最优的划分属性(分类树)?</h2><blockquote>\n<p>决策树不断分叉的原因，是尽可能的让不同类别的样本划分到不同的节点，同类别的样本划分到同一个节点。而选择最优的划分属性（特征）的过程，相当于是遍历计算出所有特征的结果，找到能使分叉后子集合最 “纯” 的特征，就是最优的划分属性了。<br>所以，该如何定义 “纯” ，需要借助信息论中 “信息熵” 的概念了。</p>\n</blockquote>\n<p><strong>熵</strong> :  表示随机变量不确定性的度量,也就是混乱程度的一种度量。</p>\n<p>假定数据集 <code>D</code> 中第 <code>K</code> 类样本所占的比例为 <script type=\"math/tex\">p_{k}</script>,则信息熵定义为:</p>\n<script type=\"math/tex; mode=display\">\n\\operatorname{Ent}(D)=-\\sum_{k=1}^{N} p_{k} \\log _{2} p_{k}</script><p>数据集包含的<font color=\"#FF0000\">类别越少时越纯，<code>Ent(D)</code>也越小。</font> </p>\n<h3 id=\"法1-信息增益\"><a href=\"#法1-信息增益\" class=\"headerlink\" title=\"法1: 信息增益\"></a>法1: 信息增益</h3><p>==ID3算法用到信息增益==</p>\n<blockquote>\n<p>直白的讲就是决策树分叉前的信息熵减去分叉后的信息熵。</p>\n<p>信息增益最大的特征就是最佳划分属性。</p>\n</blockquote>\n<p>假定分叉前样本集 <code>D</code> 中的特征 <code>a</code> 有 <code>V</code>个可能的取值 <script type=\"math/tex\">\\left\\{a^{1}, a^{2}, \\ldots, a^{V}\\right\\}</script> ,当选择 <code>a</code> 做划分属性时，会分<code>V</code>个节点，每个节点上的子样本集合为 <script type=\"math/tex\">D^{v}</script>,同时为不同节点赋权重(按照样本的比例)，于是信息增益为: </p>\n<script type=\"math/tex; mode=display\">\\operatorname{Gain}(D, a)=\\operatorname{Ent}(D)-\\sum_{v=1}^{V} \\frac{\\left|D^{v}\\right|}{|D|} \\operatorname{Ent}\\left(D^{v}\\right)</script><p>减数部分也叫<font color=\"#FF0000\"> 条件熵 </font></p>\n<font color=\"#FF0000\">缺点:</font> 分叉时偏好取值较多的属性。\n\n<font color=\"#FF0000\">原因分析:</font>\n\n<ol>\n<li>取值多的特征，样本更分散，所有得到的新节点”纯度” 趋于更高，熵更低，而划分前的增益不变的情况下，该特征增益更大。</li>\n<li>比如，当特征的可能取值数量正好等于样本数量，那条件熵几乎为0，该特征一定会被选择。</li>\n</ol>\n<h3 id=\"法2-信息增益率\"><a href=\"#法2-信息增益率\" class=\"headerlink\" title=\"法2: 信息增益率\"></a>法2: 信息增益率</h3><p>==C4.5算法用到信息增率==</p>\n<blockquote>\n<p>相当于在法1基础上，增加了惩罚系数，可取值越多，系数越大。</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">Gain\\_ratio\\left( D,a \\right) =\\frac{Gain\\left( D,a \\right)}{IV\\left( a \\right)}</script><script type=\"math/tex; mode=display\">\\mathrm{IV}(a)=-\\sum_{v=1}^{V} \\frac{\\left|D^{v}\\right|}{|D|} \\log _{2} \\frac{\\left|D^{v}\\right|}{|D|}</script><p><code>IV(a)</code> 是属性 <code>a</code> 的 “固有值”，内部属性。</p>\n<p><font color=\"#FF0000\">缺点:</font> 分叉时偏好取值较少的属性。</p>\n<h3 id=\"法3：基尼指数\"><a href=\"#法3：基尼指数\" class=\"headerlink\" title=\"法3：基尼指数\"></a>法3：基尼指数</h3><p>==CART决策树算法用到基尼指数==</p>\n<blockquote>\n<p>反应从节点样本集合中随机抽取两个样本，类别不一致的概率。CART决策树默认为二叉树。</p>\n</blockquote>\n<p>基尼值的定义:</p>\n<script type=\"math/tex; mode=display\">\n\\operatorname{Gini}(D)=\\sum_{k=1}^{|y|} \\sum_{k^{\\prime}=k} p_{k} p_{k^{\\prime}}</script><script type=\"math/tex; mode=display\">=\\sum_{k=1}^{|y|} p_{k}\\left(1-P_{k}\\right)</script><script type=\"math/tex; mode=display\">=1-\\sum_{k=1}^{|\\mathcal{Y}|} p_{k}^{2}</script><p>选择特征 <code>A</code> 的情况下，针对 <code>A</code> 所有可能取值 <code>a</code>, 分别计算基尼指数：</p>\n<script type=\"math/tex; mode=display\">Gini\\_index\\left( D,a \\right) =\\sum_{v=1}^V{\\frac{\\left| D^v \\right|}{|D|}}\\text{}Gini\\left( D^v \\right)</script><p>选择基尼指数最小的特征和切分点，作为最优划分属性。</p>\n<p>三种决策树模型：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>算法</th>\n<th>特征选择标准</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ID3</td>\n<td>信息增益</td>\n</tr>\n<tr>\n<td>C4.5</td>\n<td>信息增益率</td>\n</tr>\n<tr>\n<td>CART</td>\n<td>基尼指数</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"对抗过拟合-—-剪枝处理\"><a href=\"#对抗过拟合-—-剪枝处理\" class=\"headerlink\" title=\"对抗过拟合 — 剪枝处理\"></a>对抗过拟合 — 剪枝处理</h2><blockquote>\n<p>分支太多，容易过拟合，泛化能力变差。所以要适当剪枝，常用方法是<strong>预剪枝</strong>和<strong>后剪枝</strong></p>\n<p>剪枝操作包括的点也很多，这里只是简单描述一下，详细的参考未来的博客。<a href=\"www.elgong.top\">www.elgong.top</a></p>\n</blockquote>\n<h3 id=\"预剪枝\"><a href=\"#预剪枝\" class=\"headerlink\" title=\"预剪枝\"></a>预剪枝</h3><ol>\n<li>预剪枝是在决策树生成的过程中，对每个结点在划分前先估计，根据划分前后验证集的精度，来决定是否划分；</li>\n</ol>\n<ol>\n<li>只能估计当前结点可划分性，不能预测到未来节点划分的必要性，是贪心算法；</li>\n</ol>\n<ol>\n<li>容易造成欠拟合。</li>\n</ol>\n<h3 id=\"后剪枝\"><a href=\"#后剪枝\" class=\"headerlink\" title=\"后剪枝\"></a>后剪枝</h3><ol>\n<li>先生成完整的树，再从叶结点往回计算，根据验证集精度是否提升决定是否剪枝；</li>\n</ol>\n<ol>\n<li>泛化能力往往优于预剪枝，欠拟合风险小；</li>\n</ol>\n<ol>\n<li>时间开销大。</li>\n</ol>\n<h2 id=\"属性为连续值时？\"><a href=\"#属性为连续值时？\" class=\"headerlink\" title=\"属性为连续值时？\"></a>属性为连续值时？</h2><blockquote>\n<p>C4.5 算法采用二分法将连续值离散化</p>\n<p>与离散属性不同，连续的属性可以在后代节点中再次使用</p>\n</blockquote>\n<h2 id=\"当数据中含有缺失值时？\"><a href=\"#当数据中含有缺失值时？\" class=\"headerlink\" title=\"当数据中含有缺失值时？\"></a>当数据中含有缺失值时？</h2><p>处理方法：</p>\n<p>通过无缺失数据计算出三个参数：</p>\n<ol>\n<li>无缺失样本占总样本比例 </li>\n<li>无缺失样中 <code>K类别</code> 占比 <code>pk</code></li>\n<li>无缺失样本中 <code>v 属性</code>样本占比 <code>rv</code></li>\n</ol>\n<p>对单样本增加一个权值 <code>Wx</code>, 无缺失样本的<code>Wx = 1</code>，  有缺失样本的<code>Wx = rv*Wx</code>。</p>\n<p>在计算分支时，<strong>同一样本以不同的概率划分到不同的子节点中</strong></p>\n<ul>\n<li>当样本的属性已知：则把该样本划分进对应的子节点，权值=1；</li>\n</ul>\n<ul>\n<li>当样本的该属性缺失：则把该样本同时划入所有的子节点，样本权值需要更新为`Wx = rv*Wx。</li>\n</ul>\n<h2 id=\"决策树的优缺点\"><a href=\"#决策树的优缺点\" class=\"headerlink\" title=\"决策树的优缺点\"></a>决策树的优缺点</h2><p>==优点==：</p>\n<ul>\n<li>便于理解和可视化；</li>\n<li>训练需要的数据少，不需要对数据进行规范化；</li>\n<li>可同时处理数值型，类别型数据；</li>\n<li>是白盒模型，可解释；</li>\n</ul>\n<p>==缺点==：</p>\n<ul>\n<li>容易产生过于复杂的模型 -&gt; 泛化能力差 （剪枝，限制叶节点所需要的最小样本数，最大深度）</li>\n<li>决策树不稳定，微小变化会产生不同的树（集成多棵树可以缓解）</li>\n<li>难学NP问题（启发式学习）</li>\n<li>异或，奇偶，很难被学习到</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"决策树1-基本概念\"><a href=\"#决策树1-基本概念\" class=\"headerlink\" title=\"决策树1- 基本概念\"></a>决策树1- 基本概念</h1><h2 id=\"决策树\"><a href=\"#决策树\" class=\"headerlink\" title=\"决策树\"></a>决策树</h2><p><img src=\"/2019/04/20/决策树-1基本概念/tree.png\" alt=\"logo\"></p>\n<p>上图来自西瓜书，是决策树的一种树形。生成决策树的过程，不断的<strong>根据样本的属性( 样本的某个特征 )划分样本子集</strong>。每个结点选择当前最优的属性作为划分依据，将样本集合不断的划分成更小的子集合，直到子集合中样本类别一致时或者没有可以划分的属性值时，则停止划分，标记为叶结点(叶节点代表一个类别)。</p>\n<p>简单的介绍一下决策树的组成元素:</p>\n<ol>\n<li>根节点:  所有的训练样本</li>\n<li>内部节点:   对应某一个划分属性</li>\n<li>叶节点：   对应某一种决策结果</li>\n<li>判定测试序列：   某个样本在节点中传递的路径</li>\n</ol>\n<p>所有节点都包含着不同数量的样本。</p>\n<blockquote>\n<p>以上是分类树的例子，决策树也可以用作回归任务，如CART算法。决策树是GBDT,Xgboost等更高级结构的基础，所以尽量要掌握决策树的原理。</p>\n</blockquote>\n<h2 id=\"决策树算法的基本流程\"><a href=\"#决策树算法的基本流程\" class=\"headerlink\" title=\"决策树算法的基本流程\"></a>决策树算法的基本流程</h2><p>假设有一个数据集，其中的每个样本有多种特征，每个特征有不同的取值。通过这个数据集来生成一个决策树的一般流程可以归纳为:</p>\n<ul>\n<li>特征选择</li>\n</ul>\n<blockquote>\n<p>特征选择就是决策树分叉时，依据新节点的”纯度”，选择最优的划分属性;</p>\n</blockquote>\n<ul>\n<li>决策树生成</li>\n</ul>\n<blockquote>\n<p>树不断的分叉，直到样本的属性用光，或者树的深度达到了预定值，则结束分叉;</p>\n</blockquote>\n<ul>\n<li>剪枝</li>\n</ul>\n<blockquote>\n<p>如果一直树杈分下去，一定能够使得所有的样本都正确的归类，但这样会产生对训练集的过拟合，泛化能力变差，可以通过剪枝操作来改善泛化能力。</p>\n</blockquote>\n<p>通过这三步，就可以生成一颗决策树了。下面来学习一下具体怎么进行特征的选择和剪枝。</p>\n<h2 id=\"如何选择最优的划分属性-分类树\"><a href=\"#如何选择最优的划分属性-分类树\" class=\"headerlink\" title=\"如何选择最优的划分属性(分类树)?\"></a>如何选择最优的划分属性(分类树)?</h2><blockquote>\n<p>决策树不断分叉的原因，是尽可能的让不同类别的样本划分到不同的节点，同类别的样本划分到同一个节点。而选择最优的划分属性（特征）的过程，相当于是遍历计算出所有特征的结果，找到能使分叉后子集合最 “纯” 的特征，就是最优的划分属性了。<br>所以，该如何定义 “纯” ，需要借助信息论中 “信息熵” 的概念了。</p>\n</blockquote>\n<p><strong>熵</strong> :  表示随机变量不确定性的度量,也就是混乱程度的一种度量。</p>\n<p>假定数据集 <code>D</code> 中第 <code>K</code> 类样本所占的比例为 <script type=\"math/tex\">p_{k}</script>,则信息熵定义为:</p>\n<script type=\"math/tex; mode=display\">\n\\operatorname{Ent}(D)=-\\sum_{k=1}^{N} p_{k} \\log _{2} p_{k}</script><p>数据集包含的<font color=\"#FF0000\">类别越少时越纯，<code>Ent(D)</code>也越小。</font> </p>\n<h3 id=\"法1-信息增益\"><a href=\"#法1-信息增益\" class=\"headerlink\" title=\"法1: 信息增益\"></a>法1: 信息增益</h3><p>==ID3算法用到信息增益==</p>\n<blockquote>\n<p>直白的讲就是决策树分叉前的信息熵减去分叉后的信息熵。</p>\n<p>信息增益最大的特征就是最佳划分属性。</p>\n</blockquote>\n<p>假定分叉前样本集 <code>D</code> 中的特征 <code>a</code> 有 <code>V</code>个可能的取值 <script type=\"math/tex\">\\left\\{a^{1}, a^{2}, \\ldots, a^{V}\\right\\}</script> ,当选择 <code>a</code> 做划分属性时，会分<code>V</code>个节点，每个节点上的子样本集合为 <script type=\"math/tex\">D^{v}</script>,同时为不同节点赋权重(按照样本的比例)，于是信息增益为: </p>\n<script type=\"math/tex; mode=display\">\\operatorname{Gain}(D, a)=\\operatorname{Ent}(D)-\\sum_{v=1}^{V} \\frac{\\left|D^{v}\\right|}{|D|} \\operatorname{Ent}\\left(D^{v}\\right)</script><p>减数部分也叫<font color=\"#FF0000\"> 条件熵 </font></p>\n<font color=\"#FF0000\">缺点:</font> 分叉时偏好取值较多的属性。\n\n<font color=\"#FF0000\">原因分析:</font>\n\n<ol>\n<li>取值多的特征，样本更分散，所有得到的新节点”纯度” 趋于更高，熵更低，而划分前的增益不变的情况下，该特征增益更大。</li>\n<li>比如，当特征的可能取值数量正好等于样本数量，那条件熵几乎为0，该特征一定会被选择。</li>\n</ol>\n<h3 id=\"法2-信息增益率\"><a href=\"#法2-信息增益率\" class=\"headerlink\" title=\"法2: 信息增益率\"></a>法2: 信息增益率</h3><p>==C4.5算法用到信息增率==</p>\n<blockquote>\n<p>相当于在法1基础上，增加了惩罚系数，可取值越多，系数越大。</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">Gain\\_ratio\\left( D,a \\right) =\\frac{Gain\\left( D,a \\right)}{IV\\left( a \\right)}</script><script type=\"math/tex; mode=display\">\\mathrm{IV}(a)=-\\sum_{v=1}^{V} \\frac{\\left|D^{v}\\right|}{|D|} \\log _{2} \\frac{\\left|D^{v}\\right|}{|D|}</script><p><code>IV(a)</code> 是属性 <code>a</code> 的 “固有值”，内部属性。</p>\n<p><font color=\"#FF0000\">缺点:</font> 分叉时偏好取值较少的属性。</p>\n<h3 id=\"法3：基尼指数\"><a href=\"#法3：基尼指数\" class=\"headerlink\" title=\"法3：基尼指数\"></a>法3：基尼指数</h3><p>==CART决策树算法用到基尼指数==</p>\n<blockquote>\n<p>反应从节点样本集合中随机抽取两个样本，类别不一致的概率。CART决策树默认为二叉树。</p>\n</blockquote>\n<p>基尼值的定义:</p>\n<script type=\"math/tex; mode=display\">\n\\operatorname{Gini}(D)=\\sum_{k=1}^{|y|} \\sum_{k^{\\prime}=k} p_{k} p_{k^{\\prime}}</script><script type=\"math/tex; mode=display\">=\\sum_{k=1}^{|y|} p_{k}\\left(1-P_{k}\\right)</script><script type=\"math/tex; mode=display\">=1-\\sum_{k=1}^{|\\mathcal{Y}|} p_{k}^{2}</script><p>选择特征 <code>A</code> 的情况下，针对 <code>A</code> 所有可能取值 <code>a</code>, 分别计算基尼指数：</p>\n<script type=\"math/tex; mode=display\">Gini\\_index\\left( D,a \\right) =\\sum_{v=1}^V{\\frac{\\left| D^v \\right|}{|D|}}\\text{}Gini\\left( D^v \\right)</script><p>选择基尼指数最小的特征和切分点，作为最优划分属性。</p>\n<p>三种决策树模型：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>算法</th>\n<th>特征选择标准</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>ID3</td>\n<td>信息增益</td>\n</tr>\n<tr>\n<td>C4.5</td>\n<td>信息增益率</td>\n</tr>\n<tr>\n<td>CART</td>\n<td>基尼指数</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h2 id=\"对抗过拟合-—-剪枝处理\"><a href=\"#对抗过拟合-—-剪枝处理\" class=\"headerlink\" title=\"对抗过拟合 — 剪枝处理\"></a>对抗过拟合 — 剪枝处理</h2><blockquote>\n<p>分支太多，容易过拟合，泛化能力变差。所以要适当剪枝，常用方法是<strong>预剪枝</strong>和<strong>后剪枝</strong></p>\n<p>剪枝操作包括的点也很多，这里只是简单描述一下，详细的参考未来的博客。<a href=\"www.elgong.top\">www.elgong.top</a></p>\n</blockquote>\n<h3 id=\"预剪枝\"><a href=\"#预剪枝\" class=\"headerlink\" title=\"预剪枝\"></a>预剪枝</h3><ol>\n<li>预剪枝是在决策树生成的过程中，对每个结点在划分前先估计，根据划分前后验证集的精度，来决定是否划分；</li>\n</ol>\n<ol>\n<li>只能估计当前结点可划分性，不能预测到未来节点划分的必要性，是贪心算法；</li>\n</ol>\n<ol>\n<li>容易造成欠拟合。</li>\n</ol>\n<h3 id=\"后剪枝\"><a href=\"#后剪枝\" class=\"headerlink\" title=\"后剪枝\"></a>后剪枝</h3><ol>\n<li>先生成完整的树，再从叶结点往回计算，根据验证集精度是否提升决定是否剪枝；</li>\n</ol>\n<ol>\n<li>泛化能力往往优于预剪枝，欠拟合风险小；</li>\n</ol>\n<ol>\n<li>时间开销大。</li>\n</ol>\n<h2 id=\"属性为连续值时？\"><a href=\"#属性为连续值时？\" class=\"headerlink\" title=\"属性为连续值时？\"></a>属性为连续值时？</h2><blockquote>\n<p>C4.5 算法采用二分法将连续值离散化</p>\n<p>与离散属性不同，连续的属性可以在后代节点中再次使用</p>\n</blockquote>\n<h2 id=\"当数据中含有缺失值时？\"><a href=\"#当数据中含有缺失值时？\" class=\"headerlink\" title=\"当数据中含有缺失值时？\"></a>当数据中含有缺失值时？</h2><p>处理方法：</p>\n<p>通过无缺失数据计算出三个参数：</p>\n<ol>\n<li>无缺失样本占总样本比例 </li>\n<li>无缺失样中 <code>K类别</code> 占比 <code>pk</code></li>\n<li>无缺失样本中 <code>v 属性</code>样本占比 <code>rv</code></li>\n</ol>\n<p>对单样本增加一个权值 <code>Wx</code>, 无缺失样本的<code>Wx = 1</code>，  有缺失样本的<code>Wx = rv*Wx</code>。</p>\n<p>在计算分支时，<strong>同一样本以不同的概率划分到不同的子节点中</strong></p>\n<ul>\n<li>当样本的属性已知：则把该样本划分进对应的子节点，权值=1；</li>\n</ul>\n<ul>\n<li>当样本的该属性缺失：则把该样本同时划入所有的子节点，样本权值需要更新为`Wx = rv*Wx。</li>\n</ul>\n<h2 id=\"决策树的优缺点\"><a href=\"#决策树的优缺点\" class=\"headerlink\" title=\"决策树的优缺点\"></a>决策树的优缺点</h2><p>==优点==：</p>\n<ul>\n<li>便于理解和可视化；</li>\n<li>训练需要的数据少，不需要对数据进行规范化；</li>\n<li>可同时处理数值型，类别型数据；</li>\n<li>是白盒模型，可解释；</li>\n</ul>\n<p>==缺点==：</p>\n<ul>\n<li>容易产生过于复杂的模型 -&gt; 泛化能力差 （剪枝，限制叶节点所需要的最小样本数，最大深度）</li>\n<li>决策树不稳定，微小变化会产生不同的树（集成多棵树可以缓解）</li>\n<li>难学NP问题（启发式学习）</li>\n<li>异或，奇偶，很难被学习到</li>\n</ul>\n"},{"title":"评价指标 ROC与AUC","mathjax":true,"date":"2019-07-20T07:10:00.000Z","top":true,"_content":"\n## 非均衡分类问题\n\n> 非均衡分类问题指的是每个类别的错误代价不同。\n\n> 比如疾病检测中,有病患者诊断健康的代价，要比健康人诊断成有病（可能性）造成的影响更为严重。\n\n> 对于常用的预测模型，通常是有预测的概率值，我们找到一个合适的截断点作为正负类别的界限。显然再不同的任务下，截断点选择是不同的。我们使用Precison 和Recall的新度量指标来针对特定任务下选择合适的截断值。\n\n\n真实标签 | 预测为正 | 预测为反\n---|---|---\n正例 | TP | FN\n反例 | FP | TN\n\n\n\n- Precison(查准率)：\n\n```\n    P = TP/(TP+FP)\n```\n\n- Recall(召回率)：\n\n```\n    R = TP/(TP+FN)\n```\n\n> 当正负样本不不均衡,人为修改测试集中的正负比例时, P-R曲线波动很大，但是ROC曲线变化很小。\n\n## ROC 曲线\n\n> 可以研究学习器的泛化性能。\n## 加图\n- 横坐标：真阳率，正例被正确预测的概率\n\n```\n    FPR = FP/(TN+FP)\n```\n- 纵坐标：假阳率，负例被预测错误的概率\n```\n    TPR = TP/(TP+FN)\n```\n**==理解四点一线==**：\n- (0, 0):  FP = TP = 0, 所有样本预测为负\n- (1, 1):  FP = TP = 1, 所有样本预测为正\n- (1, 0):  FP = 1, TP = 0, 所有正样本预测为负\n- (0, 1):  FP = 0, TP = 1, 完美预测\n- 对角线：随机猜测的值。\n\n\n## AUC值\n\nAUC(Area under Curve) 被定义为ROC曲线的下侧面积。一般在(0.5~1)之间。\n\n### 计算方法\n\n1. 几何角度\n> 直接计算曲线下的面积，梯形\n\n2. 概率角度\n> 任取一对正负样本对，正样本score大于负样本score的概率\n\n\n### python 实现\n\n\n\n[链接](http://zhuzhuyule.xyz)\n\n```\n\timport numpy as np\n\tfrom sklearn.metrics import roc_curve\n\tfrom sklearn.metrics import auc\n\tfrom time import time\n\t\n\t# y:     标签\n\t# pred： 预测值\n\tdef myAUC(y, pred):\n\t\n\t    auc = 0.0\n\t    p_list = []  # 正负例的索引\n\t    n_list = []\n\t    for i, y_ in enumerate(y):\n\t        if y_ == 1:\n\t            p_list.append(i)\n\t        else:\n\t            n_list.append(i)\n\t    # 构成p-n对\n\t    p_n = [(i,j) for i in p_list for j in n_list]\n\t    \n\t    pn_len = len(p_n)\n\t    for tup in p_n:\n\t        if pred[tup[0]] > pred[tup[1]]:\n\t            auc += 1\n\t        elif pred[tup[0]] == pred[tup[1]]:\n\t            auc += 0.5\n\t    auc = auc/pn_len\n\t    return auc\n\t\n\t\n\t## 产生一组数据\n\ty = np.array([1,0,0,0,1,0,1,0,])\n\tpred = np.array([0.9, 0.8, 0.3, 0.1,0.4,0.9,0.66,0.7])\n\t\n\t## sklearn 结果\n\tfpr, tpr, thresholds = roc_curve(y, pred, pos_label=1)\n\t\n\ttim = time()\n\tprint(\"sklearn AUC:\",auc(fpr, tpr))\n\tprint(\"sklearn AUC time:\", time()-tim)\n\t\n\t\n\t## myAUC 结果\n\ttim = time()\n\tprint(\"\\nmyAUC:\",myAUC(y,pred))\n\tprint(\"myAUC time:\", time()-tim)\n\n```","source":"_posts/评价指标-ROC与AUC.md","raw":"---\ntitle: 评价指标 ROC与AUC\nmathjax: true\ndate: 2019-07-20 15:10:00\ncategories: 机器学习方法\ntags: ROC\ntop: True\n---\n\n## 非均衡分类问题\n\n> 非均衡分类问题指的是每个类别的错误代价不同。\n\n> 比如疾病检测中,有病患者诊断健康的代价，要比健康人诊断成有病（可能性）造成的影响更为严重。\n\n> 对于常用的预测模型，通常是有预测的概率值，我们找到一个合适的截断点作为正负类别的界限。显然再不同的任务下，截断点选择是不同的。我们使用Precison 和Recall的新度量指标来针对特定任务下选择合适的截断值。\n\n\n真实标签 | 预测为正 | 预测为反\n---|---|---\n正例 | TP | FN\n反例 | FP | TN\n\n\n\n- Precison(查准率)：\n\n```\n    P = TP/(TP+FP)\n```\n\n- Recall(召回率)：\n\n```\n    R = TP/(TP+FN)\n```\n\n> 当正负样本不不均衡,人为修改测试集中的正负比例时, P-R曲线波动很大，但是ROC曲线变化很小。\n\n## ROC 曲线\n\n> 可以研究学习器的泛化性能。\n## 加图\n- 横坐标：真阳率，正例被正确预测的概率\n\n```\n    FPR = FP/(TN+FP)\n```\n- 纵坐标：假阳率，负例被预测错误的概率\n```\n    TPR = TP/(TP+FN)\n```\n**==理解四点一线==**：\n- (0, 0):  FP = TP = 0, 所有样本预测为负\n- (1, 1):  FP = TP = 1, 所有样本预测为正\n- (1, 0):  FP = 1, TP = 0, 所有正样本预测为负\n- (0, 1):  FP = 0, TP = 1, 完美预测\n- 对角线：随机猜测的值。\n\n\n## AUC值\n\nAUC(Area under Curve) 被定义为ROC曲线的下侧面积。一般在(0.5~1)之间。\n\n### 计算方法\n\n1. 几何角度\n> 直接计算曲线下的面积，梯形\n\n2. 概率角度\n> 任取一对正负样本对，正样本score大于负样本score的概率\n\n\n### python 实现\n\n\n\n[链接](http://zhuzhuyule.xyz)\n\n```\n\timport numpy as np\n\tfrom sklearn.metrics import roc_curve\n\tfrom sklearn.metrics import auc\n\tfrom time import time\n\t\n\t# y:     标签\n\t# pred： 预测值\n\tdef myAUC(y, pred):\n\t\n\t    auc = 0.0\n\t    p_list = []  # 正负例的索引\n\t    n_list = []\n\t    for i, y_ in enumerate(y):\n\t        if y_ == 1:\n\t            p_list.append(i)\n\t        else:\n\t            n_list.append(i)\n\t    # 构成p-n对\n\t    p_n = [(i,j) for i in p_list for j in n_list]\n\t    \n\t    pn_len = len(p_n)\n\t    for tup in p_n:\n\t        if pred[tup[0]] > pred[tup[1]]:\n\t            auc += 1\n\t        elif pred[tup[0]] == pred[tup[1]]:\n\t            auc += 0.5\n\t    auc = auc/pn_len\n\t    return auc\n\t\n\t\n\t## 产生一组数据\n\ty = np.array([1,0,0,0,1,0,1,0,])\n\tpred = np.array([0.9, 0.8, 0.3, 0.1,0.4,0.9,0.66,0.7])\n\t\n\t## sklearn 结果\n\tfpr, tpr, thresholds = roc_curve(y, pred, pos_label=1)\n\t\n\ttim = time()\n\tprint(\"sklearn AUC:\",auc(fpr, tpr))\n\tprint(\"sklearn AUC time:\", time()-tim)\n\t\n\t\n\t## myAUC 结果\n\ttim = time()\n\tprint(\"\\nmyAUC:\",myAUC(y,pred))\n\tprint(\"myAUC time:\", time()-tim)\n\n```","slug":"评价指标-ROC与AUC","published":1,"updated":"2019-08-09T02:09:17.555Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz98jgzb000sy0plxdglyowm","content":"<h2 id=\"非均衡分类问题\"><a href=\"#非均衡分类问题\" class=\"headerlink\" title=\"非均衡分类问题\"></a>非均衡分类问题</h2><blockquote>\n<p>非均衡分类问题指的是每个类别的错误代价不同。</p>\n<p>比如疾病检测中,有病患者诊断健康的代价，要比健康人诊断成有病（可能性）造成的影响更为严重。</p>\n<p>对于常用的预测模型，通常是有预测的概率值，我们找到一个合适的截断点作为正负类别的界限。显然再不同的任务下，截断点选择是不同的。我们使用Precison 和Recall的新度量指标来针对特定任务下选择合适的截断值。</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>真实标签</th>\n<th>预测为正</th>\n<th>预测为反</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>正例</td>\n<td>TP</td>\n<td>FN</td>\n</tr>\n<tr>\n<td>反例</td>\n<td>FP</td>\n<td>TN</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>Precison(查准率)：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">P = TP/(TP+FP)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>Recall(召回率)：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">R = TP/(TP+FN)</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>当正负样本不不均衡,人为修改测试集中的正负比例时, P-R曲线波动很大，但是ROC曲线变化很小。</p>\n</blockquote>\n<h2 id=\"ROC-曲线\"><a href=\"#ROC-曲线\" class=\"headerlink\" title=\"ROC 曲线\"></a>ROC 曲线</h2><blockquote>\n<p>可以研究学习器的泛化性能。</p>\n<h2 id=\"加图\"><a href=\"#加图\" class=\"headerlink\" title=\"加图\"></a>加图</h2><ul>\n<li>横坐标：真阳率，正例被正确预测的概率</li>\n</ul>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FPR = FP/(TN+FP)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>纵坐标：假阳率，负例被预测错误的概率<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TPR = TP/(TP+FN)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p><strong>==理解四点一线==</strong>：</p>\n<ul>\n<li>(0, 0):  FP = TP = 0, 所有样本预测为负</li>\n<li>(1, 1):  FP = TP = 1, 所有样本预测为正</li>\n<li>(1, 0):  FP = 1, TP = 0, 所有正样本预测为负</li>\n<li>(0, 1):  FP = 0, TP = 1, 完美预测</li>\n<li>对角线：随机猜测的值。</li>\n</ul>\n<h2 id=\"AUC值\"><a href=\"#AUC值\" class=\"headerlink\" title=\"AUC值\"></a>AUC值</h2><p>AUC(Area under Curve) 被定义为ROC曲线的下侧面积。一般在(0.5~1)之间。</p>\n<h3 id=\"计算方法\"><a href=\"#计算方法\" class=\"headerlink\" title=\"计算方法\"></a>计算方法</h3><ol>\n<li><p>几何角度</p>\n<blockquote>\n<p>直接计算曲线下的面积，梯形</p>\n</blockquote>\n</li>\n<li><p>概率角度</p>\n<blockquote>\n<p>任取一对正负样本对，正样本score大于负样本score的概率</p>\n</blockquote>\n</li>\n</ol>\n<h3 id=\"python-实现\"><a href=\"#python-实现\" class=\"headerlink\" title=\"python 实现\"></a>python 实现</h3><p><a href=\"http://zhuzhuyule.xyz\" target=\"_blank\" rel=\"noopener\">链接</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\">from sklearn.metrics import roc_curve</span><br><span class=\"line\">from sklearn.metrics import auc</span><br><span class=\"line\">from time import time</span><br><span class=\"line\"></span><br><span class=\"line\"># y:     标签</span><br><span class=\"line\"># pred： 预测值</span><br><span class=\"line\">def myAUC(y, pred):</span><br><span class=\"line\"></span><br><span class=\"line\">    auc = 0.0</span><br><span class=\"line\">    p_list = []  # 正负例的索引</span><br><span class=\"line\">    n_list = []</span><br><span class=\"line\">    for i, y_ in enumerate(y):</span><br><span class=\"line\">        if y_ == 1:</span><br><span class=\"line\">            p_list.append(i)</span><br><span class=\"line\">        else:</span><br><span class=\"line\">            n_list.append(i)</span><br><span class=\"line\">    # 构成p-n对</span><br><span class=\"line\">    p_n = [(i,j) for i in p_list for j in n_list]</span><br><span class=\"line\">    </span><br><span class=\"line\">    pn_len = len(p_n)</span><br><span class=\"line\">    for tup in p_n:</span><br><span class=\"line\">        if pred[tup[0]] &gt; pred[tup[1]]:</span><br><span class=\"line\">            auc += 1</span><br><span class=\"line\">        elif pred[tup[0]] == pred[tup[1]]:</span><br><span class=\"line\">            auc += 0.5</span><br><span class=\"line\">    auc = auc/pn_len</span><br><span class=\"line\">    return auc</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">## 产生一组数据</span><br><span class=\"line\">y = np.array([1,0,0,0,1,0,1,0,])</span><br><span class=\"line\">pred = np.array([0.9, 0.8, 0.3, 0.1,0.4,0.9,0.66,0.7])</span><br><span class=\"line\"></span><br><span class=\"line\">## sklearn 结果</span><br><span class=\"line\">fpr, tpr, thresholds = roc_curve(y, pred, pos_label=1)</span><br><span class=\"line\"></span><br><span class=\"line\">tim = time()</span><br><span class=\"line\">print(&quot;sklearn AUC:&quot;,auc(fpr, tpr))</span><br><span class=\"line\">print(&quot;sklearn AUC time:&quot;, time()-tim)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">## myAUC 结果</span><br><span class=\"line\">tim = time()</span><br><span class=\"line\">print(&quot;\\nmyAUC:&quot;,myAUC(y,pred))</span><br><span class=\"line\">print(&quot;myAUC time:&quot;, time()-tim)</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"非均衡分类问题\"><a href=\"#非均衡分类问题\" class=\"headerlink\" title=\"非均衡分类问题\"></a>非均衡分类问题</h2><blockquote>\n<p>非均衡分类问题指的是每个类别的错误代价不同。</p>\n<p>比如疾病检测中,有病患者诊断健康的代价，要比健康人诊断成有病（可能性）造成的影响更为严重。</p>\n<p>对于常用的预测模型，通常是有预测的概率值，我们找到一个合适的截断点作为正负类别的界限。显然再不同的任务下，截断点选择是不同的。我们使用Precison 和Recall的新度量指标来针对特定任务下选择合适的截断值。</p>\n</blockquote>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>真实标签</th>\n<th>预测为正</th>\n<th>预测为反</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>正例</td>\n<td>TP</td>\n<td>FN</td>\n</tr>\n<tr>\n<td>反例</td>\n<td>FP</td>\n<td>TN</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li>Precison(查准率)：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">P = TP/(TP+FP)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>Recall(召回率)：</li>\n</ul>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">R = TP/(TP+FN)</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>当正负样本不不均衡,人为修改测试集中的正负比例时, P-R曲线波动很大，但是ROC曲线变化很小。</p>\n</blockquote>\n<h2 id=\"ROC-曲线\"><a href=\"#ROC-曲线\" class=\"headerlink\" title=\"ROC 曲线\"></a>ROC 曲线</h2><blockquote>\n<p>可以研究学习器的泛化性能。</p>\n<h2 id=\"加图\"><a href=\"#加图\" class=\"headerlink\" title=\"加图\"></a>加图</h2><ul>\n<li>横坐标：真阳率，正例被正确预测的概率</li>\n</ul>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">FPR = FP/(TN+FP)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>纵坐标：假阳率，负例被预测错误的概率<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TPR = TP/(TP+FN)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p><strong>==理解四点一线==</strong>：</p>\n<ul>\n<li>(0, 0):  FP = TP = 0, 所有样本预测为负</li>\n<li>(1, 1):  FP = TP = 1, 所有样本预测为正</li>\n<li>(1, 0):  FP = 1, TP = 0, 所有正样本预测为负</li>\n<li>(0, 1):  FP = 0, TP = 1, 完美预测</li>\n<li>对角线：随机猜测的值。</li>\n</ul>\n<h2 id=\"AUC值\"><a href=\"#AUC值\" class=\"headerlink\" title=\"AUC值\"></a>AUC值</h2><p>AUC(Area under Curve) 被定义为ROC曲线的下侧面积。一般在(0.5~1)之间。</p>\n<h3 id=\"计算方法\"><a href=\"#计算方法\" class=\"headerlink\" title=\"计算方法\"></a>计算方法</h3><ol>\n<li><p>几何角度</p>\n<blockquote>\n<p>直接计算曲线下的面积，梯形</p>\n</blockquote>\n</li>\n<li><p>概率角度</p>\n<blockquote>\n<p>任取一对正负样本对，正样本score大于负样本score的概率</p>\n</blockquote>\n</li>\n</ol>\n<h3 id=\"python-实现\"><a href=\"#python-实现\" class=\"headerlink\" title=\"python 实现\"></a>python 实现</h3><p><a href=\"http://zhuzhuyule.xyz\" target=\"_blank\" rel=\"noopener\">链接</a></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import numpy as np</span><br><span class=\"line\">from sklearn.metrics import roc_curve</span><br><span class=\"line\">from sklearn.metrics import auc</span><br><span class=\"line\">from time import time</span><br><span class=\"line\"></span><br><span class=\"line\"># y:     标签</span><br><span class=\"line\"># pred： 预测值</span><br><span class=\"line\">def myAUC(y, pred):</span><br><span class=\"line\"></span><br><span class=\"line\">    auc = 0.0</span><br><span class=\"line\">    p_list = []  # 正负例的索引</span><br><span class=\"line\">    n_list = []</span><br><span class=\"line\">    for i, y_ in enumerate(y):</span><br><span class=\"line\">        if y_ == 1:</span><br><span class=\"line\">            p_list.append(i)</span><br><span class=\"line\">        else:</span><br><span class=\"line\">            n_list.append(i)</span><br><span class=\"line\">    # 构成p-n对</span><br><span class=\"line\">    p_n = [(i,j) for i in p_list for j in n_list]</span><br><span class=\"line\">    </span><br><span class=\"line\">    pn_len = len(p_n)</span><br><span class=\"line\">    for tup in p_n:</span><br><span class=\"line\">        if pred[tup[0]] &gt; pred[tup[1]]:</span><br><span class=\"line\">            auc += 1</span><br><span class=\"line\">        elif pred[tup[0]] == pred[tup[1]]:</span><br><span class=\"line\">            auc += 0.5</span><br><span class=\"line\">    auc = auc/pn_len</span><br><span class=\"line\">    return auc</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">## 产生一组数据</span><br><span class=\"line\">y = np.array([1,0,0,0,1,0,1,0,])</span><br><span class=\"line\">pred = np.array([0.9, 0.8, 0.3, 0.1,0.4,0.9,0.66,0.7])</span><br><span class=\"line\"></span><br><span class=\"line\">## sklearn 结果</span><br><span class=\"line\">fpr, tpr, thresholds = roc_curve(y, pred, pos_label=1)</span><br><span class=\"line\"></span><br><span class=\"line\">tim = time()</span><br><span class=\"line\">print(&quot;sklearn AUC:&quot;,auc(fpr, tpr))</span><br><span class=\"line\">print(&quot;sklearn AUC time:&quot;, time()-tim)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">## myAUC 结果</span><br><span class=\"line\">tim = time()</span><br><span class=\"line\">print(&quot;\\nmyAUC:&quot;,myAUC(y,pred))</span><br><span class=\"line\">print(&quot;myAUC time:&quot;, time()-tim)</span><br></pre></td></tr></table></figure>"},{"title":"pandas-6重复值处理","mathjax":true,"date":"2019-08-09T07:26:52.000Z","_content":"\n# pandas -6 重复值处理\n\n> 如果你想找到或者删除 `DataFrame`中重复的行, 可以使用 `duplicated` 和 `drop_duplicates`\n\n## 查找重复值\n\n```\nexample:\n        col1  col2     c\n    0    one   x   -1.067137\n    1    one   y    0.309500\n    2    two   x   -0.211056\n    3    two   y   -1.842023\n    4    two   x   -0.390820\n    5  three   x   -1.964475\n    6   four   x    1.298329\nIn:\n    // 单列\n    df.duplicated(\"col1\", keep=\"first\")\n    \n    // 多列\n    // df.duplicated([\"col1\", \"col2\"], keep=\"first\")\n    \nOut:\n    0    False\n    1     True\n    2    False\n    3     True\n    4     True\n    5    False\n    6    False\n    dtype: bool\n    \n    // 默认 keep = \"first\",第一次出现的不算重复，返回False\n    // keep = \"last\", 最后出现的不算重复\n    // keep = False, 重复值均返回 True\n\n```\n\n## 删除重复值\n\n```\nIn:\n    df.drop_duplicates('col1')\n    \nOut:\n        col1  col2    c\n    0    one   x    -1.067137\n    2    two   x    -0.211056\n    5  three   x    -1.964475\n    6   four   x     1.298329\n\n```","source":"_posts/pandas-重复值处理.md","raw":"---\ntitle: pandas-6重复值处理\nmathjax: true\ndate: 2019-08-09 15:26:52\ncategories: pandas系列教程\ntags: pandas\n---\n\n# pandas -6 重复值处理\n\n> 如果你想找到或者删除 `DataFrame`中重复的行, 可以使用 `duplicated` 和 `drop_duplicates`\n\n## 查找重复值\n\n```\nexample:\n        col1  col2     c\n    0    one   x   -1.067137\n    1    one   y    0.309500\n    2    two   x   -0.211056\n    3    two   y   -1.842023\n    4    two   x   -0.390820\n    5  three   x   -1.964475\n    6   four   x    1.298329\nIn:\n    // 单列\n    df.duplicated(\"col1\", keep=\"first\")\n    \n    // 多列\n    // df.duplicated([\"col1\", \"col2\"], keep=\"first\")\n    \nOut:\n    0    False\n    1     True\n    2    False\n    3     True\n    4     True\n    5    False\n    6    False\n    dtype: bool\n    \n    // 默认 keep = \"first\",第一次出现的不算重复，返回False\n    // keep = \"last\", 最后出现的不算重复\n    // keep = False, 重复值均返回 True\n\n```\n\n## 删除重复值\n\n```\nIn:\n    df.drop_duplicates('col1')\n    \nOut:\n        col1  col2    c\n    0    one   x    -1.067137\n    2    two   x    -0.211056\n    5  three   x    -1.964475\n    6   four   x     1.298329\n\n```","slug":"pandas-重复值处理","published":1,"updated":"2019-09-11T06:20:13.038Z","_id":"cjz98jgze000wy0plyn6c764n","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"pandas-6-重复值处理\"><a href=\"#pandas-6-重复值处理\" class=\"headerlink\" title=\"pandas -6 重复值处理\"></a>pandas -6 重复值处理</h1><blockquote>\n<p>如果你想找到或者删除 <code>DataFrame</code>中重复的行, 可以使用 <code>duplicated</code> 和 <code>drop_duplicates</code></p>\n</blockquote>\n<h2 id=\"查找重复值\"><a href=\"#查找重复值\" class=\"headerlink\" title=\"查找重复值\"></a>查找重复值</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">example:</span><br><span class=\"line\">        col1  col2     c</span><br><span class=\"line\">    0    one   x   -1.067137</span><br><span class=\"line\">    1    one   y    0.309500</span><br><span class=\"line\">    2    two   x   -0.211056</span><br><span class=\"line\">    3    two   y   -1.842023</span><br><span class=\"line\">    4    two   x   -0.390820</span><br><span class=\"line\">    5  three   x   -1.964475</span><br><span class=\"line\">    6   four   x    1.298329</span><br><span class=\"line\">In:</span><br><span class=\"line\">    // 单列</span><br><span class=\"line\">    df.duplicated(&quot;col1&quot;, keep=&quot;first&quot;)</span><br><span class=\"line\">    </span><br><span class=\"line\">    // 多列</span><br><span class=\"line\">    // df.duplicated([&quot;col1&quot;, &quot;col2&quot;], keep=&quot;first&quot;)</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">    0    False</span><br><span class=\"line\">    1     True</span><br><span class=\"line\">    2    False</span><br><span class=\"line\">    3     True</span><br><span class=\"line\">    4     True</span><br><span class=\"line\">    5    False</span><br><span class=\"line\">    6    False</span><br><span class=\"line\">    dtype: bool</span><br><span class=\"line\">    </span><br><span class=\"line\">    // 默认 keep = &quot;first&quot;,第一次出现的不算重复，返回False</span><br><span class=\"line\">    // keep = &quot;last&quot;, 最后出现的不算重复</span><br><span class=\"line\">    // keep = False, 重复值均返回 True</span><br></pre></td></tr></table></figure>\n<h2 id=\"删除重复值\"><a href=\"#删除重复值\" class=\"headerlink\" title=\"删除重复值\"></a>删除重复值</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In:</span><br><span class=\"line\">    df.drop_duplicates(&apos;col1&apos;)</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">        col1  col2    c</span><br><span class=\"line\">    0    one   x    -1.067137</span><br><span class=\"line\">    2    two   x    -0.211056</span><br><span class=\"line\">    5  three   x    -1.964475</span><br><span class=\"line\">    6   four   x     1.298329</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"pandas-6-重复值处理\"><a href=\"#pandas-6-重复值处理\" class=\"headerlink\" title=\"pandas -6 重复值处理\"></a>pandas -6 重复值处理</h1><blockquote>\n<p>如果你想找到或者删除 <code>DataFrame</code>中重复的行, 可以使用 <code>duplicated</code> 和 <code>drop_duplicates</code></p>\n</blockquote>\n<h2 id=\"查找重复值\"><a href=\"#查找重复值\" class=\"headerlink\" title=\"查找重复值\"></a>查找重复值</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">example:</span><br><span class=\"line\">        col1  col2     c</span><br><span class=\"line\">    0    one   x   -1.067137</span><br><span class=\"line\">    1    one   y    0.309500</span><br><span class=\"line\">    2    two   x   -0.211056</span><br><span class=\"line\">    3    two   y   -1.842023</span><br><span class=\"line\">    4    two   x   -0.390820</span><br><span class=\"line\">    5  three   x   -1.964475</span><br><span class=\"line\">    6   four   x    1.298329</span><br><span class=\"line\">In:</span><br><span class=\"line\">    // 单列</span><br><span class=\"line\">    df.duplicated(&quot;col1&quot;, keep=&quot;first&quot;)</span><br><span class=\"line\">    </span><br><span class=\"line\">    // 多列</span><br><span class=\"line\">    // df.duplicated([&quot;col1&quot;, &quot;col2&quot;], keep=&quot;first&quot;)</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">    0    False</span><br><span class=\"line\">    1     True</span><br><span class=\"line\">    2    False</span><br><span class=\"line\">    3     True</span><br><span class=\"line\">    4     True</span><br><span class=\"line\">    5    False</span><br><span class=\"line\">    6    False</span><br><span class=\"line\">    dtype: bool</span><br><span class=\"line\">    </span><br><span class=\"line\">    // 默认 keep = &quot;first&quot;,第一次出现的不算重复，返回False</span><br><span class=\"line\">    // keep = &quot;last&quot;, 最后出现的不算重复</span><br><span class=\"line\">    // keep = False, 重复值均返回 True</span><br></pre></td></tr></table></figure>\n<h2 id=\"删除重复值\"><a href=\"#删除重复值\" class=\"headerlink\" title=\"删除重复值\"></a>删除重复值</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">In:</span><br><span class=\"line\">    df.drop_duplicates(&apos;col1&apos;)</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">        col1  col2    c</span><br><span class=\"line\">    0    one   x    -1.067137</span><br><span class=\"line\">    2    two   x    -0.211056</span><br><span class=\"line\">    5  three   x    -1.964475</span><br><span class=\"line\">    6   four   x     1.298329</span><br></pre></td></tr></table></figure>"},{"title":"欢迎来我的小屋！","date":"2019-01-18T06:54:22.000Z","top":1,"_content":"# 哈哈 #\n\n## 试试效果 ##\n\n> 一直想建一个自己的网站\n\n    现在先试试这个\n- \n1. aa\n1. bb\n1. cc\n1. dd","source":"_posts/欢迎来我的小屋！.md","raw":"---\ntitle: 欢迎来我的小屋！\ndate: 2019-01-18 14:54:22\ncategories: 闲聊\ntags: 闲聊\ntop: 1\n---\n# 哈哈 #\n\n## 试试效果 ##\n\n> 一直想建一个自己的网站\n\n    现在先试试这个\n- \n1. aa\n1. bb\n1. cc\n1. dd","slug":"欢迎来我的小屋！","published":1,"updated":"2019-07-30T15:35:42.744Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz98jgzg000yy0planh5t7ql","content":"<h1 id=\"哈哈\"><a href=\"#哈哈\" class=\"headerlink\" title=\"哈哈\"></a>哈哈</h1><h2 id=\"试试效果\"><a href=\"#试试效果\" class=\"headerlink\" title=\"试试效果\"></a>试试效果</h2><blockquote>\n<p>一直想建一个自己的网站</p>\n</blockquote>\n<pre><code>现在先试试这个\n</code></pre><ul>\n<li></li>\n</ul>\n<ol>\n<li>aa</li>\n<li>bb</li>\n<li>cc</li>\n<li>dd</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"哈哈\"><a href=\"#哈哈\" class=\"headerlink\" title=\"哈哈\"></a>哈哈</h1><h2 id=\"试试效果\"><a href=\"#试试效果\" class=\"headerlink\" title=\"试试效果\"></a>试试效果</h2><blockquote>\n<p>一直想建一个自己的网站</p>\n</blockquote>\n<pre><code>现在先试试这个\n</code></pre><ul>\n<li></li>\n</ul>\n<ol>\n<li>aa</li>\n<li>bb</li>\n<li>cc</li>\n<li>dd</li>\n</ol>\n"},{"title":"机器学习模型的偏差与方差","mathjax":true,"date":"2019-08-01T08:43:19.000Z","_content":"\n# 机器学习的方差与偏差\n\n> 方差与偏差，总是迷迷糊糊的，每次看了就会，过了就忘。今天看到一个非常棒的解释，迫不及待马上整理下来了。\n\n\n## 机器学习的目标函数\n机器学习模型学习的是数据集的条件概率分布，得到一个决策函数。整个学习过程围绕着最小化（或者最大化）目标函数进行优化参数，目标函数的通常形式的定义是：\n\n\n    Obj = L(θ) + λΩ(θ)\n    \n`L(θ)` 是损失函数，衡量模型对训练集拟合程度的好坏(对应偏差)；\n\n` Ω(θ)` 是正则项，是衡量模型的复杂程度（对应方差）；\n\n<font color=\"#FF0000\"> 目标函数定义为损失函数和正则项两部分，是为了平衡模型的偏差和方差（Bias Variance Trade-off）。</font> \n\n\n\n## 偏差与学习器\n\n> 偏差描述了 <font color=\"#FF0000\">学习器的拟合能力</font> （对训练集的）。\n\n学习器在训练集表现越好，损失越低，则模型的偏差越小。\n\n\n## 方差与学习器\n\n> 方差描述了 <font color=\"#FF0000\"> 学习器的泛化能力</font>(对测试集)。\n\n学习器在测试集表现越好，则模型的方差越低。\n\n\n## 偏差与方差之间的关系\n\n> 我们最想要的是低偏差，低方差的模型，然而现实很难达到两者都极致的低。有时候需要用提高偏差来降低方差，毕竟模型的泛化能力十分重要。\n\n当损失函数达到极小值，模型对训练集的拟合达到了最佳效果，==对应着低偏差==，而这种情况下，往往对训练集的特点学的过于细微，而缺乏泛化能力。\n\n根据 ==奥坎姆剃刀原则==, 同样准确率，模型越简单越好，所以通过正则化等方式，削弱模型的拟合能力，降低过拟合的风险。通过提高偏差，来主动降低方差。\n\n最终我们要平衡方差与偏差，从而得到一个合理的模型。\n\n   \n![biasvariance](机器学习模型的偏差与方差/biasvariance.png)\n\n## 调整方差与偏差的方法\n\n待补充。。。","source":"_posts/机器学习模型的偏差与方差.md","raw":"---\ntitle: 机器学习模型的偏差与方差\nmathjax: true\ndate: 2019-08-01 16:43:19\ncategories: 机器学习方法\ntags: 方差与偏差\n---\n\n# 机器学习的方差与偏差\n\n> 方差与偏差，总是迷迷糊糊的，每次看了就会，过了就忘。今天看到一个非常棒的解释，迫不及待马上整理下来了。\n\n\n## 机器学习的目标函数\n机器学习模型学习的是数据集的条件概率分布，得到一个决策函数。整个学习过程围绕着最小化（或者最大化）目标函数进行优化参数，目标函数的通常形式的定义是：\n\n\n    Obj = L(θ) + λΩ(θ)\n    \n`L(θ)` 是损失函数，衡量模型对训练集拟合程度的好坏(对应偏差)；\n\n` Ω(θ)` 是正则项，是衡量模型的复杂程度（对应方差）；\n\n<font color=\"#FF0000\"> 目标函数定义为损失函数和正则项两部分，是为了平衡模型的偏差和方差（Bias Variance Trade-off）。</font> \n\n\n\n## 偏差与学习器\n\n> 偏差描述了 <font color=\"#FF0000\">学习器的拟合能力</font> （对训练集的）。\n\n学习器在训练集表现越好，损失越低，则模型的偏差越小。\n\n\n## 方差与学习器\n\n> 方差描述了 <font color=\"#FF0000\"> 学习器的泛化能力</font>(对测试集)。\n\n学习器在测试集表现越好，则模型的方差越低。\n\n\n## 偏差与方差之间的关系\n\n> 我们最想要的是低偏差，低方差的模型，然而现实很难达到两者都极致的低。有时候需要用提高偏差来降低方差，毕竟模型的泛化能力十分重要。\n\n当损失函数达到极小值，模型对训练集的拟合达到了最佳效果，==对应着低偏差==，而这种情况下，往往对训练集的特点学的过于细微，而缺乏泛化能力。\n\n根据 ==奥坎姆剃刀原则==, 同样准确率，模型越简单越好，所以通过正则化等方式，削弱模型的拟合能力，降低过拟合的风险。通过提高偏差，来主动降低方差。\n\n最终我们要平衡方差与偏差，从而得到一个合理的模型。\n\n   \n![biasvariance](机器学习模型的偏差与方差/biasvariance.png)\n\n## 调整方差与偏差的方法\n\n待补充。。。","slug":"机器学习模型的偏差与方差","published":1,"updated":"2019-08-02T02:26:52.381Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz98jgzj0013y0pla3fpxtul","content":"<h1 id=\"机器学习的方差与偏差\"><a href=\"#机器学习的方差与偏差\" class=\"headerlink\" title=\"机器学习的方差与偏差\"></a>机器学习的方差与偏差</h1><blockquote>\n<p>方差与偏差，总是迷迷糊糊的，每次看了就会，过了就忘。今天看到一个非常棒的解释，迫不及待马上整理下来了。</p>\n</blockquote>\n<h2 id=\"机器学习的目标函数\"><a href=\"#机器学习的目标函数\" class=\"headerlink\" title=\"机器学习的目标函数\"></a>机器学习的目标函数</h2><p>机器学习模型学习的是数据集的条件概率分布，得到一个决策函数。整个学习过程围绕着最小化（或者最大化）目标函数进行优化参数，目标函数的通常形式的定义是：</p>\n<pre><code>Obj = L(θ) + λΩ(θ)\n</code></pre><p><code>L(θ)</code> 是损失函数，衡量模型对训练集拟合程度的好坏(对应偏差)；</p>\n<p><code>Ω(θ)</code> 是正则项，是衡量模型的复杂程度（对应方差）；</p>\n<font color=\"#FF0000\"> 目标函数定义为损失函数和正则项两部分，是为了平衡模型的偏差和方差（Bias Variance Trade-off）。</font> \n\n\n\n<h2 id=\"偏差与学习器\"><a href=\"#偏差与学习器\" class=\"headerlink\" title=\"偏差与学习器\"></a>偏差与学习器</h2><blockquote>\n<p>偏差描述了 <font color=\"#FF0000\">学习器的拟合能力</font> （对训练集的）。</p>\n</blockquote>\n<p>学习器在训练集表现越好，损失越低，则模型的偏差越小。</p>\n<h2 id=\"方差与学习器\"><a href=\"#方差与学习器\" class=\"headerlink\" title=\"方差与学习器\"></a>方差与学习器</h2><blockquote>\n<p>方差描述了 <font color=\"#FF0000\"> 学习器的泛化能力</font>(对测试集)。</p>\n</blockquote>\n<p>学习器在测试集表现越好，则模型的方差越低。</p>\n<h2 id=\"偏差与方差之间的关系\"><a href=\"#偏差与方差之间的关系\" class=\"headerlink\" title=\"偏差与方差之间的关系\"></a>偏差与方差之间的关系</h2><blockquote>\n<p>我们最想要的是低偏差，低方差的模型，然而现实很难达到两者都极致的低。有时候需要用提高偏差来降低方差，毕竟模型的泛化能力十分重要。</p>\n</blockquote>\n<p>当损失函数达到极小值，模型对训练集的拟合达到了最佳效果，==对应着低偏差==，而这种情况下，往往对训练集的特点学的过于细微，而缺乏泛化能力。</p>\n<p>根据 ==奥坎姆剃刀原则==, 同样准确率，模型越简单越好，所以通过正则化等方式，削弱模型的拟合能力，降低过拟合的风险。通过提高偏差，来主动降低方差。</p>\n<p>最终我们要平衡方差与偏差，从而得到一个合理的模型。</p>\n<p><img src=\"/2019/08/01/机器学习模型的偏差与方差/biasvariance.png\" alt=\"biasvariance\"></p>\n<h2 id=\"调整方差与偏差的方法\"><a href=\"#调整方差与偏差的方法\" class=\"headerlink\" title=\"调整方差与偏差的方法\"></a>调整方差与偏差的方法</h2><p>待补充。。。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"机器学习的方差与偏差\"><a href=\"#机器学习的方差与偏差\" class=\"headerlink\" title=\"机器学习的方差与偏差\"></a>机器学习的方差与偏差</h1><blockquote>\n<p>方差与偏差，总是迷迷糊糊的，每次看了就会，过了就忘。今天看到一个非常棒的解释，迫不及待马上整理下来了。</p>\n</blockquote>\n<h2 id=\"机器学习的目标函数\"><a href=\"#机器学习的目标函数\" class=\"headerlink\" title=\"机器学习的目标函数\"></a>机器学习的目标函数</h2><p>机器学习模型学习的是数据集的条件概率分布，得到一个决策函数。整个学习过程围绕着最小化（或者最大化）目标函数进行优化参数，目标函数的通常形式的定义是：</p>\n<pre><code>Obj = L(θ) + λΩ(θ)\n</code></pre><p><code>L(θ)</code> 是损失函数，衡量模型对训练集拟合程度的好坏(对应偏差)；</p>\n<p><code>Ω(θ)</code> 是正则项，是衡量模型的复杂程度（对应方差）；</p>\n<font color=\"#FF0000\"> 目标函数定义为损失函数和正则项两部分，是为了平衡模型的偏差和方差（Bias Variance Trade-off）。</font> \n\n\n\n<h2 id=\"偏差与学习器\"><a href=\"#偏差与学习器\" class=\"headerlink\" title=\"偏差与学习器\"></a>偏差与学习器</h2><blockquote>\n<p>偏差描述了 <font color=\"#FF0000\">学习器的拟合能力</font> （对训练集的）。</p>\n</blockquote>\n<p>学习器在训练集表现越好，损失越低，则模型的偏差越小。</p>\n<h2 id=\"方差与学习器\"><a href=\"#方差与学习器\" class=\"headerlink\" title=\"方差与学习器\"></a>方差与学习器</h2><blockquote>\n<p>方差描述了 <font color=\"#FF0000\"> 学习器的泛化能力</font>(对测试集)。</p>\n</blockquote>\n<p>学习器在测试集表现越好，则模型的方差越低。</p>\n<h2 id=\"偏差与方差之间的关系\"><a href=\"#偏差与方差之间的关系\" class=\"headerlink\" title=\"偏差与方差之间的关系\"></a>偏差与方差之间的关系</h2><blockquote>\n<p>我们最想要的是低偏差，低方差的模型，然而现实很难达到两者都极致的低。有时候需要用提高偏差来降低方差，毕竟模型的泛化能力十分重要。</p>\n</blockquote>\n<p>当损失函数达到极小值，模型对训练集的拟合达到了最佳效果，==对应着低偏差==，而这种情况下，往往对训练集的特点学的过于细微，而缺乏泛化能力。</p>\n<p>根据 ==奥坎姆剃刀原则==, 同样准确率，模型越简单越好，所以通过正则化等方式，削弱模型的拟合能力，降低过拟合的风险。通过提高偏差，来主动降低方差。</p>\n<p>最终我们要平衡方差与偏差，从而得到一个合理的模型。</p>\n<p><img src=\"/2019/08/01/机器学习模型的偏差与方差/biasvariance.png\" alt=\"biasvariance\"></p>\n<h2 id=\"调整方差与偏差的方法\"><a href=\"#调整方差与偏差的方法\" class=\"headerlink\" title=\"调整方差与偏差的方法\"></a>调整方差与偏差的方法</h2><p>待补充。。。</p>\n"},{"title":"集成学习-Adaboost","date":"2019-06-25T10:57:01.000Z","top":true,"_content":"# Adaboost 算法原理及推导\n\n> Adaboost 是Boosting算法的代表。Boosting可将许多弱学习器组合达到强学习器的效果。\n\n> Adaboost 是通过提升错分数据的权重值来改善模型的不足。\n其主要的流程是：\n\n> 1. 先训练一个基学习器；\n> 2. 根据基学习器的表现，改变样本的分布，使得错误分类的样本得到更多的关注；\n> 3. 改变分布后的样本再训练新的基学习器，如此迭代；\n> 4. 加权组合这些基学习器。\n\n## 一、Adaboost算法原理\n\n> \"Adaptive Boosting\"（自适应增强）\n\nAdaboost算法中，每个样本有对应的权重D,每个基分类器也有对应的权重α，然后是下边的三步骤：\n\n    Step1：初始化训练集的权重；\n> 如果有N个样本，则每一个训练样本最开始时都被赋予相同的权重：1/N。\n\n    迭代：Step2： 改变样本分布，训练基学习器；\n> 错分的样本权重D会增加；准确率高的分类器的权重α会更大；\n\n    Step3: 加权组合弱学习器。\n    \n## 二、Adaboost算法推导\n\n给定训练集\n$$\nT=\\{(x 1, y 1),(x 2, y 2) \\ldots(\\mathrm{xN}, y \\mathrm{N})\\}\n$$\n其中，\n$$\ny_{i} \\in\\{-1,1\\}\n$$\n\n步骤1：初始化训练集的权重D。每个训练样本的初始权重w相同，均为1/N,\n\n$$\nD_{1}=\\left(w_{11}, w_{12} \\cdots w_{1 i} \\cdots, w_{1 N}\\right)\n$$\n\n$$\nw_{1 i}=\\frac{1}{N}, i=1,2, \\cdots, N\n$$\n\n步骤2：训练基学习器，改变训练样本分布，迭代训练新的学习器。\n用m=1,2...M 代表迭代的轮数，每轮产生的学习器为 $$h_{m}(x)$$\n\n- 计算学习器 $$h_{m}(x)$$ 在训练数据集上的分类错误率 $$E_{t}$$ (误差的权值和):\n\n\n $$E_{t}=P\\left(G_{m}(x) \\neq y_{i}\\right)$$\n\n\n $$=\\sum_{i=1}^{N} w_{m i} I\\left(G_{m}\\left(x_{i}\\right) \\neq y_{i}\\right)$$\n\n\n- 计算学习器 $$h_{m}(x)$$ 的权重α：\n\n $$\\alpha_{m}=\\frac{1}{2} \\ln \\frac{\\left(1-E_{m}\\right)}{E_{m}}$$\n\n- 更新训练集样本权重。\n\n$$D_{m+1}=\\left(w_{m+1,1}, w_{m+1,2} \\cdots w_{m+1, i} \\cdots, w_{m+1, N}\\right)$$\n\n$$w_{m+1, i}=\\frac{w_{m i}}{Z_{m}} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right), i=1,2, \\cdots, N$$\n\n这里的 $$Z_{m}$$ 时规范化因子:\n\n$$Z_{m}=\\sum_{i=1}^{N} w_{m i} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right)$$\n\n- 迭代训练学习器\n\n步骤3：加权组合弱学习器。\n\n$$f(x)=\\sum_{m=1}^{M} \\alpha_{m} h_{m}(x)$$\n\n$$H(x)=\\operatorname{sign}(f(x))=\\operatorname{sign}\\left(\\sum_{m=1}^{M} \\alpha_{m} h_{m}(x)\\right)$$\n\n\n","source":"_posts/集成学习-Adaboost.md","raw":"---\ntitle: 集成学习-Adaboost\ndate: 2019-06-25 18:57:01\ntags: 集成学习\ncategories: 机器学习方法\ntop: True\n---\n# Adaboost 算法原理及推导\n\n> Adaboost 是Boosting算法的代表。Boosting可将许多弱学习器组合达到强学习器的效果。\n\n> Adaboost 是通过提升错分数据的权重值来改善模型的不足。\n其主要的流程是：\n\n> 1. 先训练一个基学习器；\n> 2. 根据基学习器的表现，改变样本的分布，使得错误分类的样本得到更多的关注；\n> 3. 改变分布后的样本再训练新的基学习器，如此迭代；\n> 4. 加权组合这些基学习器。\n\n## 一、Adaboost算法原理\n\n> \"Adaptive Boosting\"（自适应增强）\n\nAdaboost算法中，每个样本有对应的权重D,每个基分类器也有对应的权重α，然后是下边的三步骤：\n\n    Step1：初始化训练集的权重；\n> 如果有N个样本，则每一个训练样本最开始时都被赋予相同的权重：1/N。\n\n    迭代：Step2： 改变样本分布，训练基学习器；\n> 错分的样本权重D会增加；准确率高的分类器的权重α会更大；\n\n    Step3: 加权组合弱学习器。\n    \n## 二、Adaboost算法推导\n\n给定训练集\n$$\nT=\\{(x 1, y 1),(x 2, y 2) \\ldots(\\mathrm{xN}, y \\mathrm{N})\\}\n$$\n其中，\n$$\ny_{i} \\in\\{-1,1\\}\n$$\n\n步骤1：初始化训练集的权重D。每个训练样本的初始权重w相同，均为1/N,\n\n$$\nD_{1}=\\left(w_{11}, w_{12} \\cdots w_{1 i} \\cdots, w_{1 N}\\right)\n$$\n\n$$\nw_{1 i}=\\frac{1}{N}, i=1,2, \\cdots, N\n$$\n\n步骤2：训练基学习器，改变训练样本分布，迭代训练新的学习器。\n用m=1,2...M 代表迭代的轮数，每轮产生的学习器为 $$h_{m}(x)$$\n\n- 计算学习器 $$h_{m}(x)$$ 在训练数据集上的分类错误率 $$E_{t}$$ (误差的权值和):\n\n\n $$E_{t}=P\\left(G_{m}(x) \\neq y_{i}\\right)$$\n\n\n $$=\\sum_{i=1}^{N} w_{m i} I\\left(G_{m}\\left(x_{i}\\right) \\neq y_{i}\\right)$$\n\n\n- 计算学习器 $$h_{m}(x)$$ 的权重α：\n\n $$\\alpha_{m}=\\frac{1}{2} \\ln \\frac{\\left(1-E_{m}\\right)}{E_{m}}$$\n\n- 更新训练集样本权重。\n\n$$D_{m+1}=\\left(w_{m+1,1}, w_{m+1,2} \\cdots w_{m+1, i} \\cdots, w_{m+1, N}\\right)$$\n\n$$w_{m+1, i}=\\frac{w_{m i}}{Z_{m}} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right), i=1,2, \\cdots, N$$\n\n这里的 $$Z_{m}$$ 时规范化因子:\n\n$$Z_{m}=\\sum_{i=1}^{N} w_{m i} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right)$$\n\n- 迭代训练学习器\n\n步骤3：加权组合弱学习器。\n\n$$f(x)=\\sum_{m=1}^{M} \\alpha_{m} h_{m}(x)$$\n\n$$H(x)=\\operatorname{sign}(f(x))=\\operatorname{sign}\\left(\\sum_{m=1}^{M} \\alpha_{m} h_{m}(x)\\right)$$\n\n\n","slug":"集成学习-Adaboost","published":1,"updated":"2019-07-30T15:35:42.744Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz98jgzl0015y0plmmrnwls6","content":"<h1 id=\"Adaboost-算法原理及推导\"><a href=\"#Adaboost-算法原理及推导\" class=\"headerlink\" title=\"Adaboost 算法原理及推导\"></a>Adaboost 算法原理及推导</h1><blockquote>\n<p>Adaboost 是Boosting算法的代表。Boosting可将许多弱学习器组合达到强学习器的效果。</p>\n<p>Adaboost 是通过提升错分数据的权重值来改善模型的不足。<br>其主要的流程是：</p>\n<ol>\n<li>先训练一个基学习器；</li>\n<li>根据基学习器的表现，改变样本的分布，使得错误分类的样本得到更多的关注；</li>\n<li>改变分布后的样本再训练新的基学习器，如此迭代；</li>\n<li>加权组合这些基学习器。</li>\n</ol>\n</blockquote>\n<h2 id=\"一、Adaboost算法原理\"><a href=\"#一、Adaboost算法原理\" class=\"headerlink\" title=\"一、Adaboost算法原理\"></a>一、Adaboost算法原理</h2><blockquote>\n<p>“Adaptive Boosting”（自适应增强）</p>\n</blockquote>\n<p>Adaboost算法中，每个样本有对应的权重D,每个基分类器也有对应的权重α，然后是下边的三步骤：</p>\n<pre><code>Step1：初始化训练集的权重；\n</code></pre><blockquote>\n<p>如果有N个样本，则每一个训练样本最开始时都被赋予相同的权重：1/N。</p>\n</blockquote>\n<pre><code>迭代：Step2： 改变样本分布，训练基学习器；\n</code></pre><blockquote>\n<p>错分的样本权重D会增加；准确率高的分类器的权重α会更大；</p>\n</blockquote>\n<pre><code>Step3: 加权组合弱学习器。\n</code></pre><h2 id=\"二、Adaboost算法推导\"><a href=\"#二、Adaboost算法推导\" class=\"headerlink\" title=\"二、Adaboost算法推导\"></a>二、Adaboost算法推导</h2><p>给定训练集</p>\n<script type=\"math/tex; mode=display\">\nT=\\{(x 1, y 1),(x 2, y 2) \\ldots(\\mathrm{xN}, y \\mathrm{N})\\}</script><p>其中，</p>\n<script type=\"math/tex; mode=display\">\ny_{i} \\in\\{-1,1\\}</script><p>步骤1：初始化训练集的权重D。每个训练样本的初始权重w相同，均为1/N,</p>\n<script type=\"math/tex; mode=display\">\nD_{1}=\\left(w_{11}, w_{12} \\cdots w_{1 i} \\cdots, w_{1 N}\\right)</script><script type=\"math/tex; mode=display\">\nw_{1 i}=\\frac{1}{N}, i=1,2, \\cdots, N</script><p>步骤2：训练基学习器，改变训练样本分布，迭代训练新的学习器。<br>用m=1,2…M 代表迭代的轮数，每轮产生的学习器为 <script type=\"math/tex\">h_{m}(x)</script></p>\n<ul>\n<li>计算学习器 <script type=\"math/tex\">h_{m}(x)</script> 在训练数据集上的分类错误率 <script type=\"math/tex\">E_{t}</script> (误差的权值和):</li>\n</ul>\n<script type=\"math/tex; mode=display\">E_{t}=P\\left(G_{m}(x) \\neq y_{i}\\right)</script><script type=\"math/tex; mode=display\">=\\sum_{i=1}^{N} w_{m i} I\\left(G_{m}\\left(x_{i}\\right) \\neq y_{i}\\right)</script><ul>\n<li><p>计算学习器 <script type=\"math/tex\">h_{m}(x)</script> 的权重α：</p>\n<script type=\"math/tex; mode=display\">\\alpha_{m}=\\frac{1}{2} \\ln \\frac{\\left(1-E_{m}\\right)}{E_{m}}</script></li>\n<li><p>更新训练集样本权重。</p>\n</li>\n</ul>\n<script type=\"math/tex; mode=display\">D_{m+1}=\\left(w_{m+1,1}, w_{m+1,2} \\cdots w_{m+1, i} \\cdots, w_{m+1, N}\\right)</script><script type=\"math/tex; mode=display\">w_{m+1, i}=\\frac{w_{m i}}{Z_{m}} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right), i=1,2, \\cdots, N</script><p>这里的 <script type=\"math/tex\">Z_{m}</script> 时规范化因子:</p>\n<script type=\"math/tex; mode=display\">Z_{m}=\\sum_{i=1}^{N} w_{m i} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right)</script><ul>\n<li>迭代训练学习器</li>\n</ul>\n<p>步骤3：加权组合弱学习器。</p>\n<script type=\"math/tex; mode=display\">f(x)=\\sum_{m=1}^{M} \\alpha_{m} h_{m}(x)</script><script type=\"math/tex; mode=display\">H(x)=\\operatorname{sign}(f(x))=\\operatorname{sign}\\left(\\sum_{m=1}^{M} \\alpha_{m} h_{m}(x)\\right)</script>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Adaboost-算法原理及推导\"><a href=\"#Adaboost-算法原理及推导\" class=\"headerlink\" title=\"Adaboost 算法原理及推导\"></a>Adaboost 算法原理及推导</h1><blockquote>\n<p>Adaboost 是Boosting算法的代表。Boosting可将许多弱学习器组合达到强学习器的效果。</p>\n<p>Adaboost 是通过提升错分数据的权重值来改善模型的不足。<br>其主要的流程是：</p>\n<ol>\n<li>先训练一个基学习器；</li>\n<li>根据基学习器的表现，改变样本的分布，使得错误分类的样本得到更多的关注；</li>\n<li>改变分布后的样本再训练新的基学习器，如此迭代；</li>\n<li>加权组合这些基学习器。</li>\n</ol>\n</blockquote>\n<h2 id=\"一、Adaboost算法原理\"><a href=\"#一、Adaboost算法原理\" class=\"headerlink\" title=\"一、Adaboost算法原理\"></a>一、Adaboost算法原理</h2><blockquote>\n<p>“Adaptive Boosting”（自适应增强）</p>\n</blockquote>\n<p>Adaboost算法中，每个样本有对应的权重D,每个基分类器也有对应的权重α，然后是下边的三步骤：</p>\n<pre><code>Step1：初始化训练集的权重；\n</code></pre><blockquote>\n<p>如果有N个样本，则每一个训练样本最开始时都被赋予相同的权重：1/N。</p>\n</blockquote>\n<pre><code>迭代：Step2： 改变样本分布，训练基学习器；\n</code></pre><blockquote>\n<p>错分的样本权重D会增加；准确率高的分类器的权重α会更大；</p>\n</blockquote>\n<pre><code>Step3: 加权组合弱学习器。\n</code></pre><h2 id=\"二、Adaboost算法推导\"><a href=\"#二、Adaboost算法推导\" class=\"headerlink\" title=\"二、Adaboost算法推导\"></a>二、Adaboost算法推导</h2><p>给定训练集</p>\n<script type=\"math/tex; mode=display\">\nT=\\{(x 1, y 1),(x 2, y 2) \\ldots(\\mathrm{xN}, y \\mathrm{N})\\}</script><p>其中，</p>\n<script type=\"math/tex; mode=display\">\ny_{i} \\in\\{-1,1\\}</script><p>步骤1：初始化训练集的权重D。每个训练样本的初始权重w相同，均为1/N,</p>\n<script type=\"math/tex; mode=display\">\nD_{1}=\\left(w_{11}, w_{12} \\cdots w_{1 i} \\cdots, w_{1 N}\\right)</script><script type=\"math/tex; mode=display\">\nw_{1 i}=\\frac{1}{N}, i=1,2, \\cdots, N</script><p>步骤2：训练基学习器，改变训练样本分布，迭代训练新的学习器。<br>用m=1,2…M 代表迭代的轮数，每轮产生的学习器为 <script type=\"math/tex\">h_{m}(x)</script></p>\n<ul>\n<li>计算学习器 <script type=\"math/tex\">h_{m}(x)</script> 在训练数据集上的分类错误率 <script type=\"math/tex\">E_{t}</script> (误差的权值和):</li>\n</ul>\n<script type=\"math/tex; mode=display\">E_{t}=P\\left(G_{m}(x) \\neq y_{i}\\right)</script><script type=\"math/tex; mode=display\">=\\sum_{i=1}^{N} w_{m i} I\\left(G_{m}\\left(x_{i}\\right) \\neq y_{i}\\right)</script><ul>\n<li><p>计算学习器 <script type=\"math/tex\">h_{m}(x)</script> 的权重α：</p>\n<script type=\"math/tex; mode=display\">\\alpha_{m}=\\frac{1}{2} \\ln \\frac{\\left(1-E_{m}\\right)}{E_{m}}</script></li>\n<li><p>更新训练集样本权重。</p>\n</li>\n</ul>\n<script type=\"math/tex; mode=display\">D_{m+1}=\\left(w_{m+1,1}, w_{m+1,2} \\cdots w_{m+1, i} \\cdots, w_{m+1, N}\\right)</script><script type=\"math/tex; mode=display\">w_{m+1, i}=\\frac{w_{m i}}{Z_{m}} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right), i=1,2, \\cdots, N</script><p>这里的 <script type=\"math/tex\">Z_{m}</script> 时规范化因子:</p>\n<script type=\"math/tex; mode=display\">Z_{m}=\\sum_{i=1}^{N} w_{m i} \\exp \\left(-\\alpha_{m} y_{i} G_{m}\\left(x_{i}\\right)\\right)</script><ul>\n<li>迭代训练学习器</li>\n</ul>\n<p>步骤3：加权组合弱学习器。</p>\n<script type=\"math/tex; mode=display\">f(x)=\\sum_{m=1}^{M} \\alpha_{m} h_{m}(x)</script><script type=\"math/tex; mode=display\">H(x)=\\operatorname{sign}(f(x))=\\operatorname{sign}\\left(\\sum_{m=1}^{M} \\alpha_{m} h_{m}(x)\\right)</script>"},{"title":"虚拟机类加载机制","date":"2019-04-14T06:11:58.000Z","copyright":true,"password":null,"top":true,"_content":"\n\n# 虚拟机类加载机制\n\n## 绑定\n> 绑定指的是把一个方法的调用与方法所在的类(方法主体)关联起来。\n\n- 静态绑定\n\n\t\n\n> 前期绑定。在程序执行前方法已经被绑定，此时由编译器或其它连接程序实现java当中的方法只有`final，static，private和构造方法` 是前期绑定的。\n\n- 动态绑定\n\n\t\n\n> 运行时绑定。在运行时根据具体对象的类型进行绑定。在java中，几乎所有的方法都是后期绑定的。\n\n\n\n\n## 类加载机制\n \n\n类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：**加载、验证、准备、解析、初始化、使用和卸载** 七个阶段，前五个阶段属于类加载的过程。这是开始顺序，每个阶段可能交错。\n\n\n\n### step1：加载\n\n#### 加载阶段，虚拟机完成的任务：\n\n- 通过一个类的全限定名来获取起定义的二进制字节流。\n\n> 二进制字节流来源： Class文件，Jar包、从网络中获取（最典型的应用便是Applet）、由其他文件生成（JSP应用）等；\n\n\n- 将该字节流的静态存储结构转换为方法区的运行时数据结构。\n\n\n- 在Java堆中声称一个代表这个类的 java.lang.Class对象，作为对方法区中这些对象的入口。\n\n#### 三种主要的类加载器？\n\n>  类加载机制采用了委托模式。 类加载器与类本身一同确定这个类在Java 虚拟机中的唯一性。\n\n1. 启动类加载器 *Bootstrap ClassLoader*\n\n> 该加载器由C++实现，不属于类，负责加载 ` /JDK/JRE/lib/rt.jar`，主要加载 JVM 工作需要的类；\n \n2. 扩展类加载器 *Extension ClassLoader*\n> Bootstrp loader 加载 ExtClassLoader,\n\t该加载器由sun.misc.Launcher$ExtClassLoader 实现，它负责加载`/JDK\\JRE\\lib\\ext目录中的类，自己的类打包jar放入也可以；\n3. 应用程序类加载器 *Application ClassLoader*\n> Bootstrp loader加载完ExtClassLoader后，就会加载AppClassLoader,并且将AppClassLoader的父加载器指定为 ExtClassLoader， 负责加载classpath所指定的位置的类。\n\n4. 自定义类加载器\n\n> 如果要自定义类加载器，需要继承 `应用程序类加载器`\n\n#### 三者如何协调工作？\n\n类加载机制采用了委托模式。启动类加载器加载其他类加载器，当需要加载类时，**优先父类加载器工作**。\n\n>   双亲委派模型的工作流程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。\n\n\n### step2：验证\n\n#### 验证的目的？\n\n保证`class 文件`的字节流符号JVM 虚拟机的要求，不危害虚拟机自身安全。虽然 Java 源码编译不会产生如数组越界之类的错误，但`class 文件`可以被编辑。\n\n#### 都需要哪些验证？\n\n- 文件格式验证\n\n> **验证字节流是否符合 `class文件规范`**（如开头是否为魔数`0xCAFEBABE`， 主次版本号是否可以被当前虚拟机处理等）\n\n\n- 元数据验证\n\n> ** 验证字节码描述的信息是否符合Java 语言规范**（如类的继承实现是否符合语法规范）\n- 字节码验证\n\n> 该阶段验证的主要工作是进行数据流和控制流分析，对类的方法体进行校验分析，以保证被校验的类的方法在运行时不会做出危害虚拟机安全的行为。\n\n\n- 符号引用验证\n\n> 发生在虚拟机将符号引用转化为直接引用的时候（解析阶段中发生该转化，后面会有讲解），主要是对类自身以外的信息（常量池中的各种符号引用）进行匹配性的校验。\n\n### step3： 准备\n\n 准备阶段是正式为**类变量**（静态变量）分配内存并设置类变量初始值的阶段，**这些内存都将在方法区中分配**。注意的是：\n\n1. 只为类变量分配内存；\n\n\n2. static 类变量初始值为默认初始值，而不是程序中的值；\n\n\n\tpublic static int value = 3；  // 实际初始值为0\n3. 同时被final和static修饰，那么在准备阶段变量value就会被初始化为ConstValue属性所指定的值；\n\n    public static final int value = 3；  // 实际初始值为3\n\n\n### step4： 解析\n\n> 解析阶段是虚拟机将常量池中的符号引用转化为直接引用的过程。\n\n\n>  解析动作主要针对类或接口、字段、类方法、接口方法四类符号引用进行，分别对应于常量池中的CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info、CONSTANT_InterfaceMethodref_info四种常量类型。\n\n\n### step5： 初始化\n\n> 真正开始执行类中定义的Java程序代码,初始化阶段是执行类构造器<clinit>()方法的过程。\n\n类构造器 `<clinit>()` 执行规则：\n\n1. 按照在源文件中出现的顺序收集`类变量` 和 ` 静态语句块 static{ }`;\n2. 静态语句块中只能访问定义在之前的变量，而在块后定义的变量只能被赋值，但不能被访问；\n3. 优先构造父类；\n4. 父类中的 ` 静态语句块 static{ }` 优先于子类中的变量赋值操作；\n5. 不是必须的，当类或者接口中没有静态语句块或者没有变量赋值，则可以不生成`<clinit>()`；\n\n\n## 双亲委派被破坏 3种情况下\n\n- 第一次： JDK1.2之前还没有双亲委派，但是有用户自定义类加载器（通过`loadClass（）`加载），为了兼容老版本，设计者添加了 ` protected findClass()`，直接调用用户`loadClass（）`方法；\n\n\n- 第二次：原则上 **越基础的类由越上层的加载器进行加载**,但是有些情况下基础类需要调用用户的代码。如**JNDI, JDBC，JCE,JAXB，JBI**,这时候引入了`线程上下文加载器`；\n\n- 第三次：“代码热替换”和“模块热部署”出现，希望程序中的功能模块像键盘鼠标一样直接更换，而不是重启。**OSGi** 是这个标准化模块，具体还没看。。。\n","source":"_posts/虚拟机类加载机制.md","raw":"---\ntitle: 虚拟机类加载机制\ndate: 2019-04-14 14:11:58\ncategories: 深入理解Java 虚拟机\ntags: Java类加载机制\ncopyright: True\npassword:\ntop: True\n---\n\n\n# 虚拟机类加载机制\n\n## 绑定\n> 绑定指的是把一个方法的调用与方法所在的类(方法主体)关联起来。\n\n- 静态绑定\n\n\t\n\n> 前期绑定。在程序执行前方法已经被绑定，此时由编译器或其它连接程序实现java当中的方法只有`final，static，private和构造方法` 是前期绑定的。\n\n- 动态绑定\n\n\t\n\n> 运行时绑定。在运行时根据具体对象的类型进行绑定。在java中，几乎所有的方法都是后期绑定的。\n\n\n\n\n## 类加载机制\n \n\n类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：**加载、验证、准备、解析、初始化、使用和卸载** 七个阶段，前五个阶段属于类加载的过程。这是开始顺序，每个阶段可能交错。\n\n\n\n### step1：加载\n\n#### 加载阶段，虚拟机完成的任务：\n\n- 通过一个类的全限定名来获取起定义的二进制字节流。\n\n> 二进制字节流来源： Class文件，Jar包、从网络中获取（最典型的应用便是Applet）、由其他文件生成（JSP应用）等；\n\n\n- 将该字节流的静态存储结构转换为方法区的运行时数据结构。\n\n\n- 在Java堆中声称一个代表这个类的 java.lang.Class对象，作为对方法区中这些对象的入口。\n\n#### 三种主要的类加载器？\n\n>  类加载机制采用了委托模式。 类加载器与类本身一同确定这个类在Java 虚拟机中的唯一性。\n\n1. 启动类加载器 *Bootstrap ClassLoader*\n\n> 该加载器由C++实现，不属于类，负责加载 ` /JDK/JRE/lib/rt.jar`，主要加载 JVM 工作需要的类；\n \n2. 扩展类加载器 *Extension ClassLoader*\n> Bootstrp loader 加载 ExtClassLoader,\n\t该加载器由sun.misc.Launcher$ExtClassLoader 实现，它负责加载`/JDK\\JRE\\lib\\ext目录中的类，自己的类打包jar放入也可以；\n3. 应用程序类加载器 *Application ClassLoader*\n> Bootstrp loader加载完ExtClassLoader后，就会加载AppClassLoader,并且将AppClassLoader的父加载器指定为 ExtClassLoader， 负责加载classpath所指定的位置的类。\n\n4. 自定义类加载器\n\n> 如果要自定义类加载器，需要继承 `应用程序类加载器`\n\n#### 三者如何协调工作？\n\n类加载机制采用了委托模式。启动类加载器加载其他类加载器，当需要加载类时，**优先父类加载器工作**。\n\n>   双亲委派模型的工作流程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。\n\n\n### step2：验证\n\n#### 验证的目的？\n\n保证`class 文件`的字节流符号JVM 虚拟机的要求，不危害虚拟机自身安全。虽然 Java 源码编译不会产生如数组越界之类的错误，但`class 文件`可以被编辑。\n\n#### 都需要哪些验证？\n\n- 文件格式验证\n\n> **验证字节流是否符合 `class文件规范`**（如开头是否为魔数`0xCAFEBABE`， 主次版本号是否可以被当前虚拟机处理等）\n\n\n- 元数据验证\n\n> ** 验证字节码描述的信息是否符合Java 语言规范**（如类的继承实现是否符合语法规范）\n- 字节码验证\n\n> 该阶段验证的主要工作是进行数据流和控制流分析，对类的方法体进行校验分析，以保证被校验的类的方法在运行时不会做出危害虚拟机安全的行为。\n\n\n- 符号引用验证\n\n> 发生在虚拟机将符号引用转化为直接引用的时候（解析阶段中发生该转化，后面会有讲解），主要是对类自身以外的信息（常量池中的各种符号引用）进行匹配性的校验。\n\n### step3： 准备\n\n 准备阶段是正式为**类变量**（静态变量）分配内存并设置类变量初始值的阶段，**这些内存都将在方法区中分配**。注意的是：\n\n1. 只为类变量分配内存；\n\n\n2. static 类变量初始值为默认初始值，而不是程序中的值；\n\n\n\tpublic static int value = 3；  // 实际初始值为0\n3. 同时被final和static修饰，那么在准备阶段变量value就会被初始化为ConstValue属性所指定的值；\n\n    public static final int value = 3；  // 实际初始值为3\n\n\n### step4： 解析\n\n> 解析阶段是虚拟机将常量池中的符号引用转化为直接引用的过程。\n\n\n>  解析动作主要针对类或接口、字段、类方法、接口方法四类符号引用进行，分别对应于常量池中的CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info、CONSTANT_InterfaceMethodref_info四种常量类型。\n\n\n### step5： 初始化\n\n> 真正开始执行类中定义的Java程序代码,初始化阶段是执行类构造器<clinit>()方法的过程。\n\n类构造器 `<clinit>()` 执行规则：\n\n1. 按照在源文件中出现的顺序收集`类变量` 和 ` 静态语句块 static{ }`;\n2. 静态语句块中只能访问定义在之前的变量，而在块后定义的变量只能被赋值，但不能被访问；\n3. 优先构造父类；\n4. 父类中的 ` 静态语句块 static{ }` 优先于子类中的变量赋值操作；\n5. 不是必须的，当类或者接口中没有静态语句块或者没有变量赋值，则可以不生成`<clinit>()`；\n\n\n## 双亲委派被破坏 3种情况下\n\n- 第一次： JDK1.2之前还没有双亲委派，但是有用户自定义类加载器（通过`loadClass（）`加载），为了兼容老版本，设计者添加了 ` protected findClass()`，直接调用用户`loadClass（）`方法；\n\n\n- 第二次：原则上 **越基础的类由越上层的加载器进行加载**,但是有些情况下基础类需要调用用户的代码。如**JNDI, JDBC，JCE,JAXB，JBI**,这时候引入了`线程上下文加载器`；\n\n- 第三次：“代码热替换”和“模块热部署”出现，希望程序中的功能模块像键盘鼠标一样直接更换，而不是重启。**OSGi** 是这个标准化模块，具体还没看。。。\n","slug":"虚拟机类加载机制","published":1,"updated":"2019-07-30T15:35:42.744Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz98jgzn0019y0plvf71njsb","content":"<h1 id=\"虚拟机类加载机制\"><a href=\"#虚拟机类加载机制\" class=\"headerlink\" title=\"虚拟机类加载机制\"></a>虚拟机类加载机制</h1><h2 id=\"绑定\"><a href=\"#绑定\" class=\"headerlink\" title=\"绑定\"></a>绑定</h2><blockquote>\n<p>绑定指的是把一个方法的调用与方法所在的类(方法主体)关联起来。</p>\n</blockquote>\n<ul>\n<li>静态绑定</li>\n</ul>\n<blockquote>\n<p>前期绑定。在程序执行前方法已经被绑定，此时由编译器或其它连接程序实现java当中的方法只有<code>final，static，private和构造方法</code> 是前期绑定的。</p>\n</blockquote>\n<ul>\n<li>动态绑定</li>\n</ul>\n<blockquote>\n<p>运行时绑定。在运行时根据具体对象的类型进行绑定。在java中，几乎所有的方法都是后期绑定的。</p>\n</blockquote>\n<h2 id=\"类加载机制\"><a href=\"#类加载机制\" class=\"headerlink\" title=\"类加载机制\"></a>类加载机制</h2><p>类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：<strong>加载、验证、准备、解析、初始化、使用和卸载</strong> 七个阶段，前五个阶段属于类加载的过程。这是开始顺序，每个阶段可能交错。</p>\n<h3 id=\"step1：加载\"><a href=\"#step1：加载\" class=\"headerlink\" title=\"step1：加载\"></a>step1：加载</h3><h4 id=\"加载阶段，虚拟机完成的任务：\"><a href=\"#加载阶段，虚拟机完成的任务：\" class=\"headerlink\" title=\"加载阶段，虚拟机完成的任务：\"></a>加载阶段，虚拟机完成的任务：</h4><ul>\n<li>通过一个类的全限定名来获取起定义的二进制字节流。</li>\n</ul>\n<blockquote>\n<p>二进制字节流来源： Class文件，Jar包、从网络中获取（最典型的应用便是Applet）、由其他文件生成（JSP应用）等；</p>\n</blockquote>\n<ul>\n<li>将该字节流的静态存储结构转换为方法区的运行时数据结构。</li>\n</ul>\n<ul>\n<li>在Java堆中声称一个代表这个类的 java.lang.Class对象，作为对方法区中这些对象的入口。</li>\n</ul>\n<h4 id=\"三种主要的类加载器？\"><a href=\"#三种主要的类加载器？\" class=\"headerlink\" title=\"三种主要的类加载器？\"></a>三种主要的类加载器？</h4><blockquote>\n<p> 类加载机制采用了委托模式。 类加载器与类本身一同确定这个类在Java 虚拟机中的唯一性。</p>\n</blockquote>\n<ol>\n<li>启动类加载器 <em>Bootstrap ClassLoader</em></li>\n</ol>\n<blockquote>\n<p>该加载器由C++实现，不属于类，负责加载 <code>/JDK/JRE/lib/rt.jar</code>，主要加载 JVM 工作需要的类；</p>\n</blockquote>\n<ol>\n<li>扩展类加载器 <em>Extension ClassLoader</em><blockquote>\n<p>Bootstrp loader 加载 ExtClassLoader,<br> 该加载器由sun.misc.Launcher$ExtClassLoader 实现，它负责加载`/JDK\\JRE\\lib\\ext目录中的类，自己的类打包jar放入也可以；</p>\n</blockquote>\n</li>\n<li><p>应用程序类加载器 <em>Application ClassLoader</em></p>\n<blockquote>\n<p>Bootstrp loader加载完ExtClassLoader后，就会加载AppClassLoader,并且将AppClassLoader的父加载器指定为 ExtClassLoader， 负责加载classpath所指定的位置的类。</p>\n</blockquote>\n</li>\n<li><p>自定义类加载器</p>\n</li>\n</ol>\n<blockquote>\n<p>如果要自定义类加载器，需要继承 <code>应用程序类加载器</code></p>\n</blockquote>\n<h4 id=\"三者如何协调工作？\"><a href=\"#三者如何协调工作？\" class=\"headerlink\" title=\"三者如何协调工作？\"></a>三者如何协调工作？</h4><p>类加载机制采用了委托模式。启动类加载器加载其他类加载器，当需要加载类时，<strong>优先父类加载器工作</strong>。</p>\n<blockquote>\n<p>  双亲委派模型的工作流程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。</p>\n</blockquote>\n<h3 id=\"step2：验证\"><a href=\"#step2：验证\" class=\"headerlink\" title=\"step2：验证\"></a>step2：验证</h3><h4 id=\"验证的目的？\"><a href=\"#验证的目的？\" class=\"headerlink\" title=\"验证的目的？\"></a>验证的目的？</h4><p>保证<code>class 文件</code>的字节流符号JVM 虚拟机的要求，不危害虚拟机自身安全。虽然 Java 源码编译不会产生如数组越界之类的错误，但<code>class 文件</code>可以被编辑。</p>\n<h4 id=\"都需要哪些验证？\"><a href=\"#都需要哪些验证？\" class=\"headerlink\" title=\"都需要哪些验证？\"></a>都需要哪些验证？</h4><ul>\n<li>文件格式验证</li>\n</ul>\n<blockquote>\n<p><strong>验证字节流是否符合 <code>class文件规范</code></strong>（如开头是否为魔数<code>0xCAFEBABE</code>， 主次版本号是否可以被当前虚拟机处理等）</p>\n</blockquote>\n<ul>\n<li>元数据验证</li>\n</ul>\n<blockquote>\n<p><strong> 验证字节码描述的信息是否符合Java 语言规范</strong>（如类的继承实现是否符合语法规范）</p>\n<ul>\n<li>字节码验证</li>\n</ul>\n<p>该阶段验证的主要工作是进行数据流和控制流分析，对类的方法体进行校验分析，以保证被校验的类的方法在运行时不会做出危害虚拟机安全的行为。</p>\n</blockquote>\n<ul>\n<li>符号引用验证</li>\n</ul>\n<blockquote>\n<p>发生在虚拟机将符号引用转化为直接引用的时候（解析阶段中发生该转化，后面会有讲解），主要是对类自身以外的信息（常量池中的各种符号引用）进行匹配性的校验。</p>\n</blockquote>\n<h3 id=\"step3：-准备\"><a href=\"#step3：-准备\" class=\"headerlink\" title=\"step3： 准备\"></a>step3： 准备</h3><p> 准备阶段是正式为<strong>类变量</strong>（静态变量）分配内存并设置类变量初始值的阶段，<strong>这些内存都将在方法区中分配</strong>。注意的是：</p>\n<ol>\n<li>只为类变量分配内存；</li>\n</ol>\n<ol>\n<li>static 类变量初始值为默认初始值，而不是程序中的值；</li>\n</ol>\n<pre><code>public static int value = 3；  // 实际初始值为0\n</code></pre><ol>\n<li><p>同时被final和static修饰，那么在准备阶段变量value就会被初始化为ConstValue属性所指定的值；</p>\n<p> public static final int value = 3；  // 实际初始值为3</p>\n</li>\n</ol>\n<h3 id=\"step4：-解析\"><a href=\"#step4：-解析\" class=\"headerlink\" title=\"step4： 解析\"></a>step4： 解析</h3><blockquote>\n<p>解析阶段是虚拟机将常量池中的符号引用转化为直接引用的过程。</p>\n<p> 解析动作主要针对类或接口、字段、类方法、接口方法四类符号引用进行，分别对应于常量池中的CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info、CONSTANT_InterfaceMethodref_info四种常量类型。</p>\n</blockquote>\n<h3 id=\"step5：-初始化\"><a href=\"#step5：-初始化\" class=\"headerlink\" title=\"step5： 初始化\"></a>step5： 初始化</h3><blockquote>\n<p>真正开始执行类中定义的Java程序代码,初始化阶段是执行类构造器<clinit>()方法的过程。</clinit></p>\n</blockquote>\n<p>类构造器 <code>&lt;clinit&gt;()</code> 执行规则：</p>\n<ol>\n<li>按照在源文件中出现的顺序收集<code>类变量</code> 和 <code>静态语句块 static{ }</code>;</li>\n<li>静态语句块中只能访问定义在之前的变量，而在块后定义的变量只能被赋值，但不能被访问；</li>\n<li>优先构造父类；</li>\n<li>父类中的 <code>静态语句块 static{ }</code> 优先于子类中的变量赋值操作；</li>\n<li>不是必须的，当类或者接口中没有静态语句块或者没有变量赋值，则可以不生成<code>&lt;clinit&gt;()</code>；</li>\n</ol>\n<h2 id=\"双亲委派被破坏-3种情况下\"><a href=\"#双亲委派被破坏-3种情况下\" class=\"headerlink\" title=\"双亲委派被破坏 3种情况下\"></a>双亲委派被破坏 3种情况下</h2><ul>\n<li>第一次： JDK1.2之前还没有双亲委派，但是有用户自定义类加载器（通过<code>loadClass（）</code>加载），为了兼容老版本，设计者添加了 <code>protected findClass()</code>，直接调用用户<code>loadClass（）</code>方法；</li>\n</ul>\n<ul>\n<li><p>第二次：原则上 <strong>越基础的类由越上层的加载器进行加载</strong>,但是有些情况下基础类需要调用用户的代码。如<strong>JNDI, JDBC，JCE,JAXB，JBI</strong>,这时候引入了<code>线程上下文加载器</code>；</p>\n</li>\n<li><p>第三次：“代码热替换”和“模块热部署”出现，希望程序中的功能模块像键盘鼠标一样直接更换，而不是重启。<strong>OSGi</strong> 是这个标准化模块，具体还没看。。。</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"虚拟机类加载机制\"><a href=\"#虚拟机类加载机制\" class=\"headerlink\" title=\"虚拟机类加载机制\"></a>虚拟机类加载机制</h1><h2 id=\"绑定\"><a href=\"#绑定\" class=\"headerlink\" title=\"绑定\"></a>绑定</h2><blockquote>\n<p>绑定指的是把一个方法的调用与方法所在的类(方法主体)关联起来。</p>\n</blockquote>\n<ul>\n<li>静态绑定</li>\n</ul>\n<blockquote>\n<p>前期绑定。在程序执行前方法已经被绑定，此时由编译器或其它连接程序实现java当中的方法只有<code>final，static，private和构造方法</code> 是前期绑定的。</p>\n</blockquote>\n<ul>\n<li>动态绑定</li>\n</ul>\n<blockquote>\n<p>运行时绑定。在运行时根据具体对象的类型进行绑定。在java中，几乎所有的方法都是后期绑定的。</p>\n</blockquote>\n<h2 id=\"类加载机制\"><a href=\"#类加载机制\" class=\"headerlink\" title=\"类加载机制\"></a>类加载机制</h2><p>类从被加载到虚拟机内存中开始，到卸载出内存为止，它的整个生命周期包括：<strong>加载、验证、准备、解析、初始化、使用和卸载</strong> 七个阶段，前五个阶段属于类加载的过程。这是开始顺序，每个阶段可能交错。</p>\n<h3 id=\"step1：加载\"><a href=\"#step1：加载\" class=\"headerlink\" title=\"step1：加载\"></a>step1：加载</h3><h4 id=\"加载阶段，虚拟机完成的任务：\"><a href=\"#加载阶段，虚拟机完成的任务：\" class=\"headerlink\" title=\"加载阶段，虚拟机完成的任务：\"></a>加载阶段，虚拟机完成的任务：</h4><ul>\n<li>通过一个类的全限定名来获取起定义的二进制字节流。</li>\n</ul>\n<blockquote>\n<p>二进制字节流来源： Class文件，Jar包、从网络中获取（最典型的应用便是Applet）、由其他文件生成（JSP应用）等；</p>\n</blockquote>\n<ul>\n<li>将该字节流的静态存储结构转换为方法区的运行时数据结构。</li>\n</ul>\n<ul>\n<li>在Java堆中声称一个代表这个类的 java.lang.Class对象，作为对方法区中这些对象的入口。</li>\n</ul>\n<h4 id=\"三种主要的类加载器？\"><a href=\"#三种主要的类加载器？\" class=\"headerlink\" title=\"三种主要的类加载器？\"></a>三种主要的类加载器？</h4><blockquote>\n<p> 类加载机制采用了委托模式。 类加载器与类本身一同确定这个类在Java 虚拟机中的唯一性。</p>\n</blockquote>\n<ol>\n<li>启动类加载器 <em>Bootstrap ClassLoader</em></li>\n</ol>\n<blockquote>\n<p>该加载器由C++实现，不属于类，负责加载 <code>/JDK/JRE/lib/rt.jar</code>，主要加载 JVM 工作需要的类；</p>\n</blockquote>\n<ol>\n<li>扩展类加载器 <em>Extension ClassLoader</em><blockquote>\n<p>Bootstrp loader 加载 ExtClassLoader,<br> 该加载器由sun.misc.Launcher$ExtClassLoader 实现，它负责加载`/JDK\\JRE\\lib\\ext目录中的类，自己的类打包jar放入也可以；</p>\n</blockquote>\n</li>\n<li><p>应用程序类加载器 <em>Application ClassLoader</em></p>\n<blockquote>\n<p>Bootstrp loader加载完ExtClassLoader后，就会加载AppClassLoader,并且将AppClassLoader的父加载器指定为 ExtClassLoader， 负责加载classpath所指定的位置的类。</p>\n</blockquote>\n</li>\n<li><p>自定义类加载器</p>\n</li>\n</ol>\n<blockquote>\n<p>如果要自定义类加载器，需要继承 <code>应用程序类加载器</code></p>\n</blockquote>\n<h4 id=\"三者如何协调工作？\"><a href=\"#三者如何协调工作？\" class=\"headerlink\" title=\"三者如何协调工作？\"></a>三者如何协调工作？</h4><p>类加载机制采用了委托模式。启动类加载器加载其他类加载器，当需要加载类时，<strong>优先父类加载器工作</strong>。</p>\n<blockquote>\n<p>  双亲委派模型的工作流程是：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把请求委托给父加载器去完成，依次向上，因此，所有的类加载请求最终都应该被传递到顶层的启动类加载器中，只有当父加载器在它的搜索范围中没有找到所需的类时，即无法完成该加载，子加载器才会尝试自己去加载该类。</p>\n</blockquote>\n<h3 id=\"step2：验证\"><a href=\"#step2：验证\" class=\"headerlink\" title=\"step2：验证\"></a>step2：验证</h3><h4 id=\"验证的目的？\"><a href=\"#验证的目的？\" class=\"headerlink\" title=\"验证的目的？\"></a>验证的目的？</h4><p>保证<code>class 文件</code>的字节流符号JVM 虚拟机的要求，不危害虚拟机自身安全。虽然 Java 源码编译不会产生如数组越界之类的错误，但<code>class 文件</code>可以被编辑。</p>\n<h4 id=\"都需要哪些验证？\"><a href=\"#都需要哪些验证？\" class=\"headerlink\" title=\"都需要哪些验证？\"></a>都需要哪些验证？</h4><ul>\n<li>文件格式验证</li>\n</ul>\n<blockquote>\n<p><strong>验证字节流是否符合 <code>class文件规范</code></strong>（如开头是否为魔数<code>0xCAFEBABE</code>， 主次版本号是否可以被当前虚拟机处理等）</p>\n</blockquote>\n<ul>\n<li>元数据验证</li>\n</ul>\n<blockquote>\n<p><strong> 验证字节码描述的信息是否符合Java 语言规范</strong>（如类的继承实现是否符合语法规范）</p>\n<ul>\n<li>字节码验证</li>\n</ul>\n<p>该阶段验证的主要工作是进行数据流和控制流分析，对类的方法体进行校验分析，以保证被校验的类的方法在运行时不会做出危害虚拟机安全的行为。</p>\n</blockquote>\n<ul>\n<li>符号引用验证</li>\n</ul>\n<blockquote>\n<p>发生在虚拟机将符号引用转化为直接引用的时候（解析阶段中发生该转化，后面会有讲解），主要是对类自身以外的信息（常量池中的各种符号引用）进行匹配性的校验。</p>\n</blockquote>\n<h3 id=\"step3：-准备\"><a href=\"#step3：-准备\" class=\"headerlink\" title=\"step3： 准备\"></a>step3： 准备</h3><p> 准备阶段是正式为<strong>类变量</strong>（静态变量）分配内存并设置类变量初始值的阶段，<strong>这些内存都将在方法区中分配</strong>。注意的是：</p>\n<ol>\n<li>只为类变量分配内存；</li>\n</ol>\n<ol>\n<li>static 类变量初始值为默认初始值，而不是程序中的值；</li>\n</ol>\n<pre><code>public static int value = 3；  // 实际初始值为0\n</code></pre><ol>\n<li><p>同时被final和static修饰，那么在准备阶段变量value就会被初始化为ConstValue属性所指定的值；</p>\n<p> public static final int value = 3；  // 实际初始值为3</p>\n</li>\n</ol>\n<h3 id=\"step4：-解析\"><a href=\"#step4：-解析\" class=\"headerlink\" title=\"step4： 解析\"></a>step4： 解析</h3><blockquote>\n<p>解析阶段是虚拟机将常量池中的符号引用转化为直接引用的过程。</p>\n<p> 解析动作主要针对类或接口、字段、类方法、接口方法四类符号引用进行，分别对应于常量池中的CONSTANT_Class_info、CONSTANT_Fieldref_info、CONSTANT_Methodref_info、CONSTANT_InterfaceMethodref_info四种常量类型。</p>\n</blockquote>\n<h3 id=\"step5：-初始化\"><a href=\"#step5：-初始化\" class=\"headerlink\" title=\"step5： 初始化\"></a>step5： 初始化</h3><blockquote>\n<p>真正开始执行类中定义的Java程序代码,初始化阶段是执行类构造器<clinit>()方法的过程。</clinit></p>\n</blockquote>\n<p>类构造器 <code>&lt;clinit&gt;()</code> 执行规则：</p>\n<ol>\n<li>按照在源文件中出现的顺序收集<code>类变量</code> 和 <code>静态语句块 static{ }</code>;</li>\n<li>静态语句块中只能访问定义在之前的变量，而在块后定义的变量只能被赋值，但不能被访问；</li>\n<li>优先构造父类；</li>\n<li>父类中的 <code>静态语句块 static{ }</code> 优先于子类中的变量赋值操作；</li>\n<li>不是必须的，当类或者接口中没有静态语句块或者没有变量赋值，则可以不生成<code>&lt;clinit&gt;()</code>；</li>\n</ol>\n<h2 id=\"双亲委派被破坏-3种情况下\"><a href=\"#双亲委派被破坏-3种情况下\" class=\"headerlink\" title=\"双亲委派被破坏 3种情况下\"></a>双亲委派被破坏 3种情况下</h2><ul>\n<li>第一次： JDK1.2之前还没有双亲委派，但是有用户自定义类加载器（通过<code>loadClass（）</code>加载），为了兼容老版本，设计者添加了 <code>protected findClass()</code>，直接调用用户<code>loadClass（）</code>方法；</li>\n</ul>\n<ul>\n<li><p>第二次：原则上 <strong>越基础的类由越上层的加载器进行加载</strong>,但是有些情况下基础类需要调用用户的代码。如<strong>JNDI, JDBC，JCE,JAXB，JBI</strong>,这时候引入了<code>线程上下文加载器</code>；</p>\n</li>\n<li><p>第三次：“代码热替换”和“模块热部署”出现，希望程序中的功能模块像键盘鼠标一样直接更换，而不是重启。<strong>OSGi</strong> 是这个标准化模块，具体还没看。。。</p>\n</li>\n</ul>\n"},{"title":"华为软挑2019","date":"2019-04-01T10:19:34.000Z","copyright":null,"_content":"\n# 参加软挑的一些感悟\n## 写在前边的话\n　　\n\n> 我本科一直在做嵌入式相关的项目,这是第一次参加软件类的竞赛,不得不说过程确实很刺激,最后止步杭厦赛区50强也很是遗憾,明明很接近,最后输在了代码效率上,本地成绩很好的 `python代码` ,上传测评运行时间超限（官测环境比本地性能好，普遍情况是用时远超本地，其中华为云主机集体宕机半小时，很多人测过的最优代码，最后再上传就超时了[https://bbs.huaweicloud.com/forum/thread-16237-1-1.html](https://bbs.huaweicloud.com/forum/thread-16237-1-1.html)）。超限原因主要两点，一是自己在实现调度器时的代码臃肿，二是正式赛数据量大增。但进入32强的不少组并没有实现调度器，完全 `随机时间发车+单车路径最优规划` , 感觉很(￣_,￣ )。这比赛不实现调度器，意义少了一半，再用上这种偷鸡方法，没觉出来还有啥意义。唉，菜鸡就是菜鸡。总之，这次经历对我还是有不少积极的影响的，下面就总结一下吧。\n\n\n## 题目解读\n本次比赛主要做的是 `动态路网下多车辆调度问题`, <font color=\"red\"><big>参赛者合理安排数万车辆在合理时间从出发点到达各自的目的地，程序上传至官方服务器，运行后得出 **所有车辆出发时间和规划的路径** ，将在官方调度器中进行调度，完成车辆调度用时即为最终成绩。</big></font>具体是比赛任务书中花了很大篇幅讲了官方调度器的规则，并且论坛前期几乎天天在更新规则补充，最终完全准确实现的队伍只见过一个，其他很对队伍是很接近，但总有差别。我们自己实现的调度器，调度时间完全对的上，但是所有车辆调度总时间总是差了一些。分析原因有以下两点:   \n \n1. 我们实现的调度规则还有与官方一些差异；（但是我们实现的和部分队伍对比的结果完全一致，但和官网就有差异，猜测可能有些规则官方描述的有些差异，或者某细节被我们忽略了）\n2. python 即使版本相同，但是在不同机器上结果确实有差异，这个也被官方证实了[https://bbs.huaweicloud.com/forum/thread-15889-1-1.html](https://bbs.huaweicloud.com/forum/thread-15889-1-1.html)。\n\n总体上参考任务书，下面只简单梳理一下思路（这里默认已经熟悉了任务书）：\n\n下面先附上官方伪代码\n\n        for(/* 按时间片处理 */) {\n\n           foreach(roads) {\n\n                /* 调整所有道路上在道路上的车辆，让道路上车辆前进，只要不出路口且可以到达终止状态的车辆\n                 * 分别标记出来等待的车辆（要出路口的车辆，或者因为要出路口的车辆阻挡而不能前进的车辆）\n                 * 和终止状态的车辆（在该车道内可以经过这一次调度可以行驶其最大可行驶距离的车辆）*/\n                driveAllCarJustOnRoadToEndState(allChannle);/* 对所有车道进行调整 */\n\n                /* driveAllCarJustOnRoadToEndState该处理内的算法与性能自行考虑 */\n           }\n\n            \n            while(/* all car in road run into end state */){\n\n                /* driveAllWaitCar() */\n\n                foreach(crosses){\n\n                    foreach(roads){\n\n\t\t\t\t\t\twhile(/* wait car on the road */){\n\n\t\t\t\t\t\t    Direction dir = getDirection();\n\n\t\t\t\t\t\t    Car car = getCarFromRoad(road, dir);\n\n\t\t\t\t\t\t    if (conflict）{\n\t\t\t\t\t\t    \tbreak;\n\t\t\t\t\t\t    }\n\n\t\t\t    channle = car.getChannel();\n\t\t\t    \n\t\t\t    /* 这里只指因下一道路有等待车辆阻挡而导致该车辆无法进入的情况 */\n\t\t\t    /* 其他情况均返回true,比如下一车道满无法进入（全是终态），或才是下一车道限速不能进入，该车辆停留在其当前车道最前方 */\n\t\t\t    /* 该车辆也是移动至其所在车道最前方，只有有车辆由等待变以终止，就对其车道后续车辆状态进行调整 */\n    \t\t    if(!car.moveToNextRoad()) {\n    \t\t        break;\n    \t\t    }\n\t\t\t    \n\t\t\t    /* driveAllCarJustOnRoadToEndState该处理内的算法与性能自行考虑 */\n\n\t\t\t    driveAllCarJustOnRoadToEndState(channel);\n\t\t\t\t\t}\n\t\t    \t}\n              }\n            }\n\n            /* 车库中的车辆上路行驶 */\n            driveCarInGarage();\n        }\n\n\n\n- 要调度的车辆分两种：<font color=\"red\"><big>路上的车和要上路的车</big></font>\n\n\n- 每个时间片<font color=\"red\">先处理路上车，在处理上路车</font>\n\n\n- 路上的车处理步骤： <font color=\"red\"><big>step1标记状态， step2 移动车辆 </big></font>\n\n\n- 车的状态：每个时间片（一个时间片指的是所有车辆一次调度完成）路上车辆有三种状态，未调度过的车是\t`无状态`， 调度过但是由于阻挡或者其他原因不能移动的车标记为 `等待状态`， 调度过并且完成移动的车标记为 `终态`。\n\n\n- step1: 怎样标记状态？\n\n\n\t- 这个时间片车辆最大行驶速度能超过该道路长度（超过了但不一定就能进入下一条道路），直接标记为`等待状态`\n\t- 这个时间片车辆最大行驶速度不能超过该道路长度，但是前方有车辆挡住自己将要走的路，直接标记为`等待状态`\n\t- 这个时间片车辆最大行驶速度不能超过该道路长度，并且前方没车辆挡住自己，**移动该车**，直接标记为`终止状态`\n\n\n- step2: 按什么顺序调度车辆？\n\n\t- 路上的车：\n\t\t- 处理次序：\n\t\t\t- 按照ID升序反复遍历**路口**，直到所有车辆变成终态\n\t\t\t- 对每个路口，按照ID升序遍历朝向这个路口的**道路**（也反复遍历，直到所有车进入终止状态，或者被阻挡无法移动）\n\t\t\t- 每个道路上有多条线，按照**优先级顺序**处理车辆，只有第一优先级车辆完成调度，才能调度优先级低的车。\n\t\t\t- 不过马路而被标记等待的车，不受优先级限制，阻挡车辆离开，这种车立马跟上\n\t- 上路的车：\n\t\t- 上路车按照ID升序处理\n\t\t- 规划的时间因为前方无空位而未上路的车，顺延到下一时刻优先上路，即不参与下一时刻车辆ID升序发车。\n\n\n- 哪些车参与**优先级**的排序？\n\n\n\t要过马路的车和车速超过当前道路剩余长度，但是根据任务书10-5条，不能进入下一道路的车都参与优先级排序。\n\n大概就这些了，其他更细微的只能遇到才想起来了。\n\n\n## 思路总结\n> 这里只总结一下初赛的思路。\n\n这个比赛就是合理安排车辆调度，以最短时间让所有车都到达终点。所以要找到合适的方法让车辆快速充满道路而不至于 `锁死`,`锁死`也是赛题的最难点。 道路上流动的车越多，越容易出现锁死情况；道路上流动的车越少，最终调度时间就越长。所以优化的目标变成了<font color=\"red\"><big>保证不死锁的情况下，让更多的车在道路上流动起来</big></font>。\n\n### 什么是死锁？\n死锁指的是，某个时间片道路上的车辆由于循环等待（形成了环形等待情况），导致无法再进一步调度任何车辆，导致调度失败，成绩为0。**体现在调度器里**，就是step2 反复调度路口时，等待状态的车辆数量不再减少，即锁死了。\n\n### 怎么避免死锁？\n唯一可以避免的方法是完全实现调度器，和官方调度器一致，就可以准确判断到锁死，并且在规划道路时动态规划新路，解开环形等待的死亡链。可惜大家完全模拟出来调度器的几乎没有（据我一直水群了解到的情况看，是这样，不排除潜水大佬真的实现了）。\n所以呢，大部分人都是想尽办法的尽量减少锁死，无法完全避免，下面会举例几种方法。\n\n### 有不完全正确调度器的解决方案\n\n1. 单车最优路径静态规划 + 遇锁死时对部分车动态规划\n\n      > 如果调度器不太一致时，就当某道路调度同一车辆多次，就给这个车强制规划新路径。\n\n2. 单车最优路径静态规划 + 遇锁死时把锁死车辆从路上删除，未来重新发车\n\n3. 分批次发车 + 每个批次单独规划路径 + 动态路阻 + 锁死车辆动态规划\n\n    > 这个是效果比较好的一种方法，练习赛后期成绩能进入前15名的方法。动态路阻指的是道路情况拥堵，这里选择了几个因素：\n    > \n    > 动态路阻 = 这个批次经过该道路车辆数量*a + abs(道路限速 - 车速)*b + （1 - 道路中路线数/最大线数）*c\n    >  \n    > 路阻每个批次都清除一次，这样在调度器不准确的情况下很大程度上抑制了死锁的发生，当时采用这种方法之后，每个批次发车量明显可以提高很多。这里a，b，c是需要调节的参数。\n\n### 没有调度器的解决方案\n\n如果没实现调度器，也有一些不错的方法，但是不算偷鸡。这里把路网当成计算机的网络，网络的带宽就是道路的线数，我们想让网络传输最大量的数据，但是网络本身承载能力有限制，我们要找到均衡流量的方法，让网络上流动的流量尽可能的均衡，这样再找到合适的参数，即网络最适合的承载车辆数目，保证网络流量不超过这个限制，也可以减少死锁的情况。即 **分批次发车 + 每个批次单独规划路径 + 动态路阻**\n\n### 还有一种不太有意义的方法\n\n这种也被很多人叫做偷鸡方法，就是 **单车路径最优规划 + 随机时间发车**，然后就是调调调。这种方法优势是答案生成快，可以反复调无数次。而实现调度器的同学，基本半小时才能调一次参数，因为模拟调度的过程比较费时间，又加上动态路径规划，时间代价大大提高。\n\n\n### 对单车的寻路算法\n\n想当然的觉得地图是平面的，因为官方给的任务书全是平面图，并且每个路口对应的四个街道都是有方向的，所以对路口直接建立了坐标系，有了每个点的方位坐标信息，也就很自然的选择了A*算法。结果没想到，最后正式赛当天出现的地图是这。。。样。。。的。。。，出现了高空立交桥，这还算直行吗。开始不知道地图变了样子，结果递归建坐标系的部分爆了bug，改了半天，卒了。后来看到群里可视化后的效果是下图，吐血了，赶紧换了Dijkstra算法。这两个算法有时间再总结。\n\n![logo](华为软挑/huawei.jpg)\n\n## 我们组的结果\n\n结果就是止步初赛了，调度器 + 动态规划 + 动态路阻 + 。。。+ python 真是很费时间，本地要15分钟勉强出结果，服务器上直接超时。 放弃了调度器和动态规划， 只用了动态路阻，最后所剩时间不多了，只调了几次参数就到时间了。 \n\n\n## 比赛的经验与教训\n\n1. 比赛运行环境一定要保证和官方一致，不然结果会出现不一致。\n2. 如果还是这种复杂规则的情况，不要再选择python，速度确实有问题，代码能力差的人体现的更明显~、~、\n3. 好好理解题目在行动。\n\n## 感悟\n\n结果有点惨淡，但是这段时间确实收获了很多，也多亏了两位队友的倾力相助，以及师兄的思路指导。郭同学为团队提供了大部分算法上的思路和代码；丁同学从开始比赛到最后一天，也一直在和我讨论着调度以及算法，纠正了我很多错误的理解，比赛的日子也是近段时间来最开心的日子，期待大家下一次的合作。画江湖之绿皮车将要回归。。。\n","source":"_posts/华为软挑.md","raw":"---\ntitle: 华为软挑2019\ndate: 2019-04-01 18:19:34\ncategories: 竞赛\ntags: 华为软挑初赛\ncopyright: \n---\n\n# 参加软挑的一些感悟\n## 写在前边的话\n　　\n\n> 我本科一直在做嵌入式相关的项目,这是第一次参加软件类的竞赛,不得不说过程确实很刺激,最后止步杭厦赛区50强也很是遗憾,明明很接近,最后输在了代码效率上,本地成绩很好的 `python代码` ,上传测评运行时间超限（官测环境比本地性能好，普遍情况是用时远超本地，其中华为云主机集体宕机半小时，很多人测过的最优代码，最后再上传就超时了[https://bbs.huaweicloud.com/forum/thread-16237-1-1.html](https://bbs.huaweicloud.com/forum/thread-16237-1-1.html)）。超限原因主要两点，一是自己在实现调度器时的代码臃肿，二是正式赛数据量大增。但进入32强的不少组并没有实现调度器，完全 `随机时间发车+单车路径最优规划` , 感觉很(￣_,￣ )。这比赛不实现调度器，意义少了一半，再用上这种偷鸡方法，没觉出来还有啥意义。唉，菜鸡就是菜鸡。总之，这次经历对我还是有不少积极的影响的，下面就总结一下吧。\n\n\n## 题目解读\n本次比赛主要做的是 `动态路网下多车辆调度问题`, <font color=\"red\"><big>参赛者合理安排数万车辆在合理时间从出发点到达各自的目的地，程序上传至官方服务器，运行后得出 **所有车辆出发时间和规划的路径** ，将在官方调度器中进行调度，完成车辆调度用时即为最终成绩。</big></font>具体是比赛任务书中花了很大篇幅讲了官方调度器的规则，并且论坛前期几乎天天在更新规则补充，最终完全准确实现的队伍只见过一个，其他很对队伍是很接近，但总有差别。我们自己实现的调度器，调度时间完全对的上，但是所有车辆调度总时间总是差了一些。分析原因有以下两点:   \n \n1. 我们实现的调度规则还有与官方一些差异；（但是我们实现的和部分队伍对比的结果完全一致，但和官网就有差异，猜测可能有些规则官方描述的有些差异，或者某细节被我们忽略了）\n2. python 即使版本相同，但是在不同机器上结果确实有差异，这个也被官方证实了[https://bbs.huaweicloud.com/forum/thread-15889-1-1.html](https://bbs.huaweicloud.com/forum/thread-15889-1-1.html)。\n\n总体上参考任务书，下面只简单梳理一下思路（这里默认已经熟悉了任务书）：\n\n下面先附上官方伪代码\n\n        for(/* 按时间片处理 */) {\n\n           foreach(roads) {\n\n                /* 调整所有道路上在道路上的车辆，让道路上车辆前进，只要不出路口且可以到达终止状态的车辆\n                 * 分别标记出来等待的车辆（要出路口的车辆，或者因为要出路口的车辆阻挡而不能前进的车辆）\n                 * 和终止状态的车辆（在该车道内可以经过这一次调度可以行驶其最大可行驶距离的车辆）*/\n                driveAllCarJustOnRoadToEndState(allChannle);/* 对所有车道进行调整 */\n\n                /* driveAllCarJustOnRoadToEndState该处理内的算法与性能自行考虑 */\n           }\n\n            \n            while(/* all car in road run into end state */){\n\n                /* driveAllWaitCar() */\n\n                foreach(crosses){\n\n                    foreach(roads){\n\n\t\t\t\t\t\twhile(/* wait car on the road */){\n\n\t\t\t\t\t\t    Direction dir = getDirection();\n\n\t\t\t\t\t\t    Car car = getCarFromRoad(road, dir);\n\n\t\t\t\t\t\t    if (conflict）{\n\t\t\t\t\t\t    \tbreak;\n\t\t\t\t\t\t    }\n\n\t\t\t    channle = car.getChannel();\n\t\t\t    \n\t\t\t    /* 这里只指因下一道路有等待车辆阻挡而导致该车辆无法进入的情况 */\n\t\t\t    /* 其他情况均返回true,比如下一车道满无法进入（全是终态），或才是下一车道限速不能进入，该车辆停留在其当前车道最前方 */\n\t\t\t    /* 该车辆也是移动至其所在车道最前方，只有有车辆由等待变以终止，就对其车道后续车辆状态进行调整 */\n    \t\t    if(!car.moveToNextRoad()) {\n    \t\t        break;\n    \t\t    }\n\t\t\t    \n\t\t\t    /* driveAllCarJustOnRoadToEndState该处理内的算法与性能自行考虑 */\n\n\t\t\t    driveAllCarJustOnRoadToEndState(channel);\n\t\t\t\t\t}\n\t\t    \t}\n              }\n            }\n\n            /* 车库中的车辆上路行驶 */\n            driveCarInGarage();\n        }\n\n\n\n- 要调度的车辆分两种：<font color=\"red\"><big>路上的车和要上路的车</big></font>\n\n\n- 每个时间片<font color=\"red\">先处理路上车，在处理上路车</font>\n\n\n- 路上的车处理步骤： <font color=\"red\"><big>step1标记状态， step2 移动车辆 </big></font>\n\n\n- 车的状态：每个时间片（一个时间片指的是所有车辆一次调度完成）路上车辆有三种状态，未调度过的车是\t`无状态`， 调度过但是由于阻挡或者其他原因不能移动的车标记为 `等待状态`， 调度过并且完成移动的车标记为 `终态`。\n\n\n- step1: 怎样标记状态？\n\n\n\t- 这个时间片车辆最大行驶速度能超过该道路长度（超过了但不一定就能进入下一条道路），直接标记为`等待状态`\n\t- 这个时间片车辆最大行驶速度不能超过该道路长度，但是前方有车辆挡住自己将要走的路，直接标记为`等待状态`\n\t- 这个时间片车辆最大行驶速度不能超过该道路长度，并且前方没车辆挡住自己，**移动该车**，直接标记为`终止状态`\n\n\n- step2: 按什么顺序调度车辆？\n\n\t- 路上的车：\n\t\t- 处理次序：\n\t\t\t- 按照ID升序反复遍历**路口**，直到所有车辆变成终态\n\t\t\t- 对每个路口，按照ID升序遍历朝向这个路口的**道路**（也反复遍历，直到所有车进入终止状态，或者被阻挡无法移动）\n\t\t\t- 每个道路上有多条线，按照**优先级顺序**处理车辆，只有第一优先级车辆完成调度，才能调度优先级低的车。\n\t\t\t- 不过马路而被标记等待的车，不受优先级限制，阻挡车辆离开，这种车立马跟上\n\t- 上路的车：\n\t\t- 上路车按照ID升序处理\n\t\t- 规划的时间因为前方无空位而未上路的车，顺延到下一时刻优先上路，即不参与下一时刻车辆ID升序发车。\n\n\n- 哪些车参与**优先级**的排序？\n\n\n\t要过马路的车和车速超过当前道路剩余长度，但是根据任务书10-5条，不能进入下一道路的车都参与优先级排序。\n\n大概就这些了，其他更细微的只能遇到才想起来了。\n\n\n## 思路总结\n> 这里只总结一下初赛的思路。\n\n这个比赛就是合理安排车辆调度，以最短时间让所有车都到达终点。所以要找到合适的方法让车辆快速充满道路而不至于 `锁死`,`锁死`也是赛题的最难点。 道路上流动的车越多，越容易出现锁死情况；道路上流动的车越少，最终调度时间就越长。所以优化的目标变成了<font color=\"red\"><big>保证不死锁的情况下，让更多的车在道路上流动起来</big></font>。\n\n### 什么是死锁？\n死锁指的是，某个时间片道路上的车辆由于循环等待（形成了环形等待情况），导致无法再进一步调度任何车辆，导致调度失败，成绩为0。**体现在调度器里**，就是step2 反复调度路口时，等待状态的车辆数量不再减少，即锁死了。\n\n### 怎么避免死锁？\n唯一可以避免的方法是完全实现调度器，和官方调度器一致，就可以准确判断到锁死，并且在规划道路时动态规划新路，解开环形等待的死亡链。可惜大家完全模拟出来调度器的几乎没有（据我一直水群了解到的情况看，是这样，不排除潜水大佬真的实现了）。\n所以呢，大部分人都是想尽办法的尽量减少锁死，无法完全避免，下面会举例几种方法。\n\n### 有不完全正确调度器的解决方案\n\n1. 单车最优路径静态规划 + 遇锁死时对部分车动态规划\n\n      > 如果调度器不太一致时，就当某道路调度同一车辆多次，就给这个车强制规划新路径。\n\n2. 单车最优路径静态规划 + 遇锁死时把锁死车辆从路上删除，未来重新发车\n\n3. 分批次发车 + 每个批次单独规划路径 + 动态路阻 + 锁死车辆动态规划\n\n    > 这个是效果比较好的一种方法，练习赛后期成绩能进入前15名的方法。动态路阻指的是道路情况拥堵，这里选择了几个因素：\n    > \n    > 动态路阻 = 这个批次经过该道路车辆数量*a + abs(道路限速 - 车速)*b + （1 - 道路中路线数/最大线数）*c\n    >  \n    > 路阻每个批次都清除一次，这样在调度器不准确的情况下很大程度上抑制了死锁的发生，当时采用这种方法之后，每个批次发车量明显可以提高很多。这里a，b，c是需要调节的参数。\n\n### 没有调度器的解决方案\n\n如果没实现调度器，也有一些不错的方法，但是不算偷鸡。这里把路网当成计算机的网络，网络的带宽就是道路的线数，我们想让网络传输最大量的数据，但是网络本身承载能力有限制，我们要找到均衡流量的方法，让网络上流动的流量尽可能的均衡，这样再找到合适的参数，即网络最适合的承载车辆数目，保证网络流量不超过这个限制，也可以减少死锁的情况。即 **分批次发车 + 每个批次单独规划路径 + 动态路阻**\n\n### 还有一种不太有意义的方法\n\n这种也被很多人叫做偷鸡方法，就是 **单车路径最优规划 + 随机时间发车**，然后就是调调调。这种方法优势是答案生成快，可以反复调无数次。而实现调度器的同学，基本半小时才能调一次参数，因为模拟调度的过程比较费时间，又加上动态路径规划，时间代价大大提高。\n\n\n### 对单车的寻路算法\n\n想当然的觉得地图是平面的，因为官方给的任务书全是平面图，并且每个路口对应的四个街道都是有方向的，所以对路口直接建立了坐标系，有了每个点的方位坐标信息，也就很自然的选择了A*算法。结果没想到，最后正式赛当天出现的地图是这。。。样。。。的。。。，出现了高空立交桥，这还算直行吗。开始不知道地图变了样子，结果递归建坐标系的部分爆了bug，改了半天，卒了。后来看到群里可视化后的效果是下图，吐血了，赶紧换了Dijkstra算法。这两个算法有时间再总结。\n\n![logo](华为软挑/huawei.jpg)\n\n## 我们组的结果\n\n结果就是止步初赛了，调度器 + 动态规划 + 动态路阻 + 。。。+ python 真是很费时间，本地要15分钟勉强出结果，服务器上直接超时。 放弃了调度器和动态规划， 只用了动态路阻，最后所剩时间不多了，只调了几次参数就到时间了。 \n\n\n## 比赛的经验与教训\n\n1. 比赛运行环境一定要保证和官方一致，不然结果会出现不一致。\n2. 如果还是这种复杂规则的情况，不要再选择python，速度确实有问题，代码能力差的人体现的更明显~、~、\n3. 好好理解题目在行动。\n\n## 感悟\n\n结果有点惨淡，但是这段时间确实收获了很多，也多亏了两位队友的倾力相助，以及师兄的思路指导。郭同学为团队提供了大部分算法上的思路和代码；丁同学从开始比赛到最后一天，也一直在和我讨论着调度以及算法，纠正了我很多错误的理解，比赛的日子也是近段时间来最开心的日子，期待大家下一次的合作。画江湖之绿皮车将要回归。。。\n","slug":"华为软挑","published":1,"updated":"2019-07-30T15:35:42.728Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz98jh9w002by0plf67c8vtb","content":"<h1 id=\"参加软挑的一些感悟\"><a href=\"#参加软挑的一些感悟\" class=\"headerlink\" title=\"参加软挑的一些感悟\"></a>参加软挑的一些感悟</h1><h2 id=\"写在前边的话\"><a href=\"#写在前边的话\" class=\"headerlink\" title=\"写在前边的话\"></a>写在前边的话</h2><p>　　</p>\n<blockquote>\n<p>我本科一直在做嵌入式相关的项目,这是第一次参加软件类的竞赛,不得不说过程确实很刺激,最后止步杭厦赛区50强也很是遗憾,明明很接近,最后输在了代码效率上,本地成绩很好的 <code>python代码</code> ,上传测评运行时间超限（官测环境比本地性能好，普遍情况是用时远超本地，其中华为云主机集体宕机半小时，很多人测过的最优代码，最后再上传就超时了<a href=\"https://bbs.huaweicloud.com/forum/thread-16237-1-1.html\" target=\"_blank\" rel=\"noopener\">https://bbs.huaweicloud.com/forum/thread-16237-1-1.html</a>）。超限原因主要两点，一是自己在实现调度器时的代码臃肿，二是正式赛数据量大增。但进入32强的不少组并没有实现调度器，完全 <code>随机时间发车+单车路径最优规划</code> , 感觉很(￣_,￣ )。这比赛不实现调度器，意义少了一半，再用上这种偷鸡方法，没觉出来还有啥意义。唉，菜鸡就是菜鸡。总之，这次经历对我还是有不少积极的影响的，下面就总结一下吧。</p>\n</blockquote>\n<h2 id=\"题目解读\"><a href=\"#题目解读\" class=\"headerlink\" title=\"题目解读\"></a>题目解读</h2><p>本次比赛主要做的是 <code>动态路网下多车辆调度问题</code>, <font color=\"red\"><big>参赛者合理安排数万车辆在合理时间从出发点到达各自的目的地，程序上传至官方服务器，运行后得出 <strong>所有车辆出发时间和规划的路径</strong> ，将在官方调度器中进行调度，完成车辆调度用时即为最终成绩。</big></font>具体是比赛任务书中花了很大篇幅讲了官方调度器的规则，并且论坛前期几乎天天在更新规则补充，最终完全准确实现的队伍只见过一个，其他很对队伍是很接近，但总有差别。我们自己实现的调度器，调度时间完全对的上，但是所有车辆调度总时间总是差了一些。分析原因有以下两点:   </p>\n<ol>\n<li>我们实现的调度规则还有与官方一些差异；（但是我们实现的和部分队伍对比的结果完全一致，但和官网就有差异，猜测可能有些规则官方描述的有些差异，或者某细节被我们忽略了）</li>\n<li>python 即使版本相同，但是在不同机器上结果确实有差异，这个也被官方证实了<a href=\"https://bbs.huaweicloud.com/forum/thread-15889-1-1.html\" target=\"_blank\" rel=\"noopener\">https://bbs.huaweicloud.com/forum/thread-15889-1-1.html</a>。</li>\n</ol>\n<p>总体上参考任务书，下面只简单梳理一下思路（这里默认已经熟悉了任务书）：</p>\n<p>下面先附上官方伪代码</p>\n<pre><code>    for(/* 按时间片处理 */) {\n\n       foreach(roads) {\n\n            /* 调整所有道路上在道路上的车辆，让道路上车辆前进，只要不出路口且可以到达终止状态的车辆\n             * 分别标记出来等待的车辆（要出路口的车辆，或者因为要出路口的车辆阻挡而不能前进的车辆）\n             * 和终止状态的车辆（在该车道内可以经过这一次调度可以行驶其最大可行驶距离的车辆）*/\n            driveAllCarJustOnRoadToEndState(allChannle);/* 对所有车道进行调整 */\n\n            /* driveAllCarJustOnRoadToEndState该处理内的算法与性能自行考虑 */\n       }\n\n\n        while(/* all car in road run into end state */){\n\n            /* driveAllWaitCar() */\n\n            foreach(crosses){\n\n                foreach(roads){\n\n                    while(/* wait car on the road */){\n\n                        Direction dir = getDirection();\n\n                        Car car = getCarFromRoad(road, dir);\n\n                        if (conflict）{\n                            break;\n                        }\n\n            channle = car.getChannel();\n\n            /* 这里只指因下一道路有等待车辆阻挡而导致该车辆无法进入的情况 */\n            /* 其他情况均返回true,比如下一车道满无法进入（全是终态），或才是下一车道限速不能进入，该车辆停留在其当前车道最前方 */\n            /* 该车辆也是移动至其所在车道最前方，只有有车辆由等待变以终止，就对其车道后续车辆状态进行调整 */\n            if(!car.moveToNextRoad()) {\n                break;\n            }\n\n            /* driveAllCarJustOnRoadToEndState该处理内的算法与性能自行考虑 */\n\n            driveAllCarJustOnRoadToEndState(channel);\n                }\n            }\n          }\n        }\n\n        /* 车库中的车辆上路行驶 */\n        driveCarInGarage();\n    }\n</code></pre><ul>\n<li>要调度的车辆分两种：<font color=\"red\"><big>路上的车和要上路的车</big></font></li>\n</ul>\n<ul>\n<li>每个时间片<font color=\"red\">先处理路上车，在处理上路车</font></li>\n</ul>\n<ul>\n<li>路上的车处理步骤： <font color=\"red\"><big>step1标记状态， step2 移动车辆 </big></font></li>\n</ul>\n<ul>\n<li>车的状态：每个时间片（一个时间片指的是所有车辆一次调度完成）路上车辆有三种状态，未调度过的车是    <code>无状态</code>， 调度过但是由于阻挡或者其他原因不能移动的车标记为 <code>等待状态</code>， 调度过并且完成移动的车标记为 <code>终态</code>。</li>\n</ul>\n<ul>\n<li>step1: 怎样标记状态？</li>\n</ul>\n<pre><code>- 这个时间片车辆最大行驶速度能超过该道路长度（超过了但不一定就能进入下一条道路），直接标记为`等待状态`\n- 这个时间片车辆最大行驶速度不能超过该道路长度，但是前方有车辆挡住自己将要走的路，直接标记为`等待状态`\n- 这个时间片车辆最大行驶速度不能超过该道路长度，并且前方没车辆挡住自己，**移动该车**，直接标记为`终止状态`\n</code></pre><ul>\n<li><p>step2: 按什么顺序调度车辆？</p>\n<ul>\n<li>路上的车：<ul>\n<li>处理次序：<ul>\n<li>按照ID升序反复遍历<strong>路口</strong>，直到所有车辆变成终态</li>\n<li>对每个路口，按照ID升序遍历朝向这个路口的<strong>道路</strong>（也反复遍历，直到所有车进入终止状态，或者被阻挡无法移动）</li>\n<li>每个道路上有多条线，按照<strong>优先级顺序</strong>处理车辆，只有第一优先级车辆完成调度，才能调度优先级低的车。</li>\n<li>不过马路而被标记等待的车，不受优先级限制，阻挡车辆离开，这种车立马跟上</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>上路的车：<ul>\n<li>上路车按照ID升序处理</li>\n<li>规划的时间因为前方无空位而未上路的车，顺延到下一时刻优先上路，即不参与下一时刻车辆ID升序发车。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>哪些车参与<strong>优先级</strong>的排序？</li>\n</ul>\n<pre><code>要过马路的车和车速超过当前道路剩余长度，但是根据任务书10-5条，不能进入下一道路的车都参与优先级排序。\n</code></pre><p>大概就这些了，其他更细微的只能遇到才想起来了。</p>\n<h2 id=\"思路总结\"><a href=\"#思路总结\" class=\"headerlink\" title=\"思路总结\"></a>思路总结</h2><blockquote>\n<p>这里只总结一下初赛的思路。</p>\n</blockquote>\n<p>这个比赛就是合理安排车辆调度，以最短时间让所有车都到达终点。所以要找到合适的方法让车辆快速充满道路而不至于 <code>锁死</code>,<code>锁死</code>也是赛题的最难点。 道路上流动的车越多，越容易出现锁死情况；道路上流动的车越少，最终调度时间就越长。所以优化的目标变成了<font color=\"red\"><big>保证不死锁的情况下，让更多的车在道路上流动起来</big></font>。</p>\n<h3 id=\"什么是死锁？\"><a href=\"#什么是死锁？\" class=\"headerlink\" title=\"什么是死锁？\"></a>什么是死锁？</h3><p>死锁指的是，某个时间片道路上的车辆由于循环等待（形成了环形等待情况），导致无法再进一步调度任何车辆，导致调度失败，成绩为0。<strong>体现在调度器里</strong>，就是step2 反复调度路口时，等待状态的车辆数量不再减少，即锁死了。</p>\n<h3 id=\"怎么避免死锁？\"><a href=\"#怎么避免死锁？\" class=\"headerlink\" title=\"怎么避免死锁？\"></a>怎么避免死锁？</h3><p>唯一可以避免的方法是完全实现调度器，和官方调度器一致，就可以准确判断到锁死，并且在规划道路时动态规划新路，解开环形等待的死亡链。可惜大家完全模拟出来调度器的几乎没有（据我一直水群了解到的情况看，是这样，不排除潜水大佬真的实现了）。<br>所以呢，大部分人都是想尽办法的尽量减少锁死，无法完全避免，下面会举例几种方法。</p>\n<h3 id=\"有不完全正确调度器的解决方案\"><a href=\"#有不完全正确调度器的解决方案\" class=\"headerlink\" title=\"有不完全正确调度器的解决方案\"></a>有不完全正确调度器的解决方案</h3><ol>\n<li><p>单车最优路径静态规划 + 遇锁死时对部分车动态规划</p>\n<blockquote>\n<p>如果调度器不太一致时，就当某道路调度同一车辆多次，就给这个车强制规划新路径。</p>\n</blockquote>\n</li>\n<li><p>单车最优路径静态规划 + 遇锁死时把锁死车辆从路上删除，未来重新发车</p>\n</li>\n<li><p>分批次发车 + 每个批次单独规划路径 + 动态路阻 + 锁死车辆动态规划</p>\n<blockquote>\n<p>这个是效果比较好的一种方法，练习赛后期成绩能进入前15名的方法。动态路阻指的是道路情况拥堵，这里选择了几个因素：</p>\n<p>动态路阻 = 这个批次经过该道路车辆数量<em>a + abs(道路限速 - 车速)</em>b + （1 - 道路中路线数/最大线数）*c</p>\n<p>路阻每个批次都清除一次，这样在调度器不准确的情况下很大程度上抑制了死锁的发生，当时采用这种方法之后，每个批次发车量明显可以提高很多。这里a，b，c是需要调节的参数。</p>\n</blockquote>\n</li>\n</ol>\n<h3 id=\"没有调度器的解决方案\"><a href=\"#没有调度器的解决方案\" class=\"headerlink\" title=\"没有调度器的解决方案\"></a>没有调度器的解决方案</h3><p>如果没实现调度器，也有一些不错的方法，但是不算偷鸡。这里把路网当成计算机的网络，网络的带宽就是道路的线数，我们想让网络传输最大量的数据，但是网络本身承载能力有限制，我们要找到均衡流量的方法，让网络上流动的流量尽可能的均衡，这样再找到合适的参数，即网络最适合的承载车辆数目，保证网络流量不超过这个限制，也可以减少死锁的情况。即 <strong>分批次发车 + 每个批次单独规划路径 + 动态路阻</strong></p>\n<h3 id=\"还有一种不太有意义的方法\"><a href=\"#还有一种不太有意义的方法\" class=\"headerlink\" title=\"还有一种不太有意义的方法\"></a>还有一种不太有意义的方法</h3><p>这种也被很多人叫做偷鸡方法，就是 <strong>单车路径最优规划 + 随机时间发车</strong>，然后就是调调调。这种方法优势是答案生成快，可以反复调无数次。而实现调度器的同学，基本半小时才能调一次参数，因为模拟调度的过程比较费时间，又加上动态路径规划，时间代价大大提高。</p>\n<h3 id=\"对单车的寻路算法\"><a href=\"#对单车的寻路算法\" class=\"headerlink\" title=\"对单车的寻路算法\"></a>对单车的寻路算法</h3><p>想当然的觉得地图是平面的，因为官方给的任务书全是平面图，并且每个路口对应的四个街道都是有方向的，所以对路口直接建立了坐标系，有了每个点的方位坐标信息，也就很自然的选择了A*算法。结果没想到，最后正式赛当天出现的地图是这。。。样。。。的。。。，出现了高空立交桥，这还算直行吗。开始不知道地图变了样子，结果递归建坐标系的部分爆了bug，改了半天，卒了。后来看到群里可视化后的效果是下图，吐血了，赶紧换了Dijkstra算法。这两个算法有时间再总结。</p>\n<p><img src=\"/2019/04/01/华为软挑/huawei.jpg\" alt=\"logo\"></p>\n<h2 id=\"我们组的结果\"><a href=\"#我们组的结果\" class=\"headerlink\" title=\"我们组的结果\"></a>我们组的结果</h2><p>结果就是止步初赛了，调度器 + 动态规划 + 动态路阻 + 。。。+ python 真是很费时间，本地要15分钟勉强出结果，服务器上直接超时。 放弃了调度器和动态规划， 只用了动态路阻，最后所剩时间不多了，只调了几次参数就到时间了。 </p>\n<h2 id=\"比赛的经验与教训\"><a href=\"#比赛的经验与教训\" class=\"headerlink\" title=\"比赛的经验与教训\"></a>比赛的经验与教训</h2><ol>\n<li>比赛运行环境一定要保证和官方一致，不然结果会出现不一致。</li>\n<li>如果还是这种复杂规则的情况，不要再选择python，速度确实有问题，代码能力差的人体现的更明显~、~、</li>\n<li>好好理解题目在行动。</li>\n</ol>\n<h2 id=\"感悟\"><a href=\"#感悟\" class=\"headerlink\" title=\"感悟\"></a>感悟</h2><p>结果有点惨淡，但是这段时间确实收获了很多，也多亏了两位队友的倾力相助，以及师兄的思路指导。郭同学为团队提供了大部分算法上的思路和代码；丁同学从开始比赛到最后一天，也一直在和我讨论着调度以及算法，纠正了我很多错误的理解，比赛的日子也是近段时间来最开心的日子，期待大家下一次的合作。画江湖之绿皮车将要回归。。。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"参加软挑的一些感悟\"><a href=\"#参加软挑的一些感悟\" class=\"headerlink\" title=\"参加软挑的一些感悟\"></a>参加软挑的一些感悟</h1><h2 id=\"写在前边的话\"><a href=\"#写在前边的话\" class=\"headerlink\" title=\"写在前边的话\"></a>写在前边的话</h2><p>　　</p>\n<blockquote>\n<p>我本科一直在做嵌入式相关的项目,这是第一次参加软件类的竞赛,不得不说过程确实很刺激,最后止步杭厦赛区50强也很是遗憾,明明很接近,最后输在了代码效率上,本地成绩很好的 <code>python代码</code> ,上传测评运行时间超限（官测环境比本地性能好，普遍情况是用时远超本地，其中华为云主机集体宕机半小时，很多人测过的最优代码，最后再上传就超时了<a href=\"https://bbs.huaweicloud.com/forum/thread-16237-1-1.html\" target=\"_blank\" rel=\"noopener\">https://bbs.huaweicloud.com/forum/thread-16237-1-1.html</a>）。超限原因主要两点，一是自己在实现调度器时的代码臃肿，二是正式赛数据量大增。但进入32强的不少组并没有实现调度器，完全 <code>随机时间发车+单车路径最优规划</code> , 感觉很(￣_,￣ )。这比赛不实现调度器，意义少了一半，再用上这种偷鸡方法，没觉出来还有啥意义。唉，菜鸡就是菜鸡。总之，这次经历对我还是有不少积极的影响的，下面就总结一下吧。</p>\n</blockquote>\n<h2 id=\"题目解读\"><a href=\"#题目解读\" class=\"headerlink\" title=\"题目解读\"></a>题目解读</h2><p>本次比赛主要做的是 <code>动态路网下多车辆调度问题</code>, <font color=\"red\"><big>参赛者合理安排数万车辆在合理时间从出发点到达各自的目的地，程序上传至官方服务器，运行后得出 <strong>所有车辆出发时间和规划的路径</strong> ，将在官方调度器中进行调度，完成车辆调度用时即为最终成绩。</big></font>具体是比赛任务书中花了很大篇幅讲了官方调度器的规则，并且论坛前期几乎天天在更新规则补充，最终完全准确实现的队伍只见过一个，其他很对队伍是很接近，但总有差别。我们自己实现的调度器，调度时间完全对的上，但是所有车辆调度总时间总是差了一些。分析原因有以下两点:   </p>\n<ol>\n<li>我们实现的调度规则还有与官方一些差异；（但是我们实现的和部分队伍对比的结果完全一致，但和官网就有差异，猜测可能有些规则官方描述的有些差异，或者某细节被我们忽略了）</li>\n<li>python 即使版本相同，但是在不同机器上结果确实有差异，这个也被官方证实了<a href=\"https://bbs.huaweicloud.com/forum/thread-15889-1-1.html\" target=\"_blank\" rel=\"noopener\">https://bbs.huaweicloud.com/forum/thread-15889-1-1.html</a>。</li>\n</ol>\n<p>总体上参考任务书，下面只简单梳理一下思路（这里默认已经熟悉了任务书）：</p>\n<p>下面先附上官方伪代码</p>\n<pre><code>    for(/* 按时间片处理 */) {\n\n       foreach(roads) {\n\n            /* 调整所有道路上在道路上的车辆，让道路上车辆前进，只要不出路口且可以到达终止状态的车辆\n             * 分别标记出来等待的车辆（要出路口的车辆，或者因为要出路口的车辆阻挡而不能前进的车辆）\n             * 和终止状态的车辆（在该车道内可以经过这一次调度可以行驶其最大可行驶距离的车辆）*/\n            driveAllCarJustOnRoadToEndState(allChannle);/* 对所有车道进行调整 */\n\n            /* driveAllCarJustOnRoadToEndState该处理内的算法与性能自行考虑 */\n       }\n\n\n        while(/* all car in road run into end state */){\n\n            /* driveAllWaitCar() */\n\n            foreach(crosses){\n\n                foreach(roads){\n\n                    while(/* wait car on the road */){\n\n                        Direction dir = getDirection();\n\n                        Car car = getCarFromRoad(road, dir);\n\n                        if (conflict）{\n                            break;\n                        }\n\n            channle = car.getChannel();\n\n            /* 这里只指因下一道路有等待车辆阻挡而导致该车辆无法进入的情况 */\n            /* 其他情况均返回true,比如下一车道满无法进入（全是终态），或才是下一车道限速不能进入，该车辆停留在其当前车道最前方 */\n            /* 该车辆也是移动至其所在车道最前方，只有有车辆由等待变以终止，就对其车道后续车辆状态进行调整 */\n            if(!car.moveToNextRoad()) {\n                break;\n            }\n\n            /* driveAllCarJustOnRoadToEndState该处理内的算法与性能自行考虑 */\n\n            driveAllCarJustOnRoadToEndState(channel);\n                }\n            }\n          }\n        }\n\n        /* 车库中的车辆上路行驶 */\n        driveCarInGarage();\n    }\n</code></pre><ul>\n<li>要调度的车辆分两种：<font color=\"red\"><big>路上的车和要上路的车</big></font></li>\n</ul>\n<ul>\n<li>每个时间片<font color=\"red\">先处理路上车，在处理上路车</font></li>\n</ul>\n<ul>\n<li>路上的车处理步骤： <font color=\"red\"><big>step1标记状态， step2 移动车辆 </big></font></li>\n</ul>\n<ul>\n<li>车的状态：每个时间片（一个时间片指的是所有车辆一次调度完成）路上车辆有三种状态，未调度过的车是    <code>无状态</code>， 调度过但是由于阻挡或者其他原因不能移动的车标记为 <code>等待状态</code>， 调度过并且完成移动的车标记为 <code>终态</code>。</li>\n</ul>\n<ul>\n<li>step1: 怎样标记状态？</li>\n</ul>\n<pre><code>- 这个时间片车辆最大行驶速度能超过该道路长度（超过了但不一定就能进入下一条道路），直接标记为`等待状态`\n- 这个时间片车辆最大行驶速度不能超过该道路长度，但是前方有车辆挡住自己将要走的路，直接标记为`等待状态`\n- 这个时间片车辆最大行驶速度不能超过该道路长度，并且前方没车辆挡住自己，**移动该车**，直接标记为`终止状态`\n</code></pre><ul>\n<li><p>step2: 按什么顺序调度车辆？</p>\n<ul>\n<li>路上的车：<ul>\n<li>处理次序：<ul>\n<li>按照ID升序反复遍历<strong>路口</strong>，直到所有车辆变成终态</li>\n<li>对每个路口，按照ID升序遍历朝向这个路口的<strong>道路</strong>（也反复遍历，直到所有车进入终止状态，或者被阻挡无法移动）</li>\n<li>每个道路上有多条线，按照<strong>优先级顺序</strong>处理车辆，只有第一优先级车辆完成调度，才能调度优先级低的车。</li>\n<li>不过马路而被标记等待的车，不受优先级限制，阻挡车辆离开，这种车立马跟上</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>上路的车：<ul>\n<li>上路车按照ID升序处理</li>\n<li>规划的时间因为前方无空位而未上路的车，顺延到下一时刻优先上路，即不参与下一时刻车辆ID升序发车。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>哪些车参与<strong>优先级</strong>的排序？</li>\n</ul>\n<pre><code>要过马路的车和车速超过当前道路剩余长度，但是根据任务书10-5条，不能进入下一道路的车都参与优先级排序。\n</code></pre><p>大概就这些了，其他更细微的只能遇到才想起来了。</p>\n<h2 id=\"思路总结\"><a href=\"#思路总结\" class=\"headerlink\" title=\"思路总结\"></a>思路总结</h2><blockquote>\n<p>这里只总结一下初赛的思路。</p>\n</blockquote>\n<p>这个比赛就是合理安排车辆调度，以最短时间让所有车都到达终点。所以要找到合适的方法让车辆快速充满道路而不至于 <code>锁死</code>,<code>锁死</code>也是赛题的最难点。 道路上流动的车越多，越容易出现锁死情况；道路上流动的车越少，最终调度时间就越长。所以优化的目标变成了<font color=\"red\"><big>保证不死锁的情况下，让更多的车在道路上流动起来</big></font>。</p>\n<h3 id=\"什么是死锁？\"><a href=\"#什么是死锁？\" class=\"headerlink\" title=\"什么是死锁？\"></a>什么是死锁？</h3><p>死锁指的是，某个时间片道路上的车辆由于循环等待（形成了环形等待情况），导致无法再进一步调度任何车辆，导致调度失败，成绩为0。<strong>体现在调度器里</strong>，就是step2 反复调度路口时，等待状态的车辆数量不再减少，即锁死了。</p>\n<h3 id=\"怎么避免死锁？\"><a href=\"#怎么避免死锁？\" class=\"headerlink\" title=\"怎么避免死锁？\"></a>怎么避免死锁？</h3><p>唯一可以避免的方法是完全实现调度器，和官方调度器一致，就可以准确判断到锁死，并且在规划道路时动态规划新路，解开环形等待的死亡链。可惜大家完全模拟出来调度器的几乎没有（据我一直水群了解到的情况看，是这样，不排除潜水大佬真的实现了）。<br>所以呢，大部分人都是想尽办法的尽量减少锁死，无法完全避免，下面会举例几种方法。</p>\n<h3 id=\"有不完全正确调度器的解决方案\"><a href=\"#有不完全正确调度器的解决方案\" class=\"headerlink\" title=\"有不完全正确调度器的解决方案\"></a>有不完全正确调度器的解决方案</h3><ol>\n<li><p>单车最优路径静态规划 + 遇锁死时对部分车动态规划</p>\n<blockquote>\n<p>如果调度器不太一致时，就当某道路调度同一车辆多次，就给这个车强制规划新路径。</p>\n</blockquote>\n</li>\n<li><p>单车最优路径静态规划 + 遇锁死时把锁死车辆从路上删除，未来重新发车</p>\n</li>\n<li><p>分批次发车 + 每个批次单独规划路径 + 动态路阻 + 锁死车辆动态规划</p>\n<blockquote>\n<p>这个是效果比较好的一种方法，练习赛后期成绩能进入前15名的方法。动态路阻指的是道路情况拥堵，这里选择了几个因素：</p>\n<p>动态路阻 = 这个批次经过该道路车辆数量<em>a + abs(道路限速 - 车速)</em>b + （1 - 道路中路线数/最大线数）*c</p>\n<p>路阻每个批次都清除一次，这样在调度器不准确的情况下很大程度上抑制了死锁的发生，当时采用这种方法之后，每个批次发车量明显可以提高很多。这里a，b，c是需要调节的参数。</p>\n</blockquote>\n</li>\n</ol>\n<h3 id=\"没有调度器的解决方案\"><a href=\"#没有调度器的解决方案\" class=\"headerlink\" title=\"没有调度器的解决方案\"></a>没有调度器的解决方案</h3><p>如果没实现调度器，也有一些不错的方法，但是不算偷鸡。这里把路网当成计算机的网络，网络的带宽就是道路的线数，我们想让网络传输最大量的数据，但是网络本身承载能力有限制，我们要找到均衡流量的方法，让网络上流动的流量尽可能的均衡，这样再找到合适的参数，即网络最适合的承载车辆数目，保证网络流量不超过这个限制，也可以减少死锁的情况。即 <strong>分批次发车 + 每个批次单独规划路径 + 动态路阻</strong></p>\n<h3 id=\"还有一种不太有意义的方法\"><a href=\"#还有一种不太有意义的方法\" class=\"headerlink\" title=\"还有一种不太有意义的方法\"></a>还有一种不太有意义的方法</h3><p>这种也被很多人叫做偷鸡方法，就是 <strong>单车路径最优规划 + 随机时间发车</strong>，然后就是调调调。这种方法优势是答案生成快，可以反复调无数次。而实现调度器的同学，基本半小时才能调一次参数，因为模拟调度的过程比较费时间，又加上动态路径规划，时间代价大大提高。</p>\n<h3 id=\"对单车的寻路算法\"><a href=\"#对单车的寻路算法\" class=\"headerlink\" title=\"对单车的寻路算法\"></a>对单车的寻路算法</h3><p>想当然的觉得地图是平面的，因为官方给的任务书全是平面图，并且每个路口对应的四个街道都是有方向的，所以对路口直接建立了坐标系，有了每个点的方位坐标信息，也就很自然的选择了A*算法。结果没想到，最后正式赛当天出现的地图是这。。。样。。。的。。。，出现了高空立交桥，这还算直行吗。开始不知道地图变了样子，结果递归建坐标系的部分爆了bug，改了半天，卒了。后来看到群里可视化后的效果是下图，吐血了，赶紧换了Dijkstra算法。这两个算法有时间再总结。</p>\n<p><img src=\"/2019/04/01/华为软挑/huawei.jpg\" alt=\"logo\"></p>\n<h2 id=\"我们组的结果\"><a href=\"#我们组的结果\" class=\"headerlink\" title=\"我们组的结果\"></a>我们组的结果</h2><p>结果就是止步初赛了，调度器 + 动态规划 + 动态路阻 + 。。。+ python 真是很费时间，本地要15分钟勉强出结果，服务器上直接超时。 放弃了调度器和动态规划， 只用了动态路阻，最后所剩时间不多了，只调了几次参数就到时间了。 </p>\n<h2 id=\"比赛的经验与教训\"><a href=\"#比赛的经验与教训\" class=\"headerlink\" title=\"比赛的经验与教训\"></a>比赛的经验与教训</h2><ol>\n<li>比赛运行环境一定要保证和官方一致，不然结果会出现不一致。</li>\n<li>如果还是这种复杂规则的情况，不要再选择python，速度确实有问题，代码能力差的人体现的更明显~、~、</li>\n<li>好好理解题目在行动。</li>\n</ol>\n<h2 id=\"感悟\"><a href=\"#感悟\" class=\"headerlink\" title=\"感悟\"></a>感悟</h2><p>结果有点惨淡，但是这段时间确实收获了很多，也多亏了两位队友的倾力相助，以及师兄的思路指导。郭同学为团队提供了大部分算法上的思路和代码；丁同学从开始比赛到最后一天，也一直在和我讨论着调度以及算法，纠正了我很多错误的理解，比赛的日子也是近段时间来最开心的日子，期待大家下一次的合作。画江湖之绿皮车将要回归。。。</p>\n"},{"title":"逻辑回归","mathjax":true,"date":"2019-04-27T05:01:43.000Z","copyright":null,"password":null,"top":true,"_content":"\n> 逻辑回归就是西瓜书里的对数几率回归，名为回归，实际则是分类算法。其实质是利用线性回归模型的预测结果来逼近真实标记的对数几率。\n> \n一句话概括就是:\n<font color=\"red\"> \n逻辑回归假设数据服从 **伯努利分布** ,通过 **极大化似然函数** 的方法，运用 **梯度下降** 来求解参数，来达到将数据二分类的目的。</font>\n\n## 线性模型如何处理二分类问题？\n\n> 在处理二分类任务时，我们希望模型能预测样本属于某类别的概率[0, 1]，或者直接输出类别的标签{0, 1}。 线性模型不能直接来完成这项任务，因为其输出是一个实际值，范围也不一定在0~1之间，无法体现我们所想要的概率或者标签。\n\n$$\ny=\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}+b\n$$\n\n因此，我们需要找到一种能把线性模型输出映射到 **概率** 或者 **标签** 的方法；\n\n- 如何转化为标签？\n\n\t单位阶跃函数\n\n- 如何转化为概率？\n\n\tsigmoid函数 (二分类): 将无穷范围的值限制在(0, 1)之间\n \n\tsoftmax函数（多分类）: 所有类别概率和为1\n\n![logo](逻辑回归/sigmoid.png)\n\n由于单位阶跃函数存在跳跃点，在跳跃点不可导，想选择梯度下降法来优化时，只能选择sigmoid函数了。\n\n## 逻辑回归模型\n\n> 逻辑回归就是这样的一个过程：面对一个分类问题，建立代价函数，然后通过优化方\n法迭代求解出最优的模型参数，然后测试验证我们这个求解的模型的好坏。\n\n### 逻辑回归的优缺点\n\n- 优点 \n\n\t- 速度快，适合二分类问题\n\t\n\t- 简单易于理解，直接看到各个特征的权重\n\n\t- 能容易地更新模型吸收新的数据\n\n\n- 缺点\n\n\t- 对数据和场景的适应能力有局限性，不如决策树算法适应性那么强\n\n### 逻辑回归的用途\n\n- **寻找主要影响因素**：  通过学习到的权重值，得到不同因素对结果的影响力大小\n\n\n- **预测**：  预测事件发生的概率\n\n\n### 建模常规步骤\n\n- 寻找 `h 函数`（预测函数）\n\n\n- 构造 `J 函数` (损失函数)\n\n\n- 利用梯度下降等方法最小化  `J 函数`，并求取参数\n\n### LR基本模型\n\n以下就是逻辑回归的基本模型：\n\n$$\ny=\\frac{1}{1+e^{-z}}\n$$\n\n$$\nz=w^{\\top} x+b\n$$\n\n取倒数\n\n$$\n\\frac{1}{y}=1+e^{-z}\n$$\n\n取对数\n\n$$\n\\ln \\left(\\frac{1}{y}-1\\right)=-z\n$$\n\n$$\n\\ln \\frac{y}{1-y}=\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}+b\n$$\n \n\nln(y/(1-y)) 就是对数几率\n\n## 代价函数\n\n线性模型常用的目标函数 `均方误差` 用在逻辑回归模型是非凸函数，非凸函数通过梯度下降法容易陷入局部最小值，因此需要想办法找到代价函数，且代价函数为凸函数。\n\n### 极大似然法定义代价函数\n这里通过极大似然估计的方法来定义目标函数：\n\n> **极大似然估计**： 这里想了很久才算有点理解，之前就一直卡在这里。。极大似然估计就是可以利用已知数据来推测出产生这些数据的最可能的环境条件。\n\n\n> 举个栗子，当我们扔硬币时，出现的可能性有两个，要么正面朝上（事件A），要么反面朝上(事件B)，假设出现某事件的可能性只与硬币的 `质量分布θ` 有关系，假设我们做了n组实验（A出现m次），这样能得到两种情况的概率 P(A), P(B),我们要推测出 `质量分布θ` 是多少，也就是 `参数估计` ,即 `质量分布θ` 是多少时，才最可能出现当前实验的结果。抛硬币的事件服从二项分布，那么给定了一组实验的情况下，似然函数是(似然函数与概率值相等)：\n> $$\nL\\left(\\theta ; x_{1}, \\ldots, x_{n}\\right)=f\\left(x_{1}, \\ldots, x_{n} ; \\theta\\right)=\\prod_{i=1}^{n} P\\left(X=x_{i}\\right)=\\theta^{m}(1-\\theta)^{n-m}\n$$\n\n假设一个数据集`Cn`,标签`y∈{0,1}`，预测值`Θ`,模型参数为`w`则似然函数可以写作:\n\n$$\nP\\left( \\theta _{\\left( x_i \\right)}|w \\right) =\\prod_{n=1}^N{\\theta}_{xi}^{yi}\\cdot \\left( 1-\\theta _{\\left( x_i \\right)} \\right) ^{1-y_i}\n$$\n\n\n取对数简化运算:\n\n$$\n\\mathrm{L}(\\mathrm{w}, \\mathrm{b})=\\sum_{i=1}^{N}\\left[y_{i} \\log \\left(\\emptyset\\left(x_{i}\\right)\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\emptyset\\left(x_{i}\\right)\\right)\\right]\n$$\n\n实际代价函数的样子:\n\n$$\n\\mathrm{J}(\\mathrm{w}, \\mathrm{b})=-\\frac{1}{N} \\mathrm{L}(\\mathrm{w}, \\mathrm{b})=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\log \\left(\\emptyset\\left(x_{i}\\right)\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\emptyset\\left(x_{i}\\right)\\right)\\right]\n$$\n\n取对数之后的公式很符合理想的代价函数，当实际标签与预测结果相同，则代价为0，而相反时，会随着差值越大，损失越大。\n\n因为\n$$\n\\operatorname{logit}(\\mathrm{p})=\\log \\frac{p}{1-p}\n$$\n\n$$\n\\log \\frac{P(Y=1 | X)}{1-P(Y=1 | X)}=w \\cdot x+b\n$$\n\n带入后继续化简\n$$\n\\mathrm{L}(\\mathrm{w}, \\mathrm{b})=\\sum_{i=1}^{N}\\left[y_{i}\\left(\\mathrm{w} \\cdot x_{i}+\\mathrm{b}\\right)-\\log \\left(1+e^{\\mathrm{w} \\cdot x_{i}+b}\\right)\\right]\n$$\n\n### 直观解释\n\n直观上理解，代价函数就是分类错误的惩罚，那么当y=1时，prediction 越小时，损失应越大；y=0时prediction 越大时，损失应越小。\n\n$$\n\\operatorname{cost}=\\left\\{\\begin{aligned}-\\log (\\hat{p}), & \\text { if } y=1 \\\\-\\log (1-\\hat{p}), & \\text { if } y=0 \\end{aligned}\\right.\n$$\n\n## 通过梯度下降来最小化代价函数\n\n因为我们找到的代价函数是凸函数，所以可以尝试用梯度下降来找到合适的参数w，b：\n\n$$\n\\mathrm{w} :=\\mathrm{w}-\\alpha \\frac{\\partial J(w, b)}{\\partial w}\n$$\n\n$$\n\\mathrm{b} :=\\mathrm{b}-\\alpha \\frac{\\partial J(w, b)}{\\partial b}\n$$\n\n偏导求解过程：\n\n对w求偏导\n\n$$\n\\frac{\\partial J(w, b)}{\\partial w}=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\frac{1}{\\partial\\left(x_{i}\\right)}-\\left(1-y_{i}\\right) \\frac{1}{1-\\emptyset\\left(x_{i}\\right)}\\right] \\frac{\\partial \\emptyset\\left(x_{i}\\right)}{\\partial w}\n$$\n\n$$\n=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\frac{1}{\\emptyset\\left(x_{i}\\right)}-\\left(1-y_{i}\\right) \\frac{1}{1-\\emptyset\\left(x_{i}\\right)}\\right] \\sigma\\left(x_{i}\\right)\\left(1-\\emptyset\\left(x_{i}\\right)\\right) \\cdot x_{i}\n$$\n\n$$\n=-\\frac{1}{N} \\Sigma_{i=1}^{N}\\left(y_{i}-\\emptyset\\left(x_{i}\\right)\\right) \\cdot x_{i^{*}}\n$$\n\n对b求偏导\n\n$$\n\\frac{\\partial J(w, b)}{\\partial b}=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\frac{1}{\\emptyset\\left(x_{i}\\right)}-\\left(1-y_{i}\\right) \\frac{1}{1-\\emptyset\\left(x_{i}\\right)}\\right] \\frac{\\partial \\emptyset\\left(x_{i}\\right)}{\\partial b}\n$$\n\n\n$$\n=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\frac{1}{\\emptyset\\left(x_{i}\\right)}-\\left(1-y_{i}\\right) \\frac{1}{1-\\emptyset\\left(x_{i}\\right)}\\right] \\wp\\left(x_{i}\\right)\\left(1-\\emptyset\\left(x_{i}\\right)\\right)\n$$\n\n$$\n=-\\frac{1}{N} \\Sigma_{i=1}^{N}\\left(y_{i}-\\emptyset\\left(x_{i}\\right)\\right)\n$$\n\n\n带入公式后，得到最终推导的结果：\n\n$$\n\\mathrm{w} :=\\mathrm{w}+\\alpha \\frac{1}{N} \\sum_{i=1}^{N}\\left(y_{i}-\\emptyset\\left(x_{i}\\right)\\right) \\cdot x_{i}\n$$\n\n$$\n\\mathrm{b} :=\\mathrm{b}+\\alpha \\frac{1}{N} \\sum_{i=1}^{N}\\left(y_{i}-\\emptyset\\left(x_{i}\\right)\\right)\n$$\n\n<font color=\"red\"> \n通过以上公式可以看出，逻辑回归的梯度与 `sigmoid` 本身无关，只与 `y` 和`x`和 `w` 有关系。</font>\n\n## 进一步提高泛化能力\n\n> 影响模型泛化能力的主因素是 `过拟合`, 过拟合问题比较容易理解，这里就不贴图了。下面分析一下产生过拟合的原因和解决办法。\n\n### 过拟合产生的原因有哪些？\n\n**过多的特征**\n\n### 怎么解决过拟合？\n\n1. 减少特征数量\n\n\t减少特征数量会导致部分信息丢失。\n\n2. 正则化\n\n\t保留所有的特征，并且减小参数的大小。\n\n### 正则化方法\n\n**在代价函数上增加一个惩罚项**，<font color=red>惩罚项应该是模型复杂度的单调递增函数，模型越复杂，惩罚项越大。 </font>\n\n回归问题中，取**平方损失**（L2 范数），或者L1范数\n\n$$\nJ(\\theta)=\\frac{1}{2 m} \\sum_{i=1}^{n}\\left(\\mathrm{h}_{\\theta}\\left(\\mathrm{x}_{i}\\right)-y_{i}\\right)^{2}+\\lambda \\sum_{j=1}^{n} \\theta_{j}^{2}\n$$\n\n这里的lambda 系数：\n\n 如果它的值很大，说明对模型的复杂度惩罚大，对拟合数据的损失惩罚小，这样它就不会过分拟合数据，在训练数据上的偏差较大，在未知数据上的方差较小，但是可能出现欠拟合的现象；\n\n 如果它的值很小，说明比较注重对训练数据的拟合，在训练数据上的偏差会小，但是可能会导致过拟合。\n\n加入正则化后的参数更新：\n\n$$\n\\theta_{j} :=\\theta_{j}-\\frac{\\alpha}{m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x_{i}\\right)-y_{i}\\right) x_{i}^{j}-\\frac{\\lambda}{m} \\theta_{j}\n$$\n\n\n## python 实现\n\n空\n\n## 参考资料\n\n[极大似然估计](https://irwenqiang.iteye.com/blog/1552680\"该部分参考这里\")","source":"_posts/逻辑回归.md","raw":"---\ntitle: 逻辑回归\nmathjax: true\ndate: 2019-04-27 13:01:43\ncategories: 机器学习方法\ntags: 逻辑回归\ncopyright:\npassword:\ntop: True\n---\n\n> 逻辑回归就是西瓜书里的对数几率回归，名为回归，实际则是分类算法。其实质是利用线性回归模型的预测结果来逼近真实标记的对数几率。\n> \n一句话概括就是:\n<font color=\"red\"> \n逻辑回归假设数据服从 **伯努利分布** ,通过 **极大化似然函数** 的方法，运用 **梯度下降** 来求解参数，来达到将数据二分类的目的。</font>\n\n## 线性模型如何处理二分类问题？\n\n> 在处理二分类任务时，我们希望模型能预测样本属于某类别的概率[0, 1]，或者直接输出类别的标签{0, 1}。 线性模型不能直接来完成这项任务，因为其输出是一个实际值，范围也不一定在0~1之间，无法体现我们所想要的概率或者标签。\n\n$$\ny=\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}+b\n$$\n\n因此，我们需要找到一种能把线性模型输出映射到 **概率** 或者 **标签** 的方法；\n\n- 如何转化为标签？\n\n\t单位阶跃函数\n\n- 如何转化为概率？\n\n\tsigmoid函数 (二分类): 将无穷范围的值限制在(0, 1)之间\n \n\tsoftmax函数（多分类）: 所有类别概率和为1\n\n![logo](逻辑回归/sigmoid.png)\n\n由于单位阶跃函数存在跳跃点，在跳跃点不可导，想选择梯度下降法来优化时，只能选择sigmoid函数了。\n\n## 逻辑回归模型\n\n> 逻辑回归就是这样的一个过程：面对一个分类问题，建立代价函数，然后通过优化方\n法迭代求解出最优的模型参数，然后测试验证我们这个求解的模型的好坏。\n\n### 逻辑回归的优缺点\n\n- 优点 \n\n\t- 速度快，适合二分类问题\n\t\n\t- 简单易于理解，直接看到各个特征的权重\n\n\t- 能容易地更新模型吸收新的数据\n\n\n- 缺点\n\n\t- 对数据和场景的适应能力有局限性，不如决策树算法适应性那么强\n\n### 逻辑回归的用途\n\n- **寻找主要影响因素**：  通过学习到的权重值，得到不同因素对结果的影响力大小\n\n\n- **预测**：  预测事件发生的概率\n\n\n### 建模常规步骤\n\n- 寻找 `h 函数`（预测函数）\n\n\n- 构造 `J 函数` (损失函数)\n\n\n- 利用梯度下降等方法最小化  `J 函数`，并求取参数\n\n### LR基本模型\n\n以下就是逻辑回归的基本模型：\n\n$$\ny=\\frac{1}{1+e^{-z}}\n$$\n\n$$\nz=w^{\\top} x+b\n$$\n\n取倒数\n\n$$\n\\frac{1}{y}=1+e^{-z}\n$$\n\n取对数\n\n$$\n\\ln \\left(\\frac{1}{y}-1\\right)=-z\n$$\n\n$$\n\\ln \\frac{y}{1-y}=\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}+b\n$$\n \n\nln(y/(1-y)) 就是对数几率\n\n## 代价函数\n\n线性模型常用的目标函数 `均方误差` 用在逻辑回归模型是非凸函数，非凸函数通过梯度下降法容易陷入局部最小值，因此需要想办法找到代价函数，且代价函数为凸函数。\n\n### 极大似然法定义代价函数\n这里通过极大似然估计的方法来定义目标函数：\n\n> **极大似然估计**： 这里想了很久才算有点理解，之前就一直卡在这里。。极大似然估计就是可以利用已知数据来推测出产生这些数据的最可能的环境条件。\n\n\n> 举个栗子，当我们扔硬币时，出现的可能性有两个，要么正面朝上（事件A），要么反面朝上(事件B)，假设出现某事件的可能性只与硬币的 `质量分布θ` 有关系，假设我们做了n组实验（A出现m次），这样能得到两种情况的概率 P(A), P(B),我们要推测出 `质量分布θ` 是多少，也就是 `参数估计` ,即 `质量分布θ` 是多少时，才最可能出现当前实验的结果。抛硬币的事件服从二项分布，那么给定了一组实验的情况下，似然函数是(似然函数与概率值相等)：\n> $$\nL\\left(\\theta ; x_{1}, \\ldots, x_{n}\\right)=f\\left(x_{1}, \\ldots, x_{n} ; \\theta\\right)=\\prod_{i=1}^{n} P\\left(X=x_{i}\\right)=\\theta^{m}(1-\\theta)^{n-m}\n$$\n\n假设一个数据集`Cn`,标签`y∈{0,1}`，预测值`Θ`,模型参数为`w`则似然函数可以写作:\n\n$$\nP\\left( \\theta _{\\left( x_i \\right)}|w \\right) =\\prod_{n=1}^N{\\theta}_{xi}^{yi}\\cdot \\left( 1-\\theta _{\\left( x_i \\right)} \\right) ^{1-y_i}\n$$\n\n\n取对数简化运算:\n\n$$\n\\mathrm{L}(\\mathrm{w}, \\mathrm{b})=\\sum_{i=1}^{N}\\left[y_{i} \\log \\left(\\emptyset\\left(x_{i}\\right)\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\emptyset\\left(x_{i}\\right)\\right)\\right]\n$$\n\n实际代价函数的样子:\n\n$$\n\\mathrm{J}(\\mathrm{w}, \\mathrm{b})=-\\frac{1}{N} \\mathrm{L}(\\mathrm{w}, \\mathrm{b})=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\log \\left(\\emptyset\\left(x_{i}\\right)\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\emptyset\\left(x_{i}\\right)\\right)\\right]\n$$\n\n取对数之后的公式很符合理想的代价函数，当实际标签与预测结果相同，则代价为0，而相反时，会随着差值越大，损失越大。\n\n因为\n$$\n\\operatorname{logit}(\\mathrm{p})=\\log \\frac{p}{1-p}\n$$\n\n$$\n\\log \\frac{P(Y=1 | X)}{1-P(Y=1 | X)}=w \\cdot x+b\n$$\n\n带入后继续化简\n$$\n\\mathrm{L}(\\mathrm{w}, \\mathrm{b})=\\sum_{i=1}^{N}\\left[y_{i}\\left(\\mathrm{w} \\cdot x_{i}+\\mathrm{b}\\right)-\\log \\left(1+e^{\\mathrm{w} \\cdot x_{i}+b}\\right)\\right]\n$$\n\n### 直观解释\n\n直观上理解，代价函数就是分类错误的惩罚，那么当y=1时，prediction 越小时，损失应越大；y=0时prediction 越大时，损失应越小。\n\n$$\n\\operatorname{cost}=\\left\\{\\begin{aligned}-\\log (\\hat{p}), & \\text { if } y=1 \\\\-\\log (1-\\hat{p}), & \\text { if } y=0 \\end{aligned}\\right.\n$$\n\n## 通过梯度下降来最小化代价函数\n\n因为我们找到的代价函数是凸函数，所以可以尝试用梯度下降来找到合适的参数w，b：\n\n$$\n\\mathrm{w} :=\\mathrm{w}-\\alpha \\frac{\\partial J(w, b)}{\\partial w}\n$$\n\n$$\n\\mathrm{b} :=\\mathrm{b}-\\alpha \\frac{\\partial J(w, b)}{\\partial b}\n$$\n\n偏导求解过程：\n\n对w求偏导\n\n$$\n\\frac{\\partial J(w, b)}{\\partial w}=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\frac{1}{\\partial\\left(x_{i}\\right)}-\\left(1-y_{i}\\right) \\frac{1}{1-\\emptyset\\left(x_{i}\\right)}\\right] \\frac{\\partial \\emptyset\\left(x_{i}\\right)}{\\partial w}\n$$\n\n$$\n=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\frac{1}{\\emptyset\\left(x_{i}\\right)}-\\left(1-y_{i}\\right) \\frac{1}{1-\\emptyset\\left(x_{i}\\right)}\\right] \\sigma\\left(x_{i}\\right)\\left(1-\\emptyset\\left(x_{i}\\right)\\right) \\cdot x_{i}\n$$\n\n$$\n=-\\frac{1}{N} \\Sigma_{i=1}^{N}\\left(y_{i}-\\emptyset\\left(x_{i}\\right)\\right) \\cdot x_{i^{*}}\n$$\n\n对b求偏导\n\n$$\n\\frac{\\partial J(w, b)}{\\partial b}=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\frac{1}{\\emptyset\\left(x_{i}\\right)}-\\left(1-y_{i}\\right) \\frac{1}{1-\\emptyset\\left(x_{i}\\right)}\\right] \\frac{\\partial \\emptyset\\left(x_{i}\\right)}{\\partial b}\n$$\n\n\n$$\n=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\frac{1}{\\emptyset\\left(x_{i}\\right)}-\\left(1-y_{i}\\right) \\frac{1}{1-\\emptyset\\left(x_{i}\\right)}\\right] \\wp\\left(x_{i}\\right)\\left(1-\\emptyset\\left(x_{i}\\right)\\right)\n$$\n\n$$\n=-\\frac{1}{N} \\Sigma_{i=1}^{N}\\left(y_{i}-\\emptyset\\left(x_{i}\\right)\\right)\n$$\n\n\n带入公式后，得到最终推导的结果：\n\n$$\n\\mathrm{w} :=\\mathrm{w}+\\alpha \\frac{1}{N} \\sum_{i=1}^{N}\\left(y_{i}-\\emptyset\\left(x_{i}\\right)\\right) \\cdot x_{i}\n$$\n\n$$\n\\mathrm{b} :=\\mathrm{b}+\\alpha \\frac{1}{N} \\sum_{i=1}^{N}\\left(y_{i}-\\emptyset\\left(x_{i}\\right)\\right)\n$$\n\n<font color=\"red\"> \n通过以上公式可以看出，逻辑回归的梯度与 `sigmoid` 本身无关，只与 `y` 和`x`和 `w` 有关系。</font>\n\n## 进一步提高泛化能力\n\n> 影响模型泛化能力的主因素是 `过拟合`, 过拟合问题比较容易理解，这里就不贴图了。下面分析一下产生过拟合的原因和解决办法。\n\n### 过拟合产生的原因有哪些？\n\n**过多的特征**\n\n### 怎么解决过拟合？\n\n1. 减少特征数量\n\n\t减少特征数量会导致部分信息丢失。\n\n2. 正则化\n\n\t保留所有的特征，并且减小参数的大小。\n\n### 正则化方法\n\n**在代价函数上增加一个惩罚项**，<font color=red>惩罚项应该是模型复杂度的单调递增函数，模型越复杂，惩罚项越大。 </font>\n\n回归问题中，取**平方损失**（L2 范数），或者L1范数\n\n$$\nJ(\\theta)=\\frac{1}{2 m} \\sum_{i=1}^{n}\\left(\\mathrm{h}_{\\theta}\\left(\\mathrm{x}_{i}\\right)-y_{i}\\right)^{2}+\\lambda \\sum_{j=1}^{n} \\theta_{j}^{2}\n$$\n\n这里的lambda 系数：\n\n 如果它的值很大，说明对模型的复杂度惩罚大，对拟合数据的损失惩罚小，这样它就不会过分拟合数据，在训练数据上的偏差较大，在未知数据上的方差较小，但是可能出现欠拟合的现象；\n\n 如果它的值很小，说明比较注重对训练数据的拟合，在训练数据上的偏差会小，但是可能会导致过拟合。\n\n加入正则化后的参数更新：\n\n$$\n\\theta_{j} :=\\theta_{j}-\\frac{\\alpha}{m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x_{i}\\right)-y_{i}\\right) x_{i}^{j}-\\frac{\\lambda}{m} \\theta_{j}\n$$\n\n\n## python 实现\n\n空\n\n## 参考资料\n\n[极大似然估计](https://irwenqiang.iteye.com/blog/1552680\"该部分参考这里\")","slug":"逻辑回归","published":1,"updated":"2019-07-30T15:35:42.744Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz98jha1002cy0pl7tjkwgl5","content":"<blockquote>\n<p>逻辑回归就是西瓜书里的对数几率回归，名为回归，实际则是分类算法。其实质是利用线性回归模型的预测结果来逼近真实标记的对数几率。</p>\n<p>一句话概括就是:</p>\n<font color=\"red\"> \n逻辑回归假设数据服从 **伯努利分布** ,通过 **极大化似然函数** 的方法，运用 **梯度下降** 来求解参数，来达到将数据二分类的目的。</font>\n\n</blockquote>\n<h2 id=\"线性模型如何处理二分类问题？\"><a href=\"#线性模型如何处理二分类问题？\" class=\"headerlink\" title=\"线性模型如何处理二分类问题？\"></a>线性模型如何处理二分类问题？</h2><blockquote>\n<p>在处理二分类任务时，我们希望模型能预测样本属于某类别的概率[0, 1]，或者直接输出类别的标签{0, 1}。 线性模型不能直接来完成这项任务，因为其输出是一个实际值，范围也不一定在0~1之间，无法体现我们所想要的概率或者标签。</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">\ny=\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}+b</script><p>因此，我们需要找到一种能把线性模型输出映射到 <strong>概率</strong> 或者 <strong>标签</strong> 的方法；</p>\n<ul>\n<li><p>如何转化为标签？</p>\n<p>  单位阶跃函数</p>\n</li>\n<li><p>如何转化为概率？</p>\n<p>  sigmoid函数 (二分类): 将无穷范围的值限制在(0, 1)之间</p>\n<p>  softmax函数（多分类）: 所有类别概率和为1</p>\n</li>\n</ul>\n<p><img src=\"/2019/04/27/逻辑回归/sigmoid.png\" alt=\"logo\"></p>\n<p>由于单位阶跃函数存在跳跃点，在跳跃点不可导，想选择梯度下降法来优化时，只能选择sigmoid函数了。</p>\n<h2 id=\"逻辑回归模型\"><a href=\"#逻辑回归模型\" class=\"headerlink\" title=\"逻辑回归模型\"></a>逻辑回归模型</h2><blockquote>\n<p>逻辑回归就是这样的一个过程：面对一个分类问题，建立代价函数，然后通过优化方<br>法迭代求解出最优的模型参数，然后测试验证我们这个求解的模型的好坏。</p>\n</blockquote>\n<h3 id=\"逻辑回归的优缺点\"><a href=\"#逻辑回归的优缺点\" class=\"headerlink\" title=\"逻辑回归的优缺点\"></a>逻辑回归的优缺点</h3><ul>\n<li><p>优点 </p>\n<ul>\n<li><p>速度快，适合二分类问题</p>\n</li>\n<li><p>简单易于理解，直接看到各个特征的权重</p>\n</li>\n<li><p>能容易地更新模型吸收新的数据</p>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>缺点</p>\n<ul>\n<li>对数据和场景的适应能力有局限性，不如决策树算法适应性那么强</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"逻辑回归的用途\"><a href=\"#逻辑回归的用途\" class=\"headerlink\" title=\"逻辑回归的用途\"></a>逻辑回归的用途</h3><ul>\n<li><strong>寻找主要影响因素</strong>：  通过学习到的权重值，得到不同因素对结果的影响力大小</li>\n</ul>\n<ul>\n<li><strong>预测</strong>：  预测事件发生的概率</li>\n</ul>\n<h3 id=\"建模常规步骤\"><a href=\"#建模常规步骤\" class=\"headerlink\" title=\"建模常规步骤\"></a>建模常规步骤</h3><ul>\n<li>寻找 <code>h 函数</code>（预测函数）</li>\n</ul>\n<ul>\n<li>构造 <code>J 函数</code> (损失函数)</li>\n</ul>\n<ul>\n<li>利用梯度下降等方法最小化  <code>J 函数</code>，并求取参数</li>\n</ul>\n<h3 id=\"LR基本模型\"><a href=\"#LR基本模型\" class=\"headerlink\" title=\"LR基本模型\"></a>LR基本模型</h3><p>以下就是逻辑回归的基本模型：</p>\n<script type=\"math/tex; mode=display\">\ny=\\frac{1}{1+e^{-z}}</script><script type=\"math/tex; mode=display\">\nz=w^{\\top} x+b</script><p>取倒数</p>\n<script type=\"math/tex; mode=display\">\n\\frac{1}{y}=1+e^{-z}</script><p>取对数</p>\n<script type=\"math/tex; mode=display\">\n\\ln \\left(\\frac{1}{y}-1\\right)=-z</script><script type=\"math/tex; mode=display\">\n\\ln \\frac{y}{1-y}=\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}+b</script><p>ln(y/(1-y)) 就是对数几率</p>\n<h2 id=\"代价函数\"><a href=\"#代价函数\" class=\"headerlink\" title=\"代价函数\"></a>代价函数</h2><p>线性模型常用的目标函数 <code>均方误差</code> 用在逻辑回归模型是非凸函数，非凸函数通过梯度下降法容易陷入局部最小值，因此需要想办法找到代价函数，且代价函数为凸函数。</p>\n<h3 id=\"极大似然法定义代价函数\"><a href=\"#极大似然法定义代价函数\" class=\"headerlink\" title=\"极大似然法定义代价函数\"></a>极大似然法定义代价函数</h3><p>这里通过极大似然估计的方法来定义目标函数：</p>\n<blockquote>\n<p><strong>极大似然估计</strong>： 这里想了很久才算有点理解，之前就一直卡在这里。。极大似然估计就是可以利用已知数据来推测出产生这些数据的最可能的环境条件。</p>\n<p>举个栗子，当我们扔硬币时，出现的可能性有两个，要么正面朝上（事件A），要么反面朝上(事件B)，假设出现某事件的可能性只与硬币的 <code>质量分布θ</code> 有关系，假设我们做了n组实验（A出现m次），这样能得到两种情况的概率 P(A), P(B),我们要推测出 <code>质量分布θ</code> 是多少，也就是 <code>参数估计</code> ,即 <code>质量分布θ</code> 是多少时，才最可能出现当前实验的结果。抛硬币的事件服从二项分布，那么给定了一组实验的情况下，似然函数是(似然函数与概率值相等)：</p>\n<script type=\"math/tex; mode=display\">\nL\\left(\\theta ; x_{1}, \\ldots, x_{n}\\right)=f\\left(x_{1}, \\ldots, x_{n} ; \\theta\\right)=\\prod_{i=1}^{n} P\\left(X=x_{i}\\right)=\\theta^{m}(1-\\theta)^{n-m}</script></blockquote>\n<p>假设一个数据集<code>Cn</code>,标签<code>y∈{0,1}</code>，预测值<code>Θ</code>,模型参数为<code>w</code>则似然函数可以写作:</p>\n<script type=\"math/tex; mode=display\">\nP\\left( \\theta _{\\left( x_i \\right)}|w \\right) =\\prod_{n=1}^N{\\theta}_{xi}^{yi}\\cdot \\left( 1-\\theta _{\\left( x_i \\right)} \\right) ^{1-y_i}</script><p>取对数简化运算:</p>\n<script type=\"math/tex; mode=display\">\n\\mathrm{L}(\\mathrm{w}, \\mathrm{b})=\\sum_{i=1}^{N}\\left[y_{i} \\log \\left(\\emptyset\\left(x_{i}\\right)\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\emptyset\\left(x_{i}\\right)\\right)\\right]</script><p>实际代价函数的样子:</p>\n<script type=\"math/tex; mode=display\">\n\\mathrm{J}(\\mathrm{w}, \\mathrm{b})=-\\frac{1}{N} \\mathrm{L}(\\mathrm{w}, \\mathrm{b})=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\log \\left(\\emptyset\\left(x_{i}\\right)\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\emptyset\\left(x_{i}\\right)\\right)\\right]</script><p>取对数之后的公式很符合理想的代价函数，当实际标签与预测结果相同，则代价为0，而相反时，会随着差值越大，损失越大。</p>\n<p>因为</p>\n<script type=\"math/tex; mode=display\">\n\\operatorname{logit}(\\mathrm{p})=\\log \\frac{p}{1-p}</script><script type=\"math/tex; mode=display\">\n\\log \\frac{P(Y=1 | X)}{1-P(Y=1 | X)}=w \\cdot x+b</script><p>带入后继续化简</p>\n<script type=\"math/tex; mode=display\">\n\\mathrm{L}(\\mathrm{w}, \\mathrm{b})=\\sum_{i=1}^{N}\\left[y_{i}\\left(\\mathrm{w} \\cdot x_{i}+\\mathrm{b}\\right)-\\log \\left(1+e^{\\mathrm{w} \\cdot x_{i}+b}\\right)\\right]</script><h3 id=\"直观解释\"><a href=\"#直观解释\" class=\"headerlink\" title=\"直观解释\"></a>直观解释</h3><p>直观上理解，代价函数就是分类错误的惩罚，那么当y=1时，prediction 越小时，损失应越大；y=0时prediction 越大时，损失应越小。</p>\n<script type=\"math/tex; mode=display\">\n\\operatorname{cost}=\\left\\{\\begin{aligned}-\\log (\\hat{p}), & \\text { if } y=1 \\\\-\\log (1-\\hat{p}), & \\text { if } y=0 \\end{aligned}\\right.</script><h2 id=\"通过梯度下降来最小化代价函数\"><a href=\"#通过梯度下降来最小化代价函数\" class=\"headerlink\" title=\"通过梯度下降来最小化代价函数\"></a>通过梯度下降来最小化代价函数</h2><p>因为我们找到的代价函数是凸函数，所以可以尝试用梯度下降来找到合适的参数w，b：</p>\n<script type=\"math/tex; mode=display\">\n\\mathrm{w} :=\\mathrm{w}-\\alpha \\frac{\\partial J(w, b)}{\\partial w}</script><script type=\"math/tex; mode=display\">\n\\mathrm{b} :=\\mathrm{b}-\\alpha \\frac{\\partial J(w, b)}{\\partial b}</script><p>偏导求解过程：</p>\n<p>对w求偏导</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial J(w, b)}{\\partial w}=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\frac{1}{\\partial\\left(x_{i}\\right)}-\\left(1-y_{i}\\right) \\frac{1}{1-\\emptyset\\left(x_{i}\\right)}\\right] \\frac{\\partial \\emptyset\\left(x_{i}\\right)}{\\partial w}</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\frac{1}{\\emptyset\\left(x_{i}\\right)}-\\left(1-y_{i}\\right) \\frac{1}{1-\\emptyset\\left(x_{i}\\right)}\\right] \\sigma\\left(x_{i}\\right)\\left(1-\\emptyset\\left(x_{i}\\right)\\right) \\cdot x_{i}</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{N} \\Sigma_{i=1}^{N}\\left(y_{i}-\\emptyset\\left(x_{i}\\right)\\right) \\cdot x_{i^{*}}</script><p>对b求偏导</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial J(w, b)}{\\partial b}=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\frac{1}{\\emptyset\\left(x_{i}\\right)}-\\left(1-y_{i}\\right) \\frac{1}{1-\\emptyset\\left(x_{i}\\right)}\\right] \\frac{\\partial \\emptyset\\left(x_{i}\\right)}{\\partial b}</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\frac{1}{\\emptyset\\left(x_{i}\\right)}-\\left(1-y_{i}\\right) \\frac{1}{1-\\emptyset\\left(x_{i}\\right)}\\right] \\wp\\left(x_{i}\\right)\\left(1-\\emptyset\\left(x_{i}\\right)\\right)</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{N} \\Sigma_{i=1}^{N}\\left(y_{i}-\\emptyset\\left(x_{i}\\right)\\right)</script><p>带入公式后，得到最终推导的结果：</p>\n<script type=\"math/tex; mode=display\">\n\\mathrm{w} :=\\mathrm{w}+\\alpha \\frac{1}{N} \\sum_{i=1}^{N}\\left(y_{i}-\\emptyset\\left(x_{i}\\right)\\right) \\cdot x_{i}</script><script type=\"math/tex; mode=display\">\n\\mathrm{b} :=\\mathrm{b}+\\alpha \\frac{1}{N} \\sum_{i=1}^{N}\\left(y_{i}-\\emptyset\\left(x_{i}\\right)\\right)</script><font color=\"red\"> \n通过以上公式可以看出，逻辑回归的梯度与 `sigmoid` 本身无关，只与 `y` 和`x`和 `w` 有关系。</font>\n\n<h2 id=\"进一步提高泛化能力\"><a href=\"#进一步提高泛化能力\" class=\"headerlink\" title=\"进一步提高泛化能力\"></a>进一步提高泛化能力</h2><blockquote>\n<p>影响模型泛化能力的主因素是 <code>过拟合</code>, 过拟合问题比较容易理解，这里就不贴图了。下面分析一下产生过拟合的原因和解决办法。</p>\n</blockquote>\n<h3 id=\"过拟合产生的原因有哪些？\"><a href=\"#过拟合产生的原因有哪些？\" class=\"headerlink\" title=\"过拟合产生的原因有哪些？\"></a>过拟合产生的原因有哪些？</h3><p><strong>过多的特征</strong></p>\n<h3 id=\"怎么解决过拟合？\"><a href=\"#怎么解决过拟合？\" class=\"headerlink\" title=\"怎么解决过拟合？\"></a>怎么解决过拟合？</h3><ol>\n<li><p>减少特征数量</p>\n<p> 减少特征数量会导致部分信息丢失。</p>\n</li>\n<li><p>正则化</p>\n<p> 保留所有的特征，并且减小参数的大小。</p>\n</li>\n</ol>\n<h3 id=\"正则化方法\"><a href=\"#正则化方法\" class=\"headerlink\" title=\"正则化方法\"></a>正则化方法</h3><p><strong>在代价函数上增加一个惩罚项</strong>，<font color=\"red\">惩罚项应该是模型复杂度的单调递增函数，模型越复杂，惩罚项越大。 </font></p>\n<p>回归问题中，取<strong>平方损失</strong>（L2 范数），或者L1范数</p>\n<script type=\"math/tex; mode=display\">\nJ(\\theta)=\\frac{1}{2 m} \\sum_{i=1}^{n}\\left(\\mathrm{h}_{\\theta}\\left(\\mathrm{x}_{i}\\right)-y_{i}\\right)^{2}+\\lambda \\sum_{j=1}^{n} \\theta_{j}^{2}</script><p>这里的lambda 系数：</p>\n<p> 如果它的值很大，说明对模型的复杂度惩罚大，对拟合数据的损失惩罚小，这样它就不会过分拟合数据，在训练数据上的偏差较大，在未知数据上的方差较小，但是可能出现欠拟合的现象；</p>\n<p> 如果它的值很小，说明比较注重对训练数据的拟合，在训练数据上的偏差会小，但是可能会导致过拟合。</p>\n<p>加入正则化后的参数更新：</p>\n<script type=\"math/tex; mode=display\">\n\\theta_{j} :=\\theta_{j}-\\frac{\\alpha}{m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x_{i}\\right)-y_{i}\\right) x_{i}^{j}-\\frac{\\lambda}{m} \\theta_{j}</script><h2 id=\"python-实现\"><a href=\"#python-实现\" class=\"headerlink\" title=\"python 实现\"></a>python 实现</h2><p>空</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://irwenqiang.iteye.com/blog/1552680&quot;该部分参考这里&quot;\" target=\"_blank\" rel=\"noopener\">极大似然估计</a></p>\n","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>逻辑回归就是西瓜书里的对数几率回归，名为回归，实际则是分类算法。其实质是利用线性回归模型的预测结果来逼近真实标记的对数几率。</p>\n<p>一句话概括就是:</p>\n<font color=\"red\"> \n逻辑回归假设数据服从 **伯努利分布** ,通过 **极大化似然函数** 的方法，运用 **梯度下降** 来求解参数，来达到将数据二分类的目的。</font>\n\n</blockquote>\n<h2 id=\"线性模型如何处理二分类问题？\"><a href=\"#线性模型如何处理二分类问题？\" class=\"headerlink\" title=\"线性模型如何处理二分类问题？\"></a>线性模型如何处理二分类问题？</h2><blockquote>\n<p>在处理二分类任务时，我们希望模型能预测样本属于某类别的概率[0, 1]，或者直接输出类别的标签{0, 1}。 线性模型不能直接来完成这项任务，因为其输出是一个实际值，范围也不一定在0~1之间，无法体现我们所想要的概率或者标签。</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">\ny=\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}+b</script><p>因此，我们需要找到一种能把线性模型输出映射到 <strong>概率</strong> 或者 <strong>标签</strong> 的方法；</p>\n<ul>\n<li><p>如何转化为标签？</p>\n<p>  单位阶跃函数</p>\n</li>\n<li><p>如何转化为概率？</p>\n<p>  sigmoid函数 (二分类): 将无穷范围的值限制在(0, 1)之间</p>\n<p>  softmax函数（多分类）: 所有类别概率和为1</p>\n</li>\n</ul>\n<p><img src=\"/2019/04/27/逻辑回归/sigmoid.png\" alt=\"logo\"></p>\n<p>由于单位阶跃函数存在跳跃点，在跳跃点不可导，想选择梯度下降法来优化时，只能选择sigmoid函数了。</p>\n<h2 id=\"逻辑回归模型\"><a href=\"#逻辑回归模型\" class=\"headerlink\" title=\"逻辑回归模型\"></a>逻辑回归模型</h2><blockquote>\n<p>逻辑回归就是这样的一个过程：面对一个分类问题，建立代价函数，然后通过优化方<br>法迭代求解出最优的模型参数，然后测试验证我们这个求解的模型的好坏。</p>\n</blockquote>\n<h3 id=\"逻辑回归的优缺点\"><a href=\"#逻辑回归的优缺点\" class=\"headerlink\" title=\"逻辑回归的优缺点\"></a>逻辑回归的优缺点</h3><ul>\n<li><p>优点 </p>\n<ul>\n<li><p>速度快，适合二分类问题</p>\n</li>\n<li><p>简单易于理解，直接看到各个特征的权重</p>\n</li>\n<li><p>能容易地更新模型吸收新的数据</p>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li><p>缺点</p>\n<ul>\n<li>对数据和场景的适应能力有局限性，不如决策树算法适应性那么强</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"逻辑回归的用途\"><a href=\"#逻辑回归的用途\" class=\"headerlink\" title=\"逻辑回归的用途\"></a>逻辑回归的用途</h3><ul>\n<li><strong>寻找主要影响因素</strong>：  通过学习到的权重值，得到不同因素对结果的影响力大小</li>\n</ul>\n<ul>\n<li><strong>预测</strong>：  预测事件发生的概率</li>\n</ul>\n<h3 id=\"建模常规步骤\"><a href=\"#建模常规步骤\" class=\"headerlink\" title=\"建模常规步骤\"></a>建模常规步骤</h3><ul>\n<li>寻找 <code>h 函数</code>（预测函数）</li>\n</ul>\n<ul>\n<li>构造 <code>J 函数</code> (损失函数)</li>\n</ul>\n<ul>\n<li>利用梯度下降等方法最小化  <code>J 函数</code>，并求取参数</li>\n</ul>\n<h3 id=\"LR基本模型\"><a href=\"#LR基本模型\" class=\"headerlink\" title=\"LR基本模型\"></a>LR基本模型</h3><p>以下就是逻辑回归的基本模型：</p>\n<script type=\"math/tex; mode=display\">\ny=\\frac{1}{1+e^{-z}}</script><script type=\"math/tex; mode=display\">\nz=w^{\\top} x+b</script><p>取倒数</p>\n<script type=\"math/tex; mode=display\">\n\\frac{1}{y}=1+e^{-z}</script><p>取对数</p>\n<script type=\"math/tex; mode=display\">\n\\ln \\left(\\frac{1}{y}-1\\right)=-z</script><script type=\"math/tex; mode=display\">\n\\ln \\frac{y}{1-y}=\\boldsymbol{w}^{\\mathrm{T}} \\boldsymbol{x}+b</script><p>ln(y/(1-y)) 就是对数几率</p>\n<h2 id=\"代价函数\"><a href=\"#代价函数\" class=\"headerlink\" title=\"代价函数\"></a>代价函数</h2><p>线性模型常用的目标函数 <code>均方误差</code> 用在逻辑回归模型是非凸函数，非凸函数通过梯度下降法容易陷入局部最小值，因此需要想办法找到代价函数，且代价函数为凸函数。</p>\n<h3 id=\"极大似然法定义代价函数\"><a href=\"#极大似然法定义代价函数\" class=\"headerlink\" title=\"极大似然法定义代价函数\"></a>极大似然法定义代价函数</h3><p>这里通过极大似然估计的方法来定义目标函数：</p>\n<blockquote>\n<p><strong>极大似然估计</strong>： 这里想了很久才算有点理解，之前就一直卡在这里。。极大似然估计就是可以利用已知数据来推测出产生这些数据的最可能的环境条件。</p>\n<p>举个栗子，当我们扔硬币时，出现的可能性有两个，要么正面朝上（事件A），要么反面朝上(事件B)，假设出现某事件的可能性只与硬币的 <code>质量分布θ</code> 有关系，假设我们做了n组实验（A出现m次），这样能得到两种情况的概率 P(A), P(B),我们要推测出 <code>质量分布θ</code> 是多少，也就是 <code>参数估计</code> ,即 <code>质量分布θ</code> 是多少时，才最可能出现当前实验的结果。抛硬币的事件服从二项分布，那么给定了一组实验的情况下，似然函数是(似然函数与概率值相等)：</p>\n<script type=\"math/tex; mode=display\">\nL\\left(\\theta ; x_{1}, \\ldots, x_{n}\\right)=f\\left(x_{1}, \\ldots, x_{n} ; \\theta\\right)=\\prod_{i=1}^{n} P\\left(X=x_{i}\\right)=\\theta^{m}(1-\\theta)^{n-m}</script></blockquote>\n<p>假设一个数据集<code>Cn</code>,标签<code>y∈{0,1}</code>，预测值<code>Θ</code>,模型参数为<code>w</code>则似然函数可以写作:</p>\n<script type=\"math/tex; mode=display\">\nP\\left( \\theta _{\\left( x_i \\right)}|w \\right) =\\prod_{n=1}^N{\\theta}_{xi}^{yi}\\cdot \\left( 1-\\theta _{\\left( x_i \\right)} \\right) ^{1-y_i}</script><p>取对数简化运算:</p>\n<script type=\"math/tex; mode=display\">\n\\mathrm{L}(\\mathrm{w}, \\mathrm{b})=\\sum_{i=1}^{N}\\left[y_{i} \\log \\left(\\emptyset\\left(x_{i}\\right)\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\emptyset\\left(x_{i}\\right)\\right)\\right]</script><p>实际代价函数的样子:</p>\n<script type=\"math/tex; mode=display\">\n\\mathrm{J}(\\mathrm{w}, \\mathrm{b})=-\\frac{1}{N} \\mathrm{L}(\\mathrm{w}, \\mathrm{b})=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\log \\left(\\emptyset\\left(x_{i}\\right)\\right)+\\left(1-y_{i}\\right) \\log \\left(1-\\emptyset\\left(x_{i}\\right)\\right)\\right]</script><p>取对数之后的公式很符合理想的代价函数，当实际标签与预测结果相同，则代价为0，而相反时，会随着差值越大，损失越大。</p>\n<p>因为</p>\n<script type=\"math/tex; mode=display\">\n\\operatorname{logit}(\\mathrm{p})=\\log \\frac{p}{1-p}</script><script type=\"math/tex; mode=display\">\n\\log \\frac{P(Y=1 | X)}{1-P(Y=1 | X)}=w \\cdot x+b</script><p>带入后继续化简</p>\n<script type=\"math/tex; mode=display\">\n\\mathrm{L}(\\mathrm{w}, \\mathrm{b})=\\sum_{i=1}^{N}\\left[y_{i}\\left(\\mathrm{w} \\cdot x_{i}+\\mathrm{b}\\right)-\\log \\left(1+e^{\\mathrm{w} \\cdot x_{i}+b}\\right)\\right]</script><h3 id=\"直观解释\"><a href=\"#直观解释\" class=\"headerlink\" title=\"直观解释\"></a>直观解释</h3><p>直观上理解，代价函数就是分类错误的惩罚，那么当y=1时，prediction 越小时，损失应越大；y=0时prediction 越大时，损失应越小。</p>\n<script type=\"math/tex; mode=display\">\n\\operatorname{cost}=\\left\\{\\begin{aligned}-\\log (\\hat{p}), & \\text { if } y=1 \\\\-\\log (1-\\hat{p}), & \\text { if } y=0 \\end{aligned}\\right.</script><h2 id=\"通过梯度下降来最小化代价函数\"><a href=\"#通过梯度下降来最小化代价函数\" class=\"headerlink\" title=\"通过梯度下降来最小化代价函数\"></a>通过梯度下降来最小化代价函数</h2><p>因为我们找到的代价函数是凸函数，所以可以尝试用梯度下降来找到合适的参数w，b：</p>\n<script type=\"math/tex; mode=display\">\n\\mathrm{w} :=\\mathrm{w}-\\alpha \\frac{\\partial J(w, b)}{\\partial w}</script><script type=\"math/tex; mode=display\">\n\\mathrm{b} :=\\mathrm{b}-\\alpha \\frac{\\partial J(w, b)}{\\partial b}</script><p>偏导求解过程：</p>\n<p>对w求偏导</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial J(w, b)}{\\partial w}=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\frac{1}{\\partial\\left(x_{i}\\right)}-\\left(1-y_{i}\\right) \\frac{1}{1-\\emptyset\\left(x_{i}\\right)}\\right] \\frac{\\partial \\emptyset\\left(x_{i}\\right)}{\\partial w}</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\frac{1}{\\emptyset\\left(x_{i}\\right)}-\\left(1-y_{i}\\right) \\frac{1}{1-\\emptyset\\left(x_{i}\\right)}\\right] \\sigma\\left(x_{i}\\right)\\left(1-\\emptyset\\left(x_{i}\\right)\\right) \\cdot x_{i}</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{N} \\Sigma_{i=1}^{N}\\left(y_{i}-\\emptyset\\left(x_{i}\\right)\\right) \\cdot x_{i^{*}}</script><p>对b求偏导</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial J(w, b)}{\\partial b}=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\frac{1}{\\emptyset\\left(x_{i}\\right)}-\\left(1-y_{i}\\right) \\frac{1}{1-\\emptyset\\left(x_{i}\\right)}\\right] \\frac{\\partial \\emptyset\\left(x_{i}\\right)}{\\partial b}</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{N} \\sum_{i=1}^{N}\\left[y_{i} \\frac{1}{\\emptyset\\left(x_{i}\\right)}-\\left(1-y_{i}\\right) \\frac{1}{1-\\emptyset\\left(x_{i}\\right)}\\right] \\wp\\left(x_{i}\\right)\\left(1-\\emptyset\\left(x_{i}\\right)\\right)</script><script type=\"math/tex; mode=display\">\n=-\\frac{1}{N} \\Sigma_{i=1}^{N}\\left(y_{i}-\\emptyset\\left(x_{i}\\right)\\right)</script><p>带入公式后，得到最终推导的结果：</p>\n<script type=\"math/tex; mode=display\">\n\\mathrm{w} :=\\mathrm{w}+\\alpha \\frac{1}{N} \\sum_{i=1}^{N}\\left(y_{i}-\\emptyset\\left(x_{i}\\right)\\right) \\cdot x_{i}</script><script type=\"math/tex; mode=display\">\n\\mathrm{b} :=\\mathrm{b}+\\alpha \\frac{1}{N} \\sum_{i=1}^{N}\\left(y_{i}-\\emptyset\\left(x_{i}\\right)\\right)</script><font color=\"red\"> \n通过以上公式可以看出，逻辑回归的梯度与 `sigmoid` 本身无关，只与 `y` 和`x`和 `w` 有关系。</font>\n\n<h2 id=\"进一步提高泛化能力\"><a href=\"#进一步提高泛化能力\" class=\"headerlink\" title=\"进一步提高泛化能力\"></a>进一步提高泛化能力</h2><blockquote>\n<p>影响模型泛化能力的主因素是 <code>过拟合</code>, 过拟合问题比较容易理解，这里就不贴图了。下面分析一下产生过拟合的原因和解决办法。</p>\n</blockquote>\n<h3 id=\"过拟合产生的原因有哪些？\"><a href=\"#过拟合产生的原因有哪些？\" class=\"headerlink\" title=\"过拟合产生的原因有哪些？\"></a>过拟合产生的原因有哪些？</h3><p><strong>过多的特征</strong></p>\n<h3 id=\"怎么解决过拟合？\"><a href=\"#怎么解决过拟合？\" class=\"headerlink\" title=\"怎么解决过拟合？\"></a>怎么解决过拟合？</h3><ol>\n<li><p>减少特征数量</p>\n<p> 减少特征数量会导致部分信息丢失。</p>\n</li>\n<li><p>正则化</p>\n<p> 保留所有的特征，并且减小参数的大小。</p>\n</li>\n</ol>\n<h3 id=\"正则化方法\"><a href=\"#正则化方法\" class=\"headerlink\" title=\"正则化方法\"></a>正则化方法</h3><p><strong>在代价函数上增加一个惩罚项</strong>，<font color=\"red\">惩罚项应该是模型复杂度的单调递增函数，模型越复杂，惩罚项越大。 </font></p>\n<p>回归问题中，取<strong>平方损失</strong>（L2 范数），或者L1范数</p>\n<script type=\"math/tex; mode=display\">\nJ(\\theta)=\\frac{1}{2 m} \\sum_{i=1}^{n}\\left(\\mathrm{h}_{\\theta}\\left(\\mathrm{x}_{i}\\right)-y_{i}\\right)^{2}+\\lambda \\sum_{j=1}^{n} \\theta_{j}^{2}</script><p>这里的lambda 系数：</p>\n<p> 如果它的值很大，说明对模型的复杂度惩罚大，对拟合数据的损失惩罚小，这样它就不会过分拟合数据，在训练数据上的偏差较大，在未知数据上的方差较小，但是可能出现欠拟合的现象；</p>\n<p> 如果它的值很小，说明比较注重对训练数据的拟合，在训练数据上的偏差会小，但是可能会导致过拟合。</p>\n<p>加入正则化后的参数更新：</p>\n<script type=\"math/tex; mode=display\">\n\\theta_{j} :=\\theta_{j}-\\frac{\\alpha}{m} \\sum_{i=1}^{m}\\left(h_{\\theta}\\left(x_{i}\\right)-y_{i}\\right) x_{i}^{j}-\\frac{\\lambda}{m} \\theta_{j}</script><h2 id=\"python-实现\"><a href=\"#python-实现\" class=\"headerlink\" title=\"python 实现\"></a>python 实现</h2><p>空</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><p><a href=\"https://irwenqiang.iteye.com/blog/1552680&quot;该部分参考这里&quot;\" target=\"_blank\" rel=\"noopener\">极大似然估计</a></p>\n"},{"title":"C++梳理笔记","date":"2019-01-20T12:30:39.000Z","copyright":null,"password":123456,"top":null,"_content":"\n<font color=\"red\"><big>测试内容</big></font>\n\n\n~~删除线~~\n\n[链接](http://zhuzhuyule.xyz)\n\n![logo](图片测试！/test.jpg)\n\n# C++学习笔记\n\n## **类型转换：**\n\n1. 隐式转换： 低类型转换为高类型\n\n       浮点数（直接舍掉小数，不四舍五入） + 整数\n\n2. 显式转换：\n\n    \tint **(**z**) = (**int**)** z **= static_cast\\<**int**\\> (**z**)**\n\n。。。\n\n### **数据的输入和输出：信息的流动**\n\n 1. 输入：\n\n 2. 输出：\n\n 3. 流类库的操纵符：\n\n### **程序控制：**\n\n\t\tif, while, for, do-while , break, continue, { switch,case,default } ;\n1. do-while:\n\n\t    do 语句      // 先执行一次\n\t    while(表达式)；\n\n2. for的范围，遍历容器：\n\n\n### **自定义类型：**\n\n* 类型别名： \n\n\n  1. typedef double Area, V;\n\n  2. using Area = double\n\n\n\n\n* 枚举类型： 有限的个数\n\n　　　　不限定作用域： enum 类型名 { 变量值列表}\n\n　　　　限定作用域：\n\n　　　注：枚举元素是常量，不能赋值\n\n　　　　　枚举元素有默认值，默认0,1,2,3,4，声明时可以另外指定\n\n　　　　　可以进行关系运算\n\n* auto类型 和decltyoe类型\n\t\t\n\t\t    decltype( float( i )) j = 2;   // j值是2，类型是float;\n\t\t\n\t\t    auto m = 2.5;  // m 为float;\n\n* 结构体( C语言中的)： struct\n\n\t\t\tstruct MyTimeStruct{   //定义 结构体类型\n\t\t\t    unsigned int year,mouth,day,hour,min,sec;\n\t\t\t};\n\n\n\n## **函数： 可重用的功能模块（定义和调用）**\n\n### **函数定义：**\n\n　　形参不占用空间，调用时分配；\n\n### **函数调用：**\n\n　　调用前要函数声明： int sum**(** int a**,** int b**);**\n\n　　1. 函数的嵌套调用：\n\n　　2. 函数的递归调用： 直接或者间接调用自身\n\n计算n!\n\n\t\tunsigned int fac( unsigned int n){\n\t\t    if (n == 0) return 1;\n\t\t    return fac( n - 1) * n;\n\t\t}\n\n汉诺塔\n\n\t\t分析：\n\t\t1.\tA 上的n-1个盘子移动到B上（借助C）;\n\t\t2.\tA上剩下的盘子移动到C上；\n\t\t3.\tB上的n-1个盘子移动到C上（借助A）\n\t\tvoid move(char src, char obj)\n\t\t{\n\t\t    cout << src << \"--->>>\" << obj << endl;\n\t\t}\n\t\t\n\t\tvoid hanoi(int n, char src, char medium, char obj)\n\t\t{\n\t\t    if(n == 1)\n\t\t        move(src, obj);\n\t\t    else{\n\t\t        hanoi(n-1, src, obj, medium);\n\t\t        move(src, obj);\n\t\t        hanoi(n-1, medium, src, obj);\n\t\t    }\n\t\t}\n\n\n### **函数的参数：**\n\n1. 形参不占用空间，调用时分配；\n\n2. 计算结果返回多个（利用引用）\n\n3. 多个参数时，从后开始传\n\n### **引用类型（&）：** 必须初始化，该类型不可改变，是其他变量的别名\n\t\n\t\tint i, j;\n\t\tint & ri = i;  // 定义int引用类型变量 ri, 初始化为i的引用\n\n\n### **含有可变参数的函数：（两种方法）**\n\n1. 所有实参类型相同：`initializer_list<int> li; //类模板, 都是常量`\n\n2. 具体看第九章\n\n3. 类型不同：\n\n### **内联函数（inline）： **用函数体内的语句，替换函数调用表达式，编译时完成，类似 #define\n\n声明： `inline int calArea(int a){  }`\n\n要求： 1. 不能有循环，switch语句 2. 定义在调用之前 3. 不能有异常接口声明\n\n###  constexpr 函数：（常量表达式函数）\n\n\n### **带默认参数的函数：**\n\n\t\tint getVa(int length, int weight = 2)\n\n### **函数的重载：**（C++多态性的重要机制，编译过程中实现）\n\n函数体同名，参数类型不同/参数个数不同\n\n\t\tint add(int x, int y);\n\n\t\tfloat add(float x, float y);\n\n\t\tfloat add(float x, float y, float z);\n\n\n### **C++系统函数：**\n\n\t\t#include <cmath>\n\t\t\t|_\n\t\t\t|_\n\t\t#include <cstdlib>\n\t\t\t|_\n\t\t\t|_\n\t\t#include <cstdio>\n\t\t\t|_\n\t\t\t|_\n\t\t#include <ctime>\n\t\t\t|_\n\t\t\t|_\n\n\n\n## **类和对象**\n\n类：构建对象的蓝图，\n\n对象：由类创建，含有数据和方法\n\n封装：对数据和操作数据的方法的组合绑定\n\n继承：在已有类基础上，形成新的类\n\n多态：\n\n构造函数：定义对象时，通过构造函数初始化\n\n析构函数：删除对象时，通过析构函数释放资源\n\n### ** 类和对象的定义：**\n\n定义类：\n\n\t\tclass {  //类名称 \n\t\t    public:\n\t\t        // 公有成员,外部接口\n\t\t    private:\n\t\t        // 私有成员\n\t\t    protected:\n\t\t        int hour = 0; // 类内初始化\n\t\t        // 保护型成员\n\t\t}\n\n\n注意：不指定类型，默认为私有；\n\n### **成员函数：**\n\t\t\n\t\t|_ 内联成员函数： 类内声明或者inline关键字\n\n\t\t|_类外实现：void 类名称::成员函数名称（）{ }\n\n### **构造函数：**\n\n-  在创建对象时，自动调用来初始化数据\n\n-  与类名相同\n\n-  构造函数有初始化列表\n\n-  格式 类名（string s, lei i）：s(初始值)，i(初始值){ }；\n\n### **委托构造函数：**一个构造函数 通过另一个构造函数 初始化\n\n### **复制构造函数：**\n\n用途：\n\n-   用存在的对象 去初始化新对象 （通过引用旧的对象）\n\n-   函数f的形参是类的对象，调用f时，将用实参对象初始化形参对象\n\n-   函数g的返回值是类的对象，用return的对象来在主调函数中初始化一个无名对象\n\n### **析构函数：**生存期结束，删除清理工作，不能有return，不能有参数\n\n\t    class 类名{\n\n\t    public:\n\t        类名（形参）； // 构造函数\n\t        类名（const 类名& 旧对象名）；  // 复制构造函数 =delete是不生成\n\t\t\t~ 类名（）；\n\t    }\n\n\n>   注：未声明时，编译器自己生成一个默认的\n\n### **前向引用声明：**两个类相互引用时，某个类在引用之前就声明\n\n\t    class A;  //前向引用声明，只是一个标识符，不是万能的\n\t    class B{\n\t    public:\n\t        void A(B b);\n\t    }\n\n\t    class A{\n\t    public：\n\t        void B（A a）;\n\t    }\n\n\n### **结构体：**特殊的类，默认是公有的，可以有函数成员\n\n\t    //公有成员\n\t        int a;\n\t    protected:\n\t        int b;\n\t    private:\n\t        int c;\n\t    };\n\n\n### **联合体：**\n\n目的：存储空间的共用，成员不能同时有效，比如某人语文课成绩，只有一种可能；\n\t\t\n\t\tunion Mark{ // 成绩的联合体， 只有一个成立\n\t\t    char grade;  //等级类的成绩\n\t\t    bool pass;  // 是否通过的成绩\n\t\tint percent;  //百分制成绩  }\n\n### **枚举类：**\n\nenum class 枚举类型名： 底层类型（int）**{** 枚举列表 **};**\n\n    //默认 int\n\n优势：\n\n-   强制作用域 --必须在枚举类 枚举类型名：：枚举值，不同枚举类可以有同名值了\n\n-   转换限制 --枚举对象不能与整型 隐式转换\n\n-   底层类型 --可以指定\n\n\n## **数据共享和保护：**\n\n### **作用域分类：**\n\n函数原型作用域：\n\n- 形参的范围在（）内，所以不需要名字也行，int area( int );\n\n局部作用域\n\n- 函数{ }内\n\n- if、for、while { }内\n\n类作用域： 类外访问类的成员\n\n- 静态成员：通过 对象名.成员名 访问\n\n- 非静态成员：\n\n- 文件作用域\n\n- 命名空间作用域： 10章\n\n### **对象的生存期：**\n\n静态生存期： 整个程序结束后消失\n\n- 函数内的静态对象， 用static ，全局寿命，只局部可见\n\n动态生存期：\n\n- 离开作用域后消失\n\n- 下次进函数重新生成对象\n\n### **类的静态数据成员：**\n\n- static 声明\n\n- 为该类所有对象共享，具有静态生存期\n\n- 必须在类外定义和初始化，类内声明，用：：指明所属于的类\n\n比如记录 类产生了多少对象；opencv中的Mat对象好像用到了？？？？\n\n\t\tclass base{   \n\t\t    public :   \n\t\t           static   int   _num;//声明   \n\t\t};   \n\t\tint  base::_num=0;  //真正定义  \n\n\n### **类的友元：**\n\n- 破坏数据封装和数据隐藏的机制\n\n- 尽量不用\n\n### ** 友元函数：**\n\n- 类声明中由关键字 friend 修饰说明的非成员函数\n\n- 可以在其函数体内访问对象的private,protected成员\n\n- 但必须通过对象名：：访问，函数参数为类的引用\n-   \n### ** 友元类：**\n\n\t\tclass A{\n\t\t    friend B;\n\t\t  public:\n\t\t    void display(){\n\t\t        count << x << enld;\n\t\t    }\n\t\t  private:\n\t\t    int x;\n\t\t}\n\t\t\n\t\tclass B{\n\t\t  public:\n\t\t    void set(int i);\n\t\t    void display();\n\t\t  private:\n\t\t    A a;\n\t\t}\n\t\t\n\t\tvoid B::set(int i){\n\t\t    a.x = i;   // B类中改变 A类私有值\n\t\t}\n\t\tvoid B::display(){\n\t\t    a.display()\n\t\t}\n\n\n### **共享数据的保护：**\n\n#**常类型：**const\n\n常对象：必须初始化，不可更新\n\n\t\tclass A{\n\t\t}\n\t\tA const a; // a是常对象\n\n\n常成员：(不可以放在构造函数体内复制，可以在初始化列表中)\n\n\t\tA：：A(int i):a(i){ }\n\n- 常数据成员：const修饰的\n\n- 静态常数据成员： static const int b;\n\n- 常函数成员（用来处理常对象的函数）\n\n    - 不更新对象的数据成员\n\n    - 声明和实现都带const\n\n\n\t\t\tclass A{\n\t\t\t    void f（int a）const;\n\t\t\t}\n\t\t\tvoid A::f(int a) const{  \n\t\t\t}; // f是常对象函数, 处理常对象\n\n\n- 常引用：不可更新\n\n　　　引用是双向传递的，避免修改原值的方法就是常引用；\n\n         const A& a;\n\n- 常数组：\n\n- 常指针：\n\n### **多文件结构和预编译命令：**\n\n- .h 系统使用\n\n- .hpp 个人使用(类的声明,函数的声明)\n\n- .cpp (类的实现，函数的实现)\n\n   ![](media/f5d645ed218d5fa3e753f771b72310fc.png)\n\n### **外部变量：**\n\n文件作用域中定义的变量默认是外部变量，其他文件使用前，extern声明\n\n将变量和函数限制在编译单元内：namespcae:\n\n\t\tnamespace{ //匿名的命名空间，外部不可调用任何东西\n\t\t    int i;\n\t\t    void fun(){\n\t\t        i++;\n\t\t    }\n\t\t}\n\n\n### **预编译命令：**\n\n\t\t#include< >  标准方式搜索，从系统目录include\n\n\n\t\t#include”” 先当前目录搜索，没有再标准搜索\n\n\n\t\t#define \n\n\n\t\t#undef 删除有#define的宏\n\n\t\t#if 表达式  // 条件编译指令\n\t\t---\n\t\t#else\n\t\t---\n\t\t#endif \n\n\n\t\t#ifndef 标识符\n\t\t---\n\t\t#else  \n\t\t---\n\t\t#endif\n\n\n\n## **数组，指针与字符串：**\n\n### **数组：**\n\n定义： `int arr**[**m**][**n**]**…;`\n\n　　注：二维数组中 arr[1] 第二行首地址\n\n### **数组作为函数参数：**\n\n　　数组名做参数： 形参，实参都是数组名，传入的是地址\n\n### **对象数组：**\n\n　　定义：类名 数组名[对象元素个数]\n\n　　访问：数组名[下标].成员名\n\n### **基于范围的for循环：**c++11,自动遍历整个容器\n\n\t  for( auto x : 容器){ } for( auto &x : 容器){ }\n\n注意：\n\n- auto &x是元素引用，auto x是元素的副本\n\n- auto推导出的类型是容器中的值类型\n\n- ：冒号后的表达式只执行一次\n\n### **指针：**\n\n### **定义：**\n\n\t\tstatic int i;\n\t\t\n\t\tstatic int * p = &I;\n\n### **指针的初始化和赋值：**\n\n### **指针的算术运算，关系运算：**\n\n### **指针数组：**\n\n        类名  *p[2];\n\n### **指向数组的指针：**\n\n        int **p; 指向二维数组的指针\n\n### **指针与函数：**\n\n- 指针做参数：大批量数据提高效率\n\n- 指针类型的函数：返回类型是指针\n\n\t\tint * function(int i){return 全局或者静态的 }；// 不能返回非静态局部变量\n\n-  指向函数的指针：实现函数回调的功能\n\n>   定义： 数据类型 (\\*f)(参数表);\n\n>   数据类型：返回值\n\n-   对象指针：\n\n>   定义： 类名 \\*对象指针名 = & 对象；\n\n>   访问对象： 对象指针名-\\>成员名\n\n（\\*对象指针名）.成员名\n\n- this 指针：成员函数的一个隐士参数，初始化为对象的地址，不可改变\n\n- 隐含于类的每个非静态成员函数中\n\n- 指出成员函数所操作的当前的对象\n\n- \\*this 是当前对象地址\n\n### **动态内存分配：**\n\nnew** 类型名 **(**初始化列表**) // 返回首字节地址\n\ndelete 指针p //p一直在，删除的只是p指向的对象申请的空间\n\n动态数组：\nnew 类型名[数组长度]\n\ndelete[] 数组首地址p指针\n\n### **智能指针：**C++11\n\n### **内存管理**\n\n-   unique_ptr:\n\n    -   不允许多个指针共享资源，标准库中move可以转移指针，但原来指针会失效\n\n-   shared_ptr:\n\n    -   多指针共享\n\n-   weak_ptr:\n\n    -   可复制共享\n\n>   Vector对象：类模板\n\n优势：\n\n-   封装任何形式的动态数组，自动创建，删除\n\n-   下标越界检查\n\n定义： vector <元素类型> object（长度）\n\n- `object.begin()  object.end()  object.size()`\n\n- auto 遍历vector `for(auto e: object);`\n\n### **对象的复制和移动：**\n\n-   浅层复制和深层复制：复制对象用到复制构造函数，默认的复制构造只传递了指针，两个变量指向同一块内存，释放其中一个，再释放第二个会出错；\n\n    -   浅层：实现对象间数据一一对应的复制，但两个对象指向同一内存\n\n    -   深层：当对象成员是指针类型，应该对指针所指对象进行复制。\n\n>   类名**::**类名**(**const 类名**&** v**){**\n\n>   size **=** v**.**size**;**\n\n>   data_ptr **= new** Ponit**[**size**];**\n\n>   **for(**int i**=**0**;** i **\\<** size**; ++**i**){**\n\n>   data_ptr**[**i**] =** v**.**data_ptr**[**i**];**\n\n>   **}**\n\n>   **}**\n\n-   移动构造：C++11,省去了构造和删除临时对象的过程\n\n    ![](media/8c3092d99bcdba78edeb2d8123270ffe.png)\n\n>   class_name**(**class_name **&&**old**)::**xptr**(**old**.**xptr**){**\n\n>   n**.**xptr **= NULL;** // 原来的指针清空\n\n>   **}**\n\n### **C风格字符串：**字符数组\n\n### **string类：**\n\n常用构造函数：\n\n-   string(); //默认构造，长度为0\n\n    -   string s1**;**\n\n-   string(const char \\*s) //指针s所指向的字符串常量初始化该对象\n\t\n\t\tstring s2 = “abc”;\n\t\t\n\t\tstring(const string &rhs) //复制构造函数\n\t\t\n\t\tstring s3 = s2;\n\n访问：下标访问\n\n整行字符串的输入： cin 被空格隔开\n\ngetline(cin,s2); //包含\\#include\\<string\\>\n\ngetline(cin,s2,’,’);\n\n\n## **继承和派生：** 充分利用原有的\n\n继承：保持已有类的特征来构造新类\n\n派生：在已有类基础上新增自己的特性\n\n基类：父类\n\n派生类：子类\n\n直接基类和间接基类\n\n单继承：\n\n\tclass 派生类名：继承方式 基类名{  //继承方式，\n\t    成员声明；//新增成员的声明\n\t}\n\n\n多继承：\n\n\tclass 派生类名：继承方式1 基类1，继承方式2 基类2{\n    \t成员声明；\n\t}\n\n\n### **继承的方式：**\n\n控制：派生类对基类成员的访问权限\n\n-   公有继承 public\n\n>   基类中的pubilc和protected访问属性在派生类中不变\n\n>   基类的pravate不可被对象直接访问\n\n-   私有继承 ：内部可以访问基类的公有和保护成员，但是其对象不再可以访问\n\n-   保护继承 ：基类的公有和保护，到这都成了保护成员，类内可以访问，但对象不能\n\n派生类的构成：\n\n-   吸收基类成员\n\n-   改造基类成员\n\n    -   增加同名成员，基类成员被覆盖（重新定义继承的成员函数必须用虚函数）\n\n-   添加新成员\n\n### **类型转换：**\n\n基类和派生类之间：\n  \n派生类的对象可以隐含转换为基类对象；\n\n派生类的对象可以初始化基类的引用；\n\n派生类的指针可以隐含转换为基类的指针；\n\n### **派生类的构造函数：**\n\n默认情况下，基类的构造函数不被继承，派生类需要自己构造\n\nc++11，using语句继承基类构造函数\n\n### **派生类的复制构造函数：**\n\n### **派生类的析构函数：**\n\n### **虚基类：**\n\n## **多态性**\n\n### **运算符重载：**\n\n\t//双目运算符\n\t函数类型 operator 运算符（参数）  \n\t{\n\t    // 参数个数 = 原操作数个数 - 1\n\t}\n\t//前置单目运算符，返回引用所以可以当左值\n\t函数类型 & operator ++（无参数）  \n\t{\n\t    return * this;\n\t}\n\t//后置单目运算符，\n\t函数类型 operator ++（参数为int类型）  \n\t{\n\t    old = *this;\n\t    ++(*this);  //调用的前置\n\t    return old;\n\t}\n\n\n-   重载为非成员函数：\n\n1.  列出所有操作数\n\n2.  至少有一个自定义类型参数\n\n3.  后置单目运算，参数要增加int,但不用写形参名\n\n4.  要操作某类对象的私有成员，则可声明为该类的友元函数\n\n### **虚函数：**virtual改造基类成员，实现动态绑定；必须是非静态成员\n\n>   原理：编译时先不确定和哪个类的成员对应，在程序运行时刻，再对应；\n\n\t#include <iostream>\n\tusing namespace std;\n\tclass Base1{\n\tpublic:\n\t    virtual void display() const; //虚函数，不要用内联\n\t};\n\n\tvoid Base1::display() const{\n\t    cout << \"Base1 \" << endl;\n\t}\n\t\n\tclass Base2:public Base1{\n\tpublic:\n\t    virtual void display() const;\n\t}\n\tvoid Base2::display() const{\n\t    cout << \"Base2\" << endl;\n\t}\n\n\n### **虚析构函数：**打算通过基类指针调用某一个对象的析构函数（执行delete）\n\n### **虚表和动态绑定：**\n\n>   虚表：\n\n-   每个多态类都有虚表；\n\n-   存放各个数函数的入口地址；\n\n-   每个对象有指向当前类的虚表的指针（虚指针vptr）；\n\n>   动态绑定：\n\n-   构造函数为对象的虚指针赋值\n\n### **抽象类：**含有纯虚函数的类,不能直接定义对象\n\n>   纯虚函数：\n\n>   基类中声明的虚函数，在基类中没有定义具体的操作，要求在派生类中根据实际需求完\n\n>   成自己的版本：\n\n\tvirtual 函数类型 函数名**(**参数名**) =** 0**;**\n\n### **override 和 final :**C++11\n\noverride声明的函数，必须在基类中找到原型；\n\nfinal 不允许继承或者覆盖；\n\n\n## **模板**\n\n### **函数魔板：**整数和浮点数求绝对值，需要多次重载函数，但是用函数模板，只需要设计通用功能；\n\ntemplate\\<模板参数表\\> // 类型：class或者typename 常量：\n\n函数定义\n\n\ttemplate<typename T>\n\tT abs(T x){\n\t    return x<0?-x:x;\n\t}\n\n\n### **类模板：**\n\n\ttemplate<模板参数表>\n\tclass 类名{\n\t    类成员声明;\n\t}\n\n\t//类成员定义\n\ttemplate <模板参数表>\n\t类型名  类名<模板参数标识符列表> :: 函数名(参数表)\n\t{\n\n\t}\n\n\n### **线性群体：**按位置顺序有序排列\n\n直接访问：\n\n数组类模板：\n\n索引访问：\n\n顺序访问：\n\n链表类和结点类模板：\n\n单链表：每个结点包括数据和指针，只有一个指向后续结点的称为单链表；\n\n![](media/9167a427f849e864c5d630d0c0bc3163.png)\n\n单链表结点类模板：\n\n\ttemplate <class T>\n\tclass Node{\n\t\tprivate:\n\t    \tNode<T> *next;\n\t\tpublic:\n\t    \tT data; \n\t    \tNode(const T&item,Node<T>* next = 0);  //构造函数\n\t    void insertAfter(Node<T> *p); //插入\n\t    Node<T> *deleteAfter();  //删除\n\t    Node<T> *nextNode() const; \n\t}\n\t\n\ttemplate <class T>\n\tvoid Node<T>::insertAfter(Node<T> *p){  // *p是要插入的结点\n\t// p节点的指针指向当前节点的后续结点\n\t    p->next = next; // next是原链表待插入位置的结点的指针\n\t    next = p;  \n\t}\n\ttemplate <class T>\n\tNode<T> *deleteAfter(){\n\t    Node<T> * tempPtr = next;\n\t    if (next == NULL)  //判断是否是删除最后的元素\n\t        return 0;\n\t    next = tempPtr = next;\n\t    return tempPtr;\n\t}\n\n\n>   插入：\n\n![](media/85d072d9c8a8366378b00b9af8ca4920.png)\n\n>   头插法：可以当队列\n\n>   尾插法：栈\n\n>   删除：\n\n![](media/ffdd5c0226d2a3f9a7833379eb0ebf90.png)\n\n待查询：\n\nexplicit关键字\n\n构造函数 explicit可以抑制内置类型隐式转换\n\n\n## **泛型设计**\n\n基本概念：\n\n编写不依赖具体数据类型的程序，通用的；\n\nSTL简介：(Standard Template Library)\n\nC++ string类库入门：\n\n    #include <iostream>\n\n    #include <string>\n\n    using namespace std;\n\n    int main()\n    {\n\n        // 构造函数：\n\t    string str1 = \"Yesterday\";\n\t\n\t    string str2(\"Today\");\n\t\n\t    string str3(\"Hello\",2); //取c风格字符串 长度为 2 作为初值，即\"He\"\n\t\n\t    string str4(str1, 6); // 始于位置6开始的字符串，即\"day\"\n\t\n\t    string str5(str1,6,1); // 始于6，长度1，即\"d\"\n\t\n\t\tstring str6(1,'a'); //6个'a'\n\t\t\n\t\t// 赋值，交换\n\t\tstr1.assign(\"hahahaha\"); //重新赋值\n\t\t\n\t\tswap(str1,str2); //交换两个字符串内容 str1=\"Today\" str2=\"hahahaha\"\n\t\t\n\t\t// 追加\n\t\tstr1 += \" we\"; // += 可追加 string对象，字符串，字符\n\t\t\n\t\tstr1.append(\" ar\"); // append 可追加 string对象，字符串\n\t\t\n\t\tstr1.push_back('e'); //push_back 只能追加字符 str1 = \"Today we are\"\n\n\t\t// 插入\n\t\tstr1.insert(0,\" family\"); //str1 = \"Today we are family\"\n\t\t\n\t\t// 删除\n\t\tstr1.erase(2,1); //第2个位置开始， len = 1 个字符\n\n\t\tstr1.clear(); //删除全部\n\t\t\n\t\t// 访问字符串\n\t\tstring s = \"asdfgh\";\n\t\t\n\t\tcout << s[1]; // 's'\n\t\t\n\t\tcout << s.at(2); // 'd'\n\t\t\n\t\t// 查找\n\t\tint position = s.find('f',0); // 从0开始查找第一次出现‘f’的坐标\n\t\t\n\t\t// 替换\n\t\ts.replace(s.find('f'),3,\"ZZZ\"); //替换find的位置处\n\t\t3个字符串为 “ZZZ”\n\t\t\n\t\t// 分割\n\t\tgetchar();\n\t\t\n\t\treturn 0;\n\n\t}\n","source":"_posts/C-梳理笔记.md","raw":"---\ntitle: C++梳理笔记\ndate: 2019-01-20 20:30:39\ncategories: C++\ntags: C++\ncopyright: \npassword: 123456\ntop:\n---\n\n<font color=\"red\"><big>测试内容</big></font>\n\n\n~~删除线~~\n\n[链接](http://zhuzhuyule.xyz)\n\n![logo](图片测试！/test.jpg)\n\n# C++学习笔记\n\n## **类型转换：**\n\n1. 隐式转换： 低类型转换为高类型\n\n       浮点数（直接舍掉小数，不四舍五入） + 整数\n\n2. 显式转换：\n\n    \tint **(**z**) = (**int**)** z **= static_cast\\<**int**\\> (**z**)**\n\n。。。\n\n### **数据的输入和输出：信息的流动**\n\n 1. 输入：\n\n 2. 输出：\n\n 3. 流类库的操纵符：\n\n### **程序控制：**\n\n\t\tif, while, for, do-while , break, continue, { switch,case,default } ;\n1. do-while:\n\n\t    do 语句      // 先执行一次\n\t    while(表达式)；\n\n2. for的范围，遍历容器：\n\n\n### **自定义类型：**\n\n* 类型别名： \n\n\n  1. typedef double Area, V;\n\n  2. using Area = double\n\n\n\n\n* 枚举类型： 有限的个数\n\n　　　　不限定作用域： enum 类型名 { 变量值列表}\n\n　　　　限定作用域：\n\n　　　注：枚举元素是常量，不能赋值\n\n　　　　　枚举元素有默认值，默认0,1,2,3,4，声明时可以另外指定\n\n　　　　　可以进行关系运算\n\n* auto类型 和decltyoe类型\n\t\t\n\t\t    decltype( float( i )) j = 2;   // j值是2，类型是float;\n\t\t\n\t\t    auto m = 2.5;  // m 为float;\n\n* 结构体( C语言中的)： struct\n\n\t\t\tstruct MyTimeStruct{   //定义 结构体类型\n\t\t\t    unsigned int year,mouth,day,hour,min,sec;\n\t\t\t};\n\n\n\n## **函数： 可重用的功能模块（定义和调用）**\n\n### **函数定义：**\n\n　　形参不占用空间，调用时分配；\n\n### **函数调用：**\n\n　　调用前要函数声明： int sum**(** int a**,** int b**);**\n\n　　1. 函数的嵌套调用：\n\n　　2. 函数的递归调用： 直接或者间接调用自身\n\n计算n!\n\n\t\tunsigned int fac( unsigned int n){\n\t\t    if (n == 0) return 1;\n\t\t    return fac( n - 1) * n;\n\t\t}\n\n汉诺塔\n\n\t\t分析：\n\t\t1.\tA 上的n-1个盘子移动到B上（借助C）;\n\t\t2.\tA上剩下的盘子移动到C上；\n\t\t3.\tB上的n-1个盘子移动到C上（借助A）\n\t\tvoid move(char src, char obj)\n\t\t{\n\t\t    cout << src << \"--->>>\" << obj << endl;\n\t\t}\n\t\t\n\t\tvoid hanoi(int n, char src, char medium, char obj)\n\t\t{\n\t\t    if(n == 1)\n\t\t        move(src, obj);\n\t\t    else{\n\t\t        hanoi(n-1, src, obj, medium);\n\t\t        move(src, obj);\n\t\t        hanoi(n-1, medium, src, obj);\n\t\t    }\n\t\t}\n\n\n### **函数的参数：**\n\n1. 形参不占用空间，调用时分配；\n\n2. 计算结果返回多个（利用引用）\n\n3. 多个参数时，从后开始传\n\n### **引用类型（&）：** 必须初始化，该类型不可改变，是其他变量的别名\n\t\n\t\tint i, j;\n\t\tint & ri = i;  // 定义int引用类型变量 ri, 初始化为i的引用\n\n\n### **含有可变参数的函数：（两种方法）**\n\n1. 所有实参类型相同：`initializer_list<int> li; //类模板, 都是常量`\n\n2. 具体看第九章\n\n3. 类型不同：\n\n### **内联函数（inline）： **用函数体内的语句，替换函数调用表达式，编译时完成，类似 #define\n\n声明： `inline int calArea(int a){  }`\n\n要求： 1. 不能有循环，switch语句 2. 定义在调用之前 3. 不能有异常接口声明\n\n###  constexpr 函数：（常量表达式函数）\n\n\n### **带默认参数的函数：**\n\n\t\tint getVa(int length, int weight = 2)\n\n### **函数的重载：**（C++多态性的重要机制，编译过程中实现）\n\n函数体同名，参数类型不同/参数个数不同\n\n\t\tint add(int x, int y);\n\n\t\tfloat add(float x, float y);\n\n\t\tfloat add(float x, float y, float z);\n\n\n### **C++系统函数：**\n\n\t\t#include <cmath>\n\t\t\t|_\n\t\t\t|_\n\t\t#include <cstdlib>\n\t\t\t|_\n\t\t\t|_\n\t\t#include <cstdio>\n\t\t\t|_\n\t\t\t|_\n\t\t#include <ctime>\n\t\t\t|_\n\t\t\t|_\n\n\n\n## **类和对象**\n\n类：构建对象的蓝图，\n\n对象：由类创建，含有数据和方法\n\n封装：对数据和操作数据的方法的组合绑定\n\n继承：在已有类基础上，形成新的类\n\n多态：\n\n构造函数：定义对象时，通过构造函数初始化\n\n析构函数：删除对象时，通过析构函数释放资源\n\n### ** 类和对象的定义：**\n\n定义类：\n\n\t\tclass {  //类名称 \n\t\t    public:\n\t\t        // 公有成员,外部接口\n\t\t    private:\n\t\t        // 私有成员\n\t\t    protected:\n\t\t        int hour = 0; // 类内初始化\n\t\t        // 保护型成员\n\t\t}\n\n\n注意：不指定类型，默认为私有；\n\n### **成员函数：**\n\t\t\n\t\t|_ 内联成员函数： 类内声明或者inline关键字\n\n\t\t|_类外实现：void 类名称::成员函数名称（）{ }\n\n### **构造函数：**\n\n-  在创建对象时，自动调用来初始化数据\n\n-  与类名相同\n\n-  构造函数有初始化列表\n\n-  格式 类名（string s, lei i）：s(初始值)，i(初始值){ }；\n\n### **委托构造函数：**一个构造函数 通过另一个构造函数 初始化\n\n### **复制构造函数：**\n\n用途：\n\n-   用存在的对象 去初始化新对象 （通过引用旧的对象）\n\n-   函数f的形参是类的对象，调用f时，将用实参对象初始化形参对象\n\n-   函数g的返回值是类的对象，用return的对象来在主调函数中初始化一个无名对象\n\n### **析构函数：**生存期结束，删除清理工作，不能有return，不能有参数\n\n\t    class 类名{\n\n\t    public:\n\t        类名（形参）； // 构造函数\n\t        类名（const 类名& 旧对象名）；  // 复制构造函数 =delete是不生成\n\t\t\t~ 类名（）；\n\t    }\n\n\n>   注：未声明时，编译器自己生成一个默认的\n\n### **前向引用声明：**两个类相互引用时，某个类在引用之前就声明\n\n\t    class A;  //前向引用声明，只是一个标识符，不是万能的\n\t    class B{\n\t    public:\n\t        void A(B b);\n\t    }\n\n\t    class A{\n\t    public：\n\t        void B（A a）;\n\t    }\n\n\n### **结构体：**特殊的类，默认是公有的，可以有函数成员\n\n\t    //公有成员\n\t        int a;\n\t    protected:\n\t        int b;\n\t    private:\n\t        int c;\n\t    };\n\n\n### **联合体：**\n\n目的：存储空间的共用，成员不能同时有效，比如某人语文课成绩，只有一种可能；\n\t\t\n\t\tunion Mark{ // 成绩的联合体， 只有一个成立\n\t\t    char grade;  //等级类的成绩\n\t\t    bool pass;  // 是否通过的成绩\n\t\tint percent;  //百分制成绩  }\n\n### **枚举类：**\n\nenum class 枚举类型名： 底层类型（int）**{** 枚举列表 **};**\n\n    //默认 int\n\n优势：\n\n-   强制作用域 --必须在枚举类 枚举类型名：：枚举值，不同枚举类可以有同名值了\n\n-   转换限制 --枚举对象不能与整型 隐式转换\n\n-   底层类型 --可以指定\n\n\n## **数据共享和保护：**\n\n### **作用域分类：**\n\n函数原型作用域：\n\n- 形参的范围在（）内，所以不需要名字也行，int area( int );\n\n局部作用域\n\n- 函数{ }内\n\n- if、for、while { }内\n\n类作用域： 类外访问类的成员\n\n- 静态成员：通过 对象名.成员名 访问\n\n- 非静态成员：\n\n- 文件作用域\n\n- 命名空间作用域： 10章\n\n### **对象的生存期：**\n\n静态生存期： 整个程序结束后消失\n\n- 函数内的静态对象， 用static ，全局寿命，只局部可见\n\n动态生存期：\n\n- 离开作用域后消失\n\n- 下次进函数重新生成对象\n\n### **类的静态数据成员：**\n\n- static 声明\n\n- 为该类所有对象共享，具有静态生存期\n\n- 必须在类外定义和初始化，类内声明，用：：指明所属于的类\n\n比如记录 类产生了多少对象；opencv中的Mat对象好像用到了？？？？\n\n\t\tclass base{   \n\t\t    public :   \n\t\t           static   int   _num;//声明   \n\t\t};   \n\t\tint  base::_num=0;  //真正定义  \n\n\n### **类的友元：**\n\n- 破坏数据封装和数据隐藏的机制\n\n- 尽量不用\n\n### ** 友元函数：**\n\n- 类声明中由关键字 friend 修饰说明的非成员函数\n\n- 可以在其函数体内访问对象的private,protected成员\n\n- 但必须通过对象名：：访问，函数参数为类的引用\n-   \n### ** 友元类：**\n\n\t\tclass A{\n\t\t    friend B;\n\t\t  public:\n\t\t    void display(){\n\t\t        count << x << enld;\n\t\t    }\n\t\t  private:\n\t\t    int x;\n\t\t}\n\t\t\n\t\tclass B{\n\t\t  public:\n\t\t    void set(int i);\n\t\t    void display();\n\t\t  private:\n\t\t    A a;\n\t\t}\n\t\t\n\t\tvoid B::set(int i){\n\t\t    a.x = i;   // B类中改变 A类私有值\n\t\t}\n\t\tvoid B::display(){\n\t\t    a.display()\n\t\t}\n\n\n### **共享数据的保护：**\n\n#**常类型：**const\n\n常对象：必须初始化，不可更新\n\n\t\tclass A{\n\t\t}\n\t\tA const a; // a是常对象\n\n\n常成员：(不可以放在构造函数体内复制，可以在初始化列表中)\n\n\t\tA：：A(int i):a(i){ }\n\n- 常数据成员：const修饰的\n\n- 静态常数据成员： static const int b;\n\n- 常函数成员（用来处理常对象的函数）\n\n    - 不更新对象的数据成员\n\n    - 声明和实现都带const\n\n\n\t\t\tclass A{\n\t\t\t    void f（int a）const;\n\t\t\t}\n\t\t\tvoid A::f(int a) const{  \n\t\t\t}; // f是常对象函数, 处理常对象\n\n\n- 常引用：不可更新\n\n　　　引用是双向传递的，避免修改原值的方法就是常引用；\n\n         const A& a;\n\n- 常数组：\n\n- 常指针：\n\n### **多文件结构和预编译命令：**\n\n- .h 系统使用\n\n- .hpp 个人使用(类的声明,函数的声明)\n\n- .cpp (类的实现，函数的实现)\n\n   ![](media/f5d645ed218d5fa3e753f771b72310fc.png)\n\n### **外部变量：**\n\n文件作用域中定义的变量默认是外部变量，其他文件使用前，extern声明\n\n将变量和函数限制在编译单元内：namespcae:\n\n\t\tnamespace{ //匿名的命名空间，外部不可调用任何东西\n\t\t    int i;\n\t\t    void fun(){\n\t\t        i++;\n\t\t    }\n\t\t}\n\n\n### **预编译命令：**\n\n\t\t#include< >  标准方式搜索，从系统目录include\n\n\n\t\t#include”” 先当前目录搜索，没有再标准搜索\n\n\n\t\t#define \n\n\n\t\t#undef 删除有#define的宏\n\n\t\t#if 表达式  // 条件编译指令\n\t\t---\n\t\t#else\n\t\t---\n\t\t#endif \n\n\n\t\t#ifndef 标识符\n\t\t---\n\t\t#else  \n\t\t---\n\t\t#endif\n\n\n\n## **数组，指针与字符串：**\n\n### **数组：**\n\n定义： `int arr**[**m**][**n**]**…;`\n\n　　注：二维数组中 arr[1] 第二行首地址\n\n### **数组作为函数参数：**\n\n　　数组名做参数： 形参，实参都是数组名，传入的是地址\n\n### **对象数组：**\n\n　　定义：类名 数组名[对象元素个数]\n\n　　访问：数组名[下标].成员名\n\n### **基于范围的for循环：**c++11,自动遍历整个容器\n\n\t  for( auto x : 容器){ } for( auto &x : 容器){ }\n\n注意：\n\n- auto &x是元素引用，auto x是元素的副本\n\n- auto推导出的类型是容器中的值类型\n\n- ：冒号后的表达式只执行一次\n\n### **指针：**\n\n### **定义：**\n\n\t\tstatic int i;\n\t\t\n\t\tstatic int * p = &I;\n\n### **指针的初始化和赋值：**\n\n### **指针的算术运算，关系运算：**\n\n### **指针数组：**\n\n        类名  *p[2];\n\n### **指向数组的指针：**\n\n        int **p; 指向二维数组的指针\n\n### **指针与函数：**\n\n- 指针做参数：大批量数据提高效率\n\n- 指针类型的函数：返回类型是指针\n\n\t\tint * function(int i){return 全局或者静态的 }；// 不能返回非静态局部变量\n\n-  指向函数的指针：实现函数回调的功能\n\n>   定义： 数据类型 (\\*f)(参数表);\n\n>   数据类型：返回值\n\n-   对象指针：\n\n>   定义： 类名 \\*对象指针名 = & 对象；\n\n>   访问对象： 对象指针名-\\>成员名\n\n（\\*对象指针名）.成员名\n\n- this 指针：成员函数的一个隐士参数，初始化为对象的地址，不可改变\n\n- 隐含于类的每个非静态成员函数中\n\n- 指出成员函数所操作的当前的对象\n\n- \\*this 是当前对象地址\n\n### **动态内存分配：**\n\nnew** 类型名 **(**初始化列表**) // 返回首字节地址\n\ndelete 指针p //p一直在，删除的只是p指向的对象申请的空间\n\n动态数组：\nnew 类型名[数组长度]\n\ndelete[] 数组首地址p指针\n\n### **智能指针：**C++11\n\n### **内存管理**\n\n-   unique_ptr:\n\n    -   不允许多个指针共享资源，标准库中move可以转移指针，但原来指针会失效\n\n-   shared_ptr:\n\n    -   多指针共享\n\n-   weak_ptr:\n\n    -   可复制共享\n\n>   Vector对象：类模板\n\n优势：\n\n-   封装任何形式的动态数组，自动创建，删除\n\n-   下标越界检查\n\n定义： vector <元素类型> object（长度）\n\n- `object.begin()  object.end()  object.size()`\n\n- auto 遍历vector `for(auto e: object);`\n\n### **对象的复制和移动：**\n\n-   浅层复制和深层复制：复制对象用到复制构造函数，默认的复制构造只传递了指针，两个变量指向同一块内存，释放其中一个，再释放第二个会出错；\n\n    -   浅层：实现对象间数据一一对应的复制，但两个对象指向同一内存\n\n    -   深层：当对象成员是指针类型，应该对指针所指对象进行复制。\n\n>   类名**::**类名**(**const 类名**&** v**){**\n\n>   size **=** v**.**size**;**\n\n>   data_ptr **= new** Ponit**[**size**];**\n\n>   **for(**int i**=**0**;** i **\\<** size**; ++**i**){**\n\n>   data_ptr**[**i**] =** v**.**data_ptr**[**i**];**\n\n>   **}**\n\n>   **}**\n\n-   移动构造：C++11,省去了构造和删除临时对象的过程\n\n    ![](media/8c3092d99bcdba78edeb2d8123270ffe.png)\n\n>   class_name**(**class_name **&&**old**)::**xptr**(**old**.**xptr**){**\n\n>   n**.**xptr **= NULL;** // 原来的指针清空\n\n>   **}**\n\n### **C风格字符串：**字符数组\n\n### **string类：**\n\n常用构造函数：\n\n-   string(); //默认构造，长度为0\n\n    -   string s1**;**\n\n-   string(const char \\*s) //指针s所指向的字符串常量初始化该对象\n\t\n\t\tstring s2 = “abc”;\n\t\t\n\t\tstring(const string &rhs) //复制构造函数\n\t\t\n\t\tstring s3 = s2;\n\n访问：下标访问\n\n整行字符串的输入： cin 被空格隔开\n\ngetline(cin,s2); //包含\\#include\\<string\\>\n\ngetline(cin,s2,’,’);\n\n\n## **继承和派生：** 充分利用原有的\n\n继承：保持已有类的特征来构造新类\n\n派生：在已有类基础上新增自己的特性\n\n基类：父类\n\n派生类：子类\n\n直接基类和间接基类\n\n单继承：\n\n\tclass 派生类名：继承方式 基类名{  //继承方式，\n\t    成员声明；//新增成员的声明\n\t}\n\n\n多继承：\n\n\tclass 派生类名：继承方式1 基类1，继承方式2 基类2{\n    \t成员声明；\n\t}\n\n\n### **继承的方式：**\n\n控制：派生类对基类成员的访问权限\n\n-   公有继承 public\n\n>   基类中的pubilc和protected访问属性在派生类中不变\n\n>   基类的pravate不可被对象直接访问\n\n-   私有继承 ：内部可以访问基类的公有和保护成员，但是其对象不再可以访问\n\n-   保护继承 ：基类的公有和保护，到这都成了保护成员，类内可以访问，但对象不能\n\n派生类的构成：\n\n-   吸收基类成员\n\n-   改造基类成员\n\n    -   增加同名成员，基类成员被覆盖（重新定义继承的成员函数必须用虚函数）\n\n-   添加新成员\n\n### **类型转换：**\n\n基类和派生类之间：\n  \n派生类的对象可以隐含转换为基类对象；\n\n派生类的对象可以初始化基类的引用；\n\n派生类的指针可以隐含转换为基类的指针；\n\n### **派生类的构造函数：**\n\n默认情况下，基类的构造函数不被继承，派生类需要自己构造\n\nc++11，using语句继承基类构造函数\n\n### **派生类的复制构造函数：**\n\n### **派生类的析构函数：**\n\n### **虚基类：**\n\n## **多态性**\n\n### **运算符重载：**\n\n\t//双目运算符\n\t函数类型 operator 运算符（参数）  \n\t{\n\t    // 参数个数 = 原操作数个数 - 1\n\t}\n\t//前置单目运算符，返回引用所以可以当左值\n\t函数类型 & operator ++（无参数）  \n\t{\n\t    return * this;\n\t}\n\t//后置单目运算符，\n\t函数类型 operator ++（参数为int类型）  \n\t{\n\t    old = *this;\n\t    ++(*this);  //调用的前置\n\t    return old;\n\t}\n\n\n-   重载为非成员函数：\n\n1.  列出所有操作数\n\n2.  至少有一个自定义类型参数\n\n3.  后置单目运算，参数要增加int,但不用写形参名\n\n4.  要操作某类对象的私有成员，则可声明为该类的友元函数\n\n### **虚函数：**virtual改造基类成员，实现动态绑定；必须是非静态成员\n\n>   原理：编译时先不确定和哪个类的成员对应，在程序运行时刻，再对应；\n\n\t#include <iostream>\n\tusing namespace std;\n\tclass Base1{\n\tpublic:\n\t    virtual void display() const; //虚函数，不要用内联\n\t};\n\n\tvoid Base1::display() const{\n\t    cout << \"Base1 \" << endl;\n\t}\n\t\n\tclass Base2:public Base1{\n\tpublic:\n\t    virtual void display() const;\n\t}\n\tvoid Base2::display() const{\n\t    cout << \"Base2\" << endl;\n\t}\n\n\n### **虚析构函数：**打算通过基类指针调用某一个对象的析构函数（执行delete）\n\n### **虚表和动态绑定：**\n\n>   虚表：\n\n-   每个多态类都有虚表；\n\n-   存放各个数函数的入口地址；\n\n-   每个对象有指向当前类的虚表的指针（虚指针vptr）；\n\n>   动态绑定：\n\n-   构造函数为对象的虚指针赋值\n\n### **抽象类：**含有纯虚函数的类,不能直接定义对象\n\n>   纯虚函数：\n\n>   基类中声明的虚函数，在基类中没有定义具体的操作，要求在派生类中根据实际需求完\n\n>   成自己的版本：\n\n\tvirtual 函数类型 函数名**(**参数名**) =** 0**;**\n\n### **override 和 final :**C++11\n\noverride声明的函数，必须在基类中找到原型；\n\nfinal 不允许继承或者覆盖；\n\n\n## **模板**\n\n### **函数魔板：**整数和浮点数求绝对值，需要多次重载函数，但是用函数模板，只需要设计通用功能；\n\ntemplate\\<模板参数表\\> // 类型：class或者typename 常量：\n\n函数定义\n\n\ttemplate<typename T>\n\tT abs(T x){\n\t    return x<0?-x:x;\n\t}\n\n\n### **类模板：**\n\n\ttemplate<模板参数表>\n\tclass 类名{\n\t    类成员声明;\n\t}\n\n\t//类成员定义\n\ttemplate <模板参数表>\n\t类型名  类名<模板参数标识符列表> :: 函数名(参数表)\n\t{\n\n\t}\n\n\n### **线性群体：**按位置顺序有序排列\n\n直接访问：\n\n数组类模板：\n\n索引访问：\n\n顺序访问：\n\n链表类和结点类模板：\n\n单链表：每个结点包括数据和指针，只有一个指向后续结点的称为单链表；\n\n![](media/9167a427f849e864c5d630d0c0bc3163.png)\n\n单链表结点类模板：\n\n\ttemplate <class T>\n\tclass Node{\n\t\tprivate:\n\t    \tNode<T> *next;\n\t\tpublic:\n\t    \tT data; \n\t    \tNode(const T&item,Node<T>* next = 0);  //构造函数\n\t    void insertAfter(Node<T> *p); //插入\n\t    Node<T> *deleteAfter();  //删除\n\t    Node<T> *nextNode() const; \n\t}\n\t\n\ttemplate <class T>\n\tvoid Node<T>::insertAfter(Node<T> *p){  // *p是要插入的结点\n\t// p节点的指针指向当前节点的后续结点\n\t    p->next = next; // next是原链表待插入位置的结点的指针\n\t    next = p;  \n\t}\n\ttemplate <class T>\n\tNode<T> *deleteAfter(){\n\t    Node<T> * tempPtr = next;\n\t    if (next == NULL)  //判断是否是删除最后的元素\n\t        return 0;\n\t    next = tempPtr = next;\n\t    return tempPtr;\n\t}\n\n\n>   插入：\n\n![](media/85d072d9c8a8366378b00b9af8ca4920.png)\n\n>   头插法：可以当队列\n\n>   尾插法：栈\n\n>   删除：\n\n![](media/ffdd5c0226d2a3f9a7833379eb0ebf90.png)\n\n待查询：\n\nexplicit关键字\n\n构造函数 explicit可以抑制内置类型隐式转换\n\n\n## **泛型设计**\n\n基本概念：\n\n编写不依赖具体数据类型的程序，通用的；\n\nSTL简介：(Standard Template Library)\n\nC++ string类库入门：\n\n    #include <iostream>\n\n    #include <string>\n\n    using namespace std;\n\n    int main()\n    {\n\n        // 构造函数：\n\t    string str1 = \"Yesterday\";\n\t\n\t    string str2(\"Today\");\n\t\n\t    string str3(\"Hello\",2); //取c风格字符串 长度为 2 作为初值，即\"He\"\n\t\n\t    string str4(str1, 6); // 始于位置6开始的字符串，即\"day\"\n\t\n\t    string str5(str1,6,1); // 始于6，长度1，即\"d\"\n\t\n\t\tstring str6(1,'a'); //6个'a'\n\t\t\n\t\t// 赋值，交换\n\t\tstr1.assign(\"hahahaha\"); //重新赋值\n\t\t\n\t\tswap(str1,str2); //交换两个字符串内容 str1=\"Today\" str2=\"hahahaha\"\n\t\t\n\t\t// 追加\n\t\tstr1 += \" we\"; // += 可追加 string对象，字符串，字符\n\t\t\n\t\tstr1.append(\" ar\"); // append 可追加 string对象，字符串\n\t\t\n\t\tstr1.push_back('e'); //push_back 只能追加字符 str1 = \"Today we are\"\n\n\t\t// 插入\n\t\tstr1.insert(0,\" family\"); //str1 = \"Today we are family\"\n\t\t\n\t\t// 删除\n\t\tstr1.erase(2,1); //第2个位置开始， len = 1 个字符\n\n\t\tstr1.clear(); //删除全部\n\t\t\n\t\t// 访问字符串\n\t\tstring s = \"asdfgh\";\n\t\t\n\t\tcout << s[1]; // 's'\n\t\t\n\t\tcout << s.at(2); // 'd'\n\t\t\n\t\t// 查找\n\t\tint position = s.find('f',0); // 从0开始查找第一次出现‘f’的坐标\n\t\t\n\t\t// 替换\n\t\ts.replace(s.find('f'),3,\"ZZZ\"); //替换find的位置处\n\t\t3个字符串为 “ZZZ”\n\t\t\n\t\t// 分割\n\t\tgetchar();\n\t\t\n\t\treturn 0;\n\n\t}\n","slug":"C-梳理笔记","published":1,"updated":"2019-07-30T15:35:42.713Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjz98jhc9002ky0pl21cw77fw","content":"<font color=\"red\"><big>测试内容</big></font>\n\n\n<p><del>删除线</del></p>\n<p><a href=\"http://zhuzhuyule.xyz\" target=\"_blank\" rel=\"noopener\">链接</a></p>\n<p><img src=\"/2019/01/20/C-梳理笔记/test.jpg\" alt=\"logo\"></p>\n<h1 id=\"C-学习笔记\"><a href=\"#C-学习笔记\" class=\"headerlink\" title=\"C++学习笔记\"></a>C++学习笔记</h1><h2 id=\"类型转换：\"><a href=\"#类型转换：\" class=\"headerlink\" title=\"类型转换：\"></a><strong>类型转换：</strong></h2><ol>\n<li><p>隐式转换： 低类型转换为高类型</p>\n<pre><code>浮点数（直接舍掉小数，不四舍五入） + 整数\n</code></pre></li>\n<li><p>显式转换：</p>\n<pre><code> int **(**z**) = (**int**)** z **= static_cast\\&lt;**int**\\&gt; (**z**)**\n</code></pre></li>\n</ol>\n<p>。。。</p>\n<h3 id=\"数据的输入和输出：信息的流动\"><a href=\"#数据的输入和输出：信息的流动\" class=\"headerlink\" title=\"数据的输入和输出：信息的流动\"></a><strong>数据的输入和输出：信息的流动</strong></h3><ol>\n<li><p>输入：</p>\n</li>\n<li><p>输出：</p>\n</li>\n<li><p>流类库的操纵符：</p>\n</li>\n</ol>\n<h3 id=\"程序控制：\"><a href=\"#程序控制：\" class=\"headerlink\" title=\"程序控制：\"></a><strong>程序控制：</strong></h3><pre><code>    if, while, for, do-while , break, continue, { switch,case,default } ;\n</code></pre><ol>\n<li><p>do-while:</p>\n<pre><code> do 语句      // 先执行一次\n while(表达式)；\n</code></pre></li>\n<li><p>for的范围，遍历容器：</p>\n</li>\n</ol>\n<h3 id=\"自定义类型：\"><a href=\"#自定义类型：\" class=\"headerlink\" title=\"自定义类型：\"></a><strong>自定义类型：</strong></h3><ul>\n<li>类型别名： </li>\n</ul>\n<ol>\n<li><p>typedef double Area, V;</p>\n</li>\n<li><p>using Area = double</p>\n</li>\n</ol>\n<ul>\n<li>枚举类型： 有限的个数</li>\n</ul>\n<p>　　　　不限定作用域： enum 类型名 { 变量值列表}</p>\n<p>　　　　限定作用域：</p>\n<p>　　　注：枚举元素是常量，不能赋值</p>\n<p>　　　　　枚举元素有默认值，默认0,1,2,3,4，声明时可以另外指定</p>\n<p>　　　　　可以进行关系运算</p>\n<ul>\n<li><p>auto类型 和decltyoe类型</p>\n<pre><code>      decltype( float( i )) j = 2;   // j值是2，类型是float;\n\n      auto m = 2.5;  // m 为float;\n</code></pre></li>\n<li><p>结构体( C语言中的)： struct</p>\n<pre><code>      struct MyTimeStruct{   //定义 结构体类型\n          unsigned int year,mouth,day,hour,min,sec;\n      };\n</code></pre></li>\n</ul>\n<h2 id=\"函数：-可重用的功能模块（定义和调用）\"><a href=\"#函数：-可重用的功能模块（定义和调用）\" class=\"headerlink\" title=\"函数： 可重用的功能模块（定义和调用）\"></a><strong>函数： 可重用的功能模块（定义和调用）</strong></h2><h3 id=\"函数定义：\"><a href=\"#函数定义：\" class=\"headerlink\" title=\"函数定义：\"></a><strong>函数定义：</strong></h3><p>　　形参不占用空间，调用时分配；</p>\n<h3 id=\"函数调用：\"><a href=\"#函数调用：\" class=\"headerlink\" title=\"函数调用：\"></a><strong>函数调用：</strong></h3><p>　　调用前要函数声明： int sum<strong>(</strong> int a<strong>,</strong> int b<strong>);</strong></p>\n<p>　　1. 函数的嵌套调用：</p>\n<p>　　2. 函数的递归调用： 直接或者间接调用自身</p>\n<p>计算n!</p>\n<pre><code>    unsigned int fac( unsigned int n){\n        if (n == 0) return 1;\n        return fac( n - 1) * n;\n    }\n</code></pre><p>汉诺塔</p>\n<pre><code>    分析：\n    1.    A 上的n-1个盘子移动到B上（借助C）;\n    2.    A上剩下的盘子移动到C上；\n    3.    B上的n-1个盘子移动到C上（借助A）\n    void move(char src, char obj)\n    {\n        cout &lt;&lt; src &lt;&lt; &quot;---&gt;&gt;&gt;&quot; &lt;&lt; obj &lt;&lt; endl;\n    }\n\n    void hanoi(int n, char src, char medium, char obj)\n    {\n        if(n == 1)\n            move(src, obj);\n        else{\n            hanoi(n-1, src, obj, medium);\n            move(src, obj);\n            hanoi(n-1, medium, src, obj);\n        }\n    }\n</code></pre><h3 id=\"函数的参数：\"><a href=\"#函数的参数：\" class=\"headerlink\" title=\"函数的参数：\"></a><strong>函数的参数：</strong></h3><ol>\n<li><p>形参不占用空间，调用时分配；</p>\n</li>\n<li><p>计算结果返回多个（利用引用）</p>\n</li>\n<li><p>多个参数时，从后开始传</p>\n</li>\n</ol>\n<h3 id=\"引用类型（-amp-）：-必须初始化，该类型不可改变，是其他变量的别名\"><a href=\"#引用类型（-amp-）：-必须初始化，该类型不可改变，是其他变量的别名\" class=\"headerlink\" title=\"引用类型（&amp;）： 必须初始化，该类型不可改变，是其他变量的别名\"></a><strong>引用类型（&amp;）：</strong> 必须初始化，该类型不可改变，是其他变量的别名</h3><pre><code>    int i, j;\n    int &amp; ri = i;  // 定义int引用类型变量 ri, 初始化为i的引用\n</code></pre><h3 id=\"含有可变参数的函数：（两种方法）\"><a href=\"#含有可变参数的函数：（两种方法）\" class=\"headerlink\" title=\"含有可变参数的函数：（两种方法）\"></a><strong>含有可变参数的函数：（两种方法）</strong></h3><ol>\n<li><p>所有实参类型相同：<code>initializer_list&lt;int&gt; li; //类模板, 都是常量</code></p>\n</li>\n<li><p>具体看第九章</p>\n</li>\n<li><p>类型不同：</p>\n</li>\n</ol>\n<h3 id=\"内联函数（inline）：-用函数体内的语句，替换函数调用表达式，编译时完成，类似-define\"><a href=\"#内联函数（inline）：-用函数体内的语句，替换函数调用表达式，编译时完成，类似-define\" class=\"headerlink\" title=\"内联函数（inline）： 用函数体内的语句，替换函数调用表达式，编译时完成，类似 #define\"></a><strong>内联函数（inline）： </strong>用函数体内的语句，替换函数调用表达式，编译时完成，类似 #define</h3><p>声明： <code>inline int calArea(int a){  }</code></p>\n<p>要求： 1. 不能有循环，switch语句 2. 定义在调用之前 3. 不能有异常接口声明</p>\n<h3 id=\"constexpr-函数：（常量表达式函数）\"><a href=\"#constexpr-函数：（常量表达式函数）\" class=\"headerlink\" title=\"constexpr 函数：（常量表达式函数）\"></a>constexpr 函数：（常量表达式函数）</h3><h3 id=\"带默认参数的函数：\"><a href=\"#带默认参数的函数：\" class=\"headerlink\" title=\"带默认参数的函数：\"></a><strong>带默认参数的函数：</strong></h3><pre><code>    int getVa(int length, int weight = 2)\n</code></pre><h3 id=\"函数的重载：（C-多态性的重要机制，编译过程中实现）\"><a href=\"#函数的重载：（C-多态性的重要机制，编译过程中实现）\" class=\"headerlink\" title=\"函数的重载：（C++多态性的重要机制，编译过程中实现）\"></a><strong>函数的重载：</strong>（C++多态性的重要机制，编译过程中实现）</h3><p>函数体同名，参数类型不同/参数个数不同</p>\n<pre><code>    int add(int x, int y);\n\n    float add(float x, float y);\n\n    float add(float x, float y, float z);\n</code></pre><h3 id=\"C-系统函数：\"><a href=\"#C-系统函数：\" class=\"headerlink\" title=\"C++系统函数：\"></a><strong>C++系统函数：</strong></h3><pre><code>    #include &lt;cmath&gt;\n        |_\n        |_\n    #include &lt;cstdlib&gt;\n        |_\n        |_\n    #include &lt;cstdio&gt;\n        |_\n        |_\n    #include &lt;ctime&gt;\n        |_\n        |_\n</code></pre><h2 id=\"类和对象\"><a href=\"#类和对象\" class=\"headerlink\" title=\"类和对象\"></a><strong>类和对象</strong></h2><p>类：构建对象的蓝图，</p>\n<p>对象：由类创建，含有数据和方法</p>\n<p>封装：对数据和操作数据的方法的组合绑定</p>\n<p>继承：在已有类基础上，形成新的类</p>\n<p>多态：</p>\n<p>构造函数：定义对象时，通过构造函数初始化</p>\n<p>析构函数：删除对象时，通过析构函数释放资源</p>\n<h3 id=\"类和对象的定义：\"><a href=\"#类和对象的定义：\" class=\"headerlink\" title=\" 类和对象的定义：\"></a><strong> 类和对象的定义：</strong></h3><p>定义类：</p>\n<pre><code>    class {  //类名称 \n        public:\n            // 公有成员,外部接口\n        private:\n            // 私有成员\n        protected:\n            int hour = 0; // 类内初始化\n            // 保护型成员\n    }\n</code></pre><p>注意：不指定类型，默认为私有；</p>\n<h3 id=\"成员函数：\"><a href=\"#成员函数：\" class=\"headerlink\" title=\"成员函数：\"></a><strong>成员函数：</strong></h3><pre><code>    |_ 内联成员函数： 类内声明或者inline关键字\n\n    |_类外实现：void 类名称::成员函数名称（）{ }\n</code></pre><h3 id=\"构造函数：\"><a href=\"#构造函数：\" class=\"headerlink\" title=\"构造函数：\"></a><strong>构造函数：</strong></h3><ul>\n<li><p>在创建对象时，自动调用来初始化数据</p>\n</li>\n<li><p>与类名相同</p>\n</li>\n<li><p>构造函数有初始化列表</p>\n</li>\n<li><p>格式 类名（string s, lei i）：s(初始值)，i(初始值){ }；</p>\n</li>\n</ul>\n<h3 id=\"委托构造函数：一个构造函数-通过另一个构造函数-初始化\"><a href=\"#委托构造函数：一个构造函数-通过另一个构造函数-初始化\" class=\"headerlink\" title=\"委托构造函数：一个构造函数 通过另一个构造函数 初始化\"></a><strong>委托构造函数：</strong>一个构造函数 通过另一个构造函数 初始化</h3><h3 id=\"复制构造函数：\"><a href=\"#复制构造函数：\" class=\"headerlink\" title=\"复制构造函数：\"></a><strong>复制构造函数：</strong></h3><p>用途：</p>\n<ul>\n<li><p>用存在的对象 去初始化新对象 （通过引用旧的对象）</p>\n</li>\n<li><p>函数f的形参是类的对象，调用f时，将用实参对象初始化形参对象</p>\n</li>\n<li><p>函数g的返回值是类的对象，用return的对象来在主调函数中初始化一个无名对象</p>\n</li>\n</ul>\n<h3 id=\"析构函数：生存期结束，删除清理工作，不能有return，不能有参数\"><a href=\"#析构函数：生存期结束，删除清理工作，不能有return，不能有参数\" class=\"headerlink\" title=\"析构函数：生存期结束，删除清理工作，不能有return，不能有参数\"></a><strong>析构函数：</strong>生存期结束，删除清理工作，不能有return，不能有参数</h3><pre><code>    class 类名{\n\n    public:\n        类名（形参）； // 构造函数\n        类名（const 类名&amp; 旧对象名）；  // 复制构造函数 =delete是不生成\n        ~ 类名（）；\n    }\n</code></pre><blockquote>\n<p>  注：未声明时，编译器自己生成一个默认的</p>\n</blockquote>\n<h3 id=\"前向引用声明：两个类相互引用时，某个类在引用之前就声明\"><a href=\"#前向引用声明：两个类相互引用时，某个类在引用之前就声明\" class=\"headerlink\" title=\"前向引用声明：两个类相互引用时，某个类在引用之前就声明\"></a><strong>前向引用声明：</strong>两个类相互引用时，某个类在引用之前就声明</h3><pre><code>    class A;  //前向引用声明，只是一个标识符，不是万能的\n    class B{\n    public:\n        void A(B b);\n    }\n\n    class A{\n    public：\n        void B（A a）;\n    }\n</code></pre><h3 id=\"结构体：特殊的类，默认是公有的，可以有函数成员\"><a href=\"#结构体：特殊的类，默认是公有的，可以有函数成员\" class=\"headerlink\" title=\"结构体：特殊的类，默认是公有的，可以有函数成员\"></a><strong>结构体：</strong>特殊的类，默认是公有的，可以有函数成员</h3><pre><code>    //公有成员\n        int a;\n    protected:\n        int b;\n    private:\n        int c;\n    };\n</code></pre><h3 id=\"联合体：\"><a href=\"#联合体：\" class=\"headerlink\" title=\"联合体：\"></a><strong>联合体：</strong></h3><p>目的：存储空间的共用，成员不能同时有效，比如某人语文课成绩，只有一种可能；</p>\n<pre><code>    union Mark{ // 成绩的联合体， 只有一个成立\n        char grade;  //等级类的成绩\n        bool pass;  // 是否通过的成绩\n    int percent;  //百分制成绩  }\n</code></pre><h3 id=\"枚举类：\"><a href=\"#枚举类：\" class=\"headerlink\" title=\"枚举类：\"></a><strong>枚举类：</strong></h3><p>enum class 枚举类型名： 底层类型（int）<strong>{</strong> 枚举列表 <strong>};</strong></p>\n<pre><code>//默认 int\n</code></pre><p>优势：</p>\n<ul>\n<li><p>强制作用域 —必须在枚举类 枚举类型名：：枚举值，不同枚举类可以有同名值了</p>\n</li>\n<li><p>转换限制 —枚举对象不能与整型 隐式转换</p>\n</li>\n<li><p>底层类型 —可以指定</p>\n</li>\n</ul>\n<h2 id=\"数据共享和保护：\"><a href=\"#数据共享和保护：\" class=\"headerlink\" title=\"数据共享和保护：\"></a><strong>数据共享和保护：</strong></h2><h3 id=\"作用域分类：\"><a href=\"#作用域分类：\" class=\"headerlink\" title=\"作用域分类：\"></a><strong>作用域分类：</strong></h3><p>函数原型作用域：</p>\n<ul>\n<li>形参的范围在（）内，所以不需要名字也行，int area( int );</li>\n</ul>\n<p>局部作用域</p>\n<ul>\n<li><p>函数{ }内</p>\n</li>\n<li><p>if、for、while { }内</p>\n</li>\n</ul>\n<p>类作用域： 类外访问类的成员</p>\n<ul>\n<li><p>静态成员：通过 对象名.成员名 访问</p>\n</li>\n<li><p>非静态成员：</p>\n</li>\n<li><p>文件作用域</p>\n</li>\n<li><p>命名空间作用域： 10章</p>\n</li>\n</ul>\n<h3 id=\"对象的生存期：\"><a href=\"#对象的生存期：\" class=\"headerlink\" title=\"对象的生存期：\"></a><strong>对象的生存期：</strong></h3><p>静态生存期： 整个程序结束后消失</p>\n<ul>\n<li>函数内的静态对象， 用static ，全局寿命，只局部可见</li>\n</ul>\n<p>动态生存期：</p>\n<ul>\n<li><p>离开作用域后消失</p>\n</li>\n<li><p>下次进函数重新生成对象</p>\n</li>\n</ul>\n<h3 id=\"类的静态数据成员：\"><a href=\"#类的静态数据成员：\" class=\"headerlink\" title=\"类的静态数据成员：\"></a><strong>类的静态数据成员：</strong></h3><ul>\n<li><p>static 声明</p>\n</li>\n<li><p>为该类所有对象共享，具有静态生存期</p>\n</li>\n<li><p>必须在类外定义和初始化，类内声明，用：：指明所属于的类</p>\n</li>\n</ul>\n<p>比如记录 类产生了多少对象；opencv中的Mat对象好像用到了？？？？</p>\n<pre><code>    class base{   \n        public :   \n               static   int   _num;//声明   \n    };   \n    int  base::_num=0;  //真正定义  \n</code></pre><h3 id=\"类的友元：\"><a href=\"#类的友元：\" class=\"headerlink\" title=\"类的友元：\"></a><strong>类的友元：</strong></h3><ul>\n<li><p>破坏数据封装和数据隐藏的机制</p>\n</li>\n<li><p>尽量不用</p>\n</li>\n</ul>\n<h3 id=\"友元函数：\"><a href=\"#友元函数：\" class=\"headerlink\" title=\" 友元函数：\"></a><strong> 友元函数：</strong></h3><ul>\n<li><p>类声明中由关键字 friend 修饰说明的非成员函数</p>\n</li>\n<li><p>可以在其函数体内访问对象的private,protected成员</p>\n</li>\n<li><p>但必须通过对象名：：访问，函数参数为类的引用</p>\n</li>\n<li><h3 id=\"友元类：\"><a href=\"#友元类：\" class=\"headerlink\" title=\" 友元类：\"></a><strong> 友元类：</strong></h3><pre><code>class A{\n    friend B;\n  public:\n    void display(){\n        count &lt;&lt; x &lt;&lt; enld;\n    }\n  private:\n    int x;\n}\n\nclass B{\n  public:\n    void set(int i);\n    void display();\n  private:\n    A a;\n}\n\nvoid B::set(int i){\n    a.x = i;   // B类中改变 A类私有值\n}\nvoid B::display(){\n    a.display()\n}\n</code></pre></li>\n</ul>\n<h3 id=\"共享数据的保护：\"><a href=\"#共享数据的保护：\" class=\"headerlink\" title=\"共享数据的保护：\"></a><strong>共享数据的保护：</strong></h3><h1 id=\"常类型：const\"><a href=\"#常类型：const\" class=\"headerlink\" title=\"常类型：const\"></a><strong>常类型：</strong>const</h1><p>常对象：必须初始化，不可更新</p>\n<pre><code>    class A{\n    }\n    A const a; // a是常对象\n</code></pre><p>常成员：(不可以放在构造函数体内复制，可以在初始化列表中)</p>\n<pre><code>    A：：A(int i):a(i){ }\n</code></pre><ul>\n<li><p>常数据成员：const修饰的</p>\n</li>\n<li><p>静态常数据成员： static const int b;</p>\n</li>\n<li><p>常函数成员（用来处理常对象的函数）</p>\n<ul>\n<li><p>不更新对象的数据成员</p>\n</li>\n<li><p>声明和实现都带const</p>\n</li>\n</ul>\n</li>\n</ul>\n<pre><code>        class A{\n            void f（int a）const;\n        }\n        void A::f(int a) const{  \n        }; // f是常对象函数, 处理常对象\n</code></pre><ul>\n<li>常引用：不可更新</li>\n</ul>\n<p>　　　引用是双向传递的，避免修改原值的方法就是常引用；</p>\n<pre><code>     const A&amp; a;\n</code></pre><ul>\n<li><p>常数组：</p>\n</li>\n<li><p>常指针：</p>\n</li>\n</ul>\n<h3 id=\"多文件结构和预编译命令：\"><a href=\"#多文件结构和预编译命令：\" class=\"headerlink\" title=\"多文件结构和预编译命令：\"></a><strong>多文件结构和预编译命令：</strong></h3><ul>\n<li><p>.h 系统使用</p>\n</li>\n<li><p>.hpp 个人使用(类的声明,函数的声明)</p>\n</li>\n<li><p>.cpp (类的实现，函数的实现)</p>\n<p> <img src=\"/2019/01/20/C-梳理笔记/f5d645ed218d5fa3e753f771b72310fc.png\" alt=\"\"></p>\n</li>\n</ul>\n<h3 id=\"外部变量：\"><a href=\"#外部变量：\" class=\"headerlink\" title=\"外部变量：\"></a><strong>外部变量：</strong></h3><p>文件作用域中定义的变量默认是外部变量，其他文件使用前，extern声明</p>\n<p>将变量和函数限制在编译单元内：namespcae:</p>\n<pre><code>    namespace{ //匿名的命名空间，外部不可调用任何东西\n        int i;\n        void fun(){\n            i++;\n        }\n    }\n</code></pre><h3 id=\"预编译命令：\"><a href=\"#预编译命令：\" class=\"headerlink\" title=\"预编译命令：\"></a><strong>预编译命令：</strong></h3><pre><code>    #include&lt; &gt;  标准方式搜索，从系统目录include\n\n\n    #include”” 先当前目录搜索，没有再标准搜索\n\n\n    #define \n\n\n    #undef 删除有#define的宏\n\n    #if 表达式  // 条件编译指令\n    ---\n    #else\n    ---\n    #endif \n\n\n    #ifndef 标识符\n    ---\n    #else  \n    ---\n    #endif\n</code></pre><h2 id=\"数组，指针与字符串：\"><a href=\"#数组，指针与字符串：\" class=\"headerlink\" title=\"数组，指针与字符串：\"></a><strong>数组，指针与字符串：</strong></h2><h3 id=\"数组：\"><a href=\"#数组：\" class=\"headerlink\" title=\"数组：\"></a><strong>数组：</strong></h3><p>定义： <code>int arr**[**m**][**n**]**…;</code></p>\n<p>　　注：二维数组中 arr[1] 第二行首地址</p>\n<h3 id=\"数组作为函数参数：\"><a href=\"#数组作为函数参数：\" class=\"headerlink\" title=\"数组作为函数参数：\"></a><strong>数组作为函数参数：</strong></h3><p>　　数组名做参数： 形参，实参都是数组名，传入的是地址</p>\n<h3 id=\"对象数组：\"><a href=\"#对象数组：\" class=\"headerlink\" title=\"对象数组：\"></a><strong>对象数组：</strong></h3><p>　　定义：类名 数组名[对象元素个数]</p>\n<p>　　访问：数组名[下标].成员名</p>\n<h3 id=\"基于范围的for循环：c-11-自动遍历整个容器\"><a href=\"#基于范围的for循环：c-11-自动遍历整个容器\" class=\"headerlink\" title=\"基于范围的for循环：c++11,自动遍历整个容器\"></a><strong>基于范围的for循环：</strong>c++11,自动遍历整个容器</h3><pre><code>  for( auto x : 容器){ } for( auto &amp;x : 容器){ }\n</code></pre><p>注意：</p>\n<ul>\n<li><p>auto &amp;x是元素引用，auto x是元素的副本</p>\n</li>\n<li><p>auto推导出的类型是容器中的值类型</p>\n</li>\n<li><p>：冒号后的表达式只执行一次</p>\n</li>\n</ul>\n<h3 id=\"指针：\"><a href=\"#指针：\" class=\"headerlink\" title=\"指针：\"></a><strong>指针：</strong></h3><h3 id=\"定义：\"><a href=\"#定义：\" class=\"headerlink\" title=\"定义：\"></a><strong>定义：</strong></h3><pre><code>    static int i;\n\n    static int * p = &amp;I;\n</code></pre><h3 id=\"指针的初始化和赋值：\"><a href=\"#指针的初始化和赋值：\" class=\"headerlink\" title=\"指针的初始化和赋值：\"></a><strong>指针的初始化和赋值：</strong></h3><h3 id=\"指针的算术运算，关系运算：\"><a href=\"#指针的算术运算，关系运算：\" class=\"headerlink\" title=\"指针的算术运算，关系运算：\"></a><strong>指针的算术运算，关系运算：</strong></h3><h3 id=\"指针数组：\"><a href=\"#指针数组：\" class=\"headerlink\" title=\"指针数组：\"></a><strong>指针数组：</strong></h3><pre><code>    类名  *p[2];\n</code></pre><h3 id=\"指向数组的指针：\"><a href=\"#指向数组的指针：\" class=\"headerlink\" title=\"指向数组的指针：\"></a><strong>指向数组的指针：</strong></h3><pre><code>    int **p; 指向二维数组的指针\n</code></pre><h3 id=\"指针与函数：\"><a href=\"#指针与函数：\" class=\"headerlink\" title=\"指针与函数：\"></a><strong>指针与函数：</strong></h3><ul>\n<li><p>指针做参数：大批量数据提高效率</p>\n</li>\n<li><p>指针类型的函数：返回类型是指针</p>\n<pre><code>  int * function(int i){return 全局或者静态的 }；// 不能返回非静态局部变量\n</code></pre></li>\n<li><p>指向函数的指针：实现函数回调的功能</p>\n</li>\n</ul>\n<blockquote>\n<p>  定义： 数据类型 (*f)(参数表);</p>\n<p>  数据类型：返回值</p>\n</blockquote>\n<ul>\n<li>对象指针：</li>\n</ul>\n<blockquote>\n<p>  定义： 类名 *对象指针名 = &amp; 对象；</p>\n<p>  访问对象： 对象指针名->成员名</p>\n</blockquote>\n<p>（*对象指针名）.成员名</p>\n<ul>\n<li><p>this 指针：成员函数的一个隐士参数，初始化为对象的地址，不可改变</p>\n</li>\n<li><p>隐含于类的每个非静态成员函数中</p>\n</li>\n<li><p>指出成员函数所操作的当前的对象</p>\n</li>\n<li><p>*this 是当前对象地址</p>\n</li>\n</ul>\n<h3 id=\"动态内存分配：\"><a href=\"#动态内存分配：\" class=\"headerlink\" title=\"动态内存分配：\"></a><strong>动态内存分配：</strong></h3><p>new<strong> 类型名 </strong>(<strong>初始化列表</strong>) // 返回首字节地址</p>\n<p>delete 指针p //p一直在，删除的只是p指向的对象申请的空间</p>\n<p>动态数组：<br>new 类型名[数组长度]</p>\n<p>delete[] 数组首地址p指针</p>\n<h3 id=\"智能指针：C-11\"><a href=\"#智能指针：C-11\" class=\"headerlink\" title=\"智能指针：C++11\"></a><strong>智能指针：</strong>C++11</h3><h3 id=\"内存管理\"><a href=\"#内存管理\" class=\"headerlink\" title=\"内存管理\"></a><strong>内存管理</strong></h3><ul>\n<li><p>unique_ptr:</p>\n<ul>\n<li>不允许多个指针共享资源，标准库中move可以转移指针，但原来指针会失效</li>\n</ul>\n</li>\n<li><p>shared_ptr:</p>\n<ul>\n<li>多指针共享</li>\n</ul>\n</li>\n<li><p>weak_ptr:</p>\n<ul>\n<li>可复制共享</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>  Vector对象：类模板</p>\n</blockquote>\n<p>优势：</p>\n<ul>\n<li><p>封装任何形式的动态数组，自动创建，删除</p>\n</li>\n<li><p>下标越界检查</p>\n</li>\n</ul>\n<p>定义： vector &lt;元素类型&gt; object（长度）</p>\n<ul>\n<li><p><code>object.begin()  object.end()  object.size()</code></p>\n</li>\n<li><p>auto 遍历vector <code>for(auto e: object);</code></p>\n</li>\n</ul>\n<h3 id=\"对象的复制和移动：\"><a href=\"#对象的复制和移动：\" class=\"headerlink\" title=\"对象的复制和移动：\"></a><strong>对象的复制和移动：</strong></h3><ul>\n<li><p>浅层复制和深层复制：复制对象用到复制构造函数，默认的复制构造只传递了指针，两个变量指向同一块内存，释放其中一个，再释放第二个会出错；</p>\n<ul>\n<li><p>浅层：实现对象间数据一一对应的复制，但两个对象指向同一内存</p>\n</li>\n<li><p>深层：当对象成员是指针类型，应该对指针所指对象进行复制。</p>\n</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>  类名<strong>::</strong>类名<strong>(</strong>const 类名<strong>&amp;</strong> v<strong>){</strong></p>\n<p>  size <strong>=</strong> v<strong>.</strong>size<strong>;</strong></p>\n<p>  data_ptr <strong>= new</strong> Ponit<strong>[</strong>size<strong>];</strong></p>\n<p>  <strong>for(</strong>int i<strong>=</strong>0<strong>;</strong> i <strong>\\&lt;</strong> size<strong>; ++</strong>i<strong>){</strong></p>\n<p>  data_ptr<strong>[</strong>i<strong>] =</strong> v<strong>.</strong>data_ptr<strong>[</strong>i<strong>];</strong></p>\n<p>  <strong>}</strong></p>\n<p>  <strong>}</strong></p>\n</blockquote>\n<ul>\n<li><p>移动构造：C++11,省去了构造和删除临时对象的过程</p>\n<p><img src=\"/2019/01/20/C-梳理笔记/8c3092d99bcdba78edeb2d8123270ffe.png\" alt=\"\"></p>\n</li>\n</ul>\n<blockquote>\n<p>  class_name<strong>(</strong>class_name <strong>&amp;&amp;</strong>old<strong>)::</strong>xptr<strong>(</strong>old<strong>.</strong>xptr<strong>){</strong></p>\n<p>  n<strong>.</strong>xptr <strong>= NULL;</strong> // 原来的指针清空</p>\n<p>  <strong>}</strong></p>\n</blockquote>\n<h3 id=\"C风格字符串：字符数组\"><a href=\"#C风格字符串：字符数组\" class=\"headerlink\" title=\"C风格字符串：字符数组\"></a><strong>C风格字符串：</strong>字符数组</h3><h3 id=\"string类：\"><a href=\"#string类：\" class=\"headerlink\" title=\"string类：\"></a><strong>string类：</strong></h3><p>常用构造函数：</p>\n<ul>\n<li><p>string(); //默认构造，长度为0</p>\n<ul>\n<li>string s1<strong>;</strong></li>\n</ul>\n</li>\n<li><p>string(const char *s) //指针s所指向的字符串常量初始化该对象</p>\n<pre><code>string s2 = “abc”;\n\nstring(const string &amp;rhs) //复制构造函数\n\nstring s3 = s2;\n</code></pre></li>\n</ul>\n<p>访问：下标访问</p>\n<p>整行字符串的输入： cin 被空格隔开</p>\n<p>getline(cin,s2); //包含#include\\<string\\></string\\></p>\n<p>getline(cin,s2,’,’);</p>\n<h2 id=\"继承和派生：-充分利用原有的\"><a href=\"#继承和派生：-充分利用原有的\" class=\"headerlink\" title=\"继承和派生： 充分利用原有的\"></a><strong>继承和派生：</strong> 充分利用原有的</h2><p>继承：保持已有类的特征来构造新类</p>\n<p>派生：在已有类基础上新增自己的特性</p>\n<p>基类：父类</p>\n<p>派生类：子类</p>\n<p>直接基类和间接基类</p>\n<p>单继承：</p>\n<pre><code>class 派生类名：继承方式 基类名{  //继承方式，\n    成员声明；//新增成员的声明\n}\n</code></pre><p>多继承：</p>\n<pre><code>class 派生类名：继承方式1 基类1，继承方式2 基类2{\n    成员声明；\n}\n</code></pre><h3 id=\"继承的方式：\"><a href=\"#继承的方式：\" class=\"headerlink\" title=\"继承的方式：\"></a><strong>继承的方式：</strong></h3><p>控制：派生类对基类成员的访问权限</p>\n<ul>\n<li>公有继承 public</li>\n</ul>\n<blockquote>\n<p>  基类中的pubilc和protected访问属性在派生类中不变</p>\n<p>  基类的pravate不可被对象直接访问</p>\n</blockquote>\n<ul>\n<li><p>私有继承 ：内部可以访问基类的公有和保护成员，但是其对象不再可以访问</p>\n</li>\n<li><p>保护继承 ：基类的公有和保护，到这都成了保护成员，类内可以访问，但对象不能</p>\n</li>\n</ul>\n<p>派生类的构成：</p>\n<ul>\n<li><p>吸收基类成员</p>\n</li>\n<li><p>改造基类成员</p>\n<ul>\n<li>增加同名成员，基类成员被覆盖（重新定义继承的成员函数必须用虚函数）</li>\n</ul>\n</li>\n<li><p>添加新成员</p>\n</li>\n</ul>\n<h3 id=\"类型转换：-1\"><a href=\"#类型转换：-1\" class=\"headerlink\" title=\"类型转换：\"></a><strong>类型转换：</strong></h3><p>基类和派生类之间：</p>\n<p>派生类的对象可以隐含转换为基类对象；</p>\n<p>派生类的对象可以初始化基类的引用；</p>\n<p>派生类的指针可以隐含转换为基类的指针；</p>\n<h3 id=\"派生类的构造函数：\"><a href=\"#派生类的构造函数：\" class=\"headerlink\" title=\"派生类的构造函数：\"></a><strong>派生类的构造函数：</strong></h3><p>默认情况下，基类的构造函数不被继承，派生类需要自己构造</p>\n<p>c++11，using语句继承基类构造函数</p>\n<h3 id=\"派生类的复制构造函数：\"><a href=\"#派生类的复制构造函数：\" class=\"headerlink\" title=\"派生类的复制构造函数：\"></a><strong>派生类的复制构造函数：</strong></h3><h3 id=\"派生类的析构函数：\"><a href=\"#派生类的析构函数：\" class=\"headerlink\" title=\"派生类的析构函数：\"></a><strong>派生类的析构函数：</strong></h3><h3 id=\"虚基类：\"><a href=\"#虚基类：\" class=\"headerlink\" title=\"虚基类：\"></a><strong>虚基类：</strong></h3><h2 id=\"多态性\"><a href=\"#多态性\" class=\"headerlink\" title=\"多态性\"></a><strong>多态性</strong></h2><h3 id=\"运算符重载：\"><a href=\"#运算符重载：\" class=\"headerlink\" title=\"运算符重载：\"></a><strong>运算符重载：</strong></h3><pre><code>//双目运算符\n函数类型 operator 运算符（参数）  \n{\n    // 参数个数 = 原操作数个数 - 1\n}\n//前置单目运算符，返回引用所以可以当左值\n函数类型 &amp; operator ++（无参数）  \n{\n    return * this;\n}\n//后置单目运算符，\n函数类型 operator ++（参数为int类型）  \n{\n    old = *this;\n    ++(*this);  //调用的前置\n    return old;\n}\n</code></pre><ul>\n<li>重载为非成员函数：</li>\n</ul>\n<ol>\n<li><p>列出所有操作数</p>\n</li>\n<li><p>至少有一个自定义类型参数</p>\n</li>\n<li><p>后置单目运算，参数要增加int,但不用写形参名</p>\n</li>\n<li><p>要操作某类对象的私有成员，则可声明为该类的友元函数</p>\n</li>\n</ol>\n<h3 id=\"虚函数：virtual改造基类成员，实现动态绑定；必须是非静态成员\"><a href=\"#虚函数：virtual改造基类成员，实现动态绑定；必须是非静态成员\" class=\"headerlink\" title=\"虚函数：virtual改造基类成员，实现动态绑定；必须是非静态成员\"></a><strong>虚函数：</strong>virtual改造基类成员，实现动态绑定；必须是非静态成员</h3><blockquote>\n<p>  原理：编译时先不确定和哪个类的成员对应，在程序运行时刻，再对应；</p>\n</blockquote>\n<pre><code>#include &lt;iostream&gt;\nusing namespace std;\nclass Base1{\npublic:\n    virtual void display() const; //虚函数，不要用内联\n};\n\nvoid Base1::display() const{\n    cout &lt;&lt; &quot;Base1 &quot; &lt;&lt; endl;\n}\n\nclass Base2:public Base1{\npublic:\n    virtual void display() const;\n}\nvoid Base2::display() const{\n    cout &lt;&lt; &quot;Base2&quot; &lt;&lt; endl;\n}\n</code></pre><h3 id=\"虚析构函数：打算通过基类指针调用某一个对象的析构函数（执行delete）\"><a href=\"#虚析构函数：打算通过基类指针调用某一个对象的析构函数（执行delete）\" class=\"headerlink\" title=\"虚析构函数：打算通过基类指针调用某一个对象的析构函数（执行delete）\"></a><strong>虚析构函数：</strong>打算通过基类指针调用某一个对象的析构函数（执行delete）</h3><h3 id=\"虚表和动态绑定：\"><a href=\"#虚表和动态绑定：\" class=\"headerlink\" title=\"虚表和动态绑定：\"></a><strong>虚表和动态绑定：</strong></h3><blockquote>\n<p>  虚表：</p>\n</blockquote>\n<ul>\n<li><p>每个多态类都有虚表；</p>\n</li>\n<li><p>存放各个数函数的入口地址；</p>\n</li>\n<li><p>每个对象有指向当前类的虚表的指针（虚指针vptr）；</p>\n</li>\n</ul>\n<blockquote>\n<p>  动态绑定：</p>\n</blockquote>\n<ul>\n<li>构造函数为对象的虚指针赋值</li>\n</ul>\n<h3 id=\"抽象类：含有纯虚函数的类-不能直接定义对象\"><a href=\"#抽象类：含有纯虚函数的类-不能直接定义对象\" class=\"headerlink\" title=\"抽象类：含有纯虚函数的类,不能直接定义对象\"></a><strong>抽象类：</strong>含有纯虚函数的类,不能直接定义对象</h3><blockquote>\n<p>  纯虚函数：</p>\n<p>  基类中声明的虚函数，在基类中没有定义具体的操作，要求在派生类中根据实际需求完</p>\n<p>  成自己的版本：</p>\n</blockquote>\n<pre><code>virtual 函数类型 函数名**(**参数名**) =** 0**;**\n</code></pre><h3 id=\"override-和-final-C-11\"><a href=\"#override-和-final-C-11\" class=\"headerlink\" title=\"override 和 final :C++11\"></a><strong>override 和 final :</strong>C++11</h3><p>override声明的函数，必须在基类中找到原型；</p>\n<p>final 不允许继承或者覆盖；</p>\n<h2 id=\"模板\"><a href=\"#模板\" class=\"headerlink\" title=\"模板\"></a><strong>模板</strong></h2><h3 id=\"函数魔板：整数和浮点数求绝对值，需要多次重载函数，但是用函数模板，只需要设计通用功能；\"><a href=\"#函数魔板：整数和浮点数求绝对值，需要多次重载函数，但是用函数模板，只需要设计通用功能；\" class=\"headerlink\" title=\"函数魔板：整数和浮点数求绝对值，需要多次重载函数，但是用函数模板，只需要设计通用功能；\"></a><strong>函数魔板：</strong>整数和浮点数求绝对值，需要多次重载函数，但是用函数模板，只需要设计通用功能；</h3><p>template\\&lt;模板参数表> // 类型：class或者typename 常量：</p>\n<p>函数定义</p>\n<pre><code>template&lt;typename T&gt;\nT abs(T x){\n    return x&lt;0?-x:x;\n}\n</code></pre><h3 id=\"类模板：\"><a href=\"#类模板：\" class=\"headerlink\" title=\"类模板：\"></a><strong>类模板：</strong></h3><pre><code>template&lt;模板参数表&gt;\nclass 类名{\n    类成员声明;\n}\n\n//类成员定义\ntemplate &lt;模板参数表&gt;\n类型名  类名&lt;模板参数标识符列表&gt; :: 函数名(参数表)\n{\n\n}\n</code></pre><h3 id=\"线性群体：按位置顺序有序排列\"><a href=\"#线性群体：按位置顺序有序排列\" class=\"headerlink\" title=\"线性群体：按位置顺序有序排列\"></a><strong>线性群体：</strong>按位置顺序有序排列</h3><p>直接访问：</p>\n<p>数组类模板：</p>\n<p>索引访问：</p>\n<p>顺序访问：</p>\n<p>链表类和结点类模板：</p>\n<p>单链表：每个结点包括数据和指针，只有一个指向后续结点的称为单链表；</p>\n<p><img src=\"/2019/01/20/C-梳理笔记/9167a427f849e864c5d630d0c0bc3163.png\" alt=\"\"></p>\n<p>单链表结点类模板：</p>\n<pre><code>template &lt;class T&gt;\nclass Node{\n    private:\n        Node&lt;T&gt; *next;\n    public:\n        T data; \n        Node(const T&amp;item,Node&lt;T&gt;* next = 0);  //构造函数\n    void insertAfter(Node&lt;T&gt; *p); //插入\n    Node&lt;T&gt; *deleteAfter();  //删除\n    Node&lt;T&gt; *nextNode() const; \n}\n\ntemplate &lt;class T&gt;\nvoid Node&lt;T&gt;::insertAfter(Node&lt;T&gt; *p){  // *p是要插入的结点\n// p节点的指针指向当前节点的后续结点\n    p-&gt;next = next; // next是原链表待插入位置的结点的指针\n    next = p;  \n}\ntemplate &lt;class T&gt;\nNode&lt;T&gt; *deleteAfter(){\n    Node&lt;T&gt; * tempPtr = next;\n    if (next == NULL)  //判断是否是删除最后的元素\n        return 0;\n    next = tempPtr = next;\n    return tempPtr;\n}\n</code></pre><blockquote>\n<p>  插入：</p>\n</blockquote>\n<p><img src=\"/2019/01/20/C-梳理笔记/85d072d9c8a8366378b00b9af8ca4920.png\" alt=\"\"></p>\n<blockquote>\n<p>  头插法：可以当队列</p>\n<p>  尾插法：栈</p>\n<p>  删除：</p>\n</blockquote>\n<p><img src=\"/2019/01/20/C-梳理笔记/ffdd5c0226d2a3f9a7833379eb0ebf90.png\" alt=\"\"></p>\n<p>待查询：</p>\n<p>explicit关键字</p>\n<p>构造函数 explicit可以抑制内置类型隐式转换</p>\n<h2 id=\"泛型设计\"><a href=\"#泛型设计\" class=\"headerlink\" title=\"泛型设计\"></a><strong>泛型设计</strong></h2><p>基本概念：</p>\n<p>编写不依赖具体数据类型的程序，通用的；</p>\n<p>STL简介：(Standard Template Library)</p>\n<p>C++ string类库入门：</p>\n<pre><code>#include &lt;iostream&gt;\n\n#include &lt;string&gt;\n\nusing namespace std;\n\nint main()\n{\n\n    // 构造函数：\n    string str1 = &quot;Yesterday&quot;;\n\n    string str2(&quot;Today&quot;);\n\n    string str3(&quot;Hello&quot;,2); //取c风格字符串 长度为 2 作为初值，即&quot;He&quot;\n\n    string str4(str1, 6); // 始于位置6开始的字符串，即&quot;day&quot;\n\n    string str5(str1,6,1); // 始于6，长度1，即&quot;d&quot;\n\n    string str6(1,&#39;a&#39;); //6个&#39;a&#39;\n\n    // 赋值，交换\n    str1.assign(&quot;hahahaha&quot;); //重新赋值\n\n    swap(str1,str2); //交换两个字符串内容 str1=&quot;Today&quot; str2=&quot;hahahaha&quot;\n\n    // 追加\n    str1 += &quot; we&quot;; // += 可追加 string对象，字符串，字符\n\n    str1.append(&quot; ar&quot;); // append 可追加 string对象，字符串\n\n    str1.push_back(&#39;e&#39;); //push_back 只能追加字符 str1 = &quot;Today we are&quot;\n\n    // 插入\n    str1.insert(0,&quot; family&quot;); //str1 = &quot;Today we are family&quot;\n\n    // 删除\n    str1.erase(2,1); //第2个位置开始， len = 1 个字符\n\n    str1.clear(); //删除全部\n\n    // 访问字符串\n    string s = &quot;asdfgh&quot;;\n\n    cout &lt;&lt; s[1]; // &#39;s&#39;\n\n    cout &lt;&lt; s.at(2); // &#39;d&#39;\n\n    // 查找\n    int position = s.find(&#39;f&#39;,0); // 从0开始查找第一次出现‘f’的坐标\n\n    // 替换\n    s.replace(s.find(&#39;f&#39;),3,&quot;ZZZ&quot;); //替换find的位置处\n    3个字符串为 “ZZZ”\n\n    // 分割\n    getchar();\n\n    return 0;\n\n}\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<font color=\"red\"><big>测试内容</big></font>\n\n\n<p><del>删除线</del></p>\n<p><a href=\"http://zhuzhuyule.xyz\" target=\"_blank\" rel=\"noopener\">链接</a></p>\n<p><img src=\"/2019/01/20/C-梳理笔记/test.jpg\" alt=\"logo\"></p>\n<h1 id=\"C-学习笔记\"><a href=\"#C-学习笔记\" class=\"headerlink\" title=\"C++学习笔记\"></a>C++学习笔记</h1><h2 id=\"类型转换：\"><a href=\"#类型转换：\" class=\"headerlink\" title=\"类型转换：\"></a><strong>类型转换：</strong></h2><ol>\n<li><p>隐式转换： 低类型转换为高类型</p>\n<pre><code>浮点数（直接舍掉小数，不四舍五入） + 整数\n</code></pre></li>\n<li><p>显式转换：</p>\n<pre><code> int **(**z**) = (**int**)** z **= static_cast\\&lt;**int**\\&gt; (**z**)**\n</code></pre></li>\n</ol>\n<p>。。。</p>\n<h3 id=\"数据的输入和输出：信息的流动\"><a href=\"#数据的输入和输出：信息的流动\" class=\"headerlink\" title=\"数据的输入和输出：信息的流动\"></a><strong>数据的输入和输出：信息的流动</strong></h3><ol>\n<li><p>输入：</p>\n</li>\n<li><p>输出：</p>\n</li>\n<li><p>流类库的操纵符：</p>\n</li>\n</ol>\n<h3 id=\"程序控制：\"><a href=\"#程序控制：\" class=\"headerlink\" title=\"程序控制：\"></a><strong>程序控制：</strong></h3><pre><code>    if, while, for, do-while , break, continue, { switch,case,default } ;\n</code></pre><ol>\n<li><p>do-while:</p>\n<pre><code> do 语句      // 先执行一次\n while(表达式)；\n</code></pre></li>\n<li><p>for的范围，遍历容器：</p>\n</li>\n</ol>\n<h3 id=\"自定义类型：\"><a href=\"#自定义类型：\" class=\"headerlink\" title=\"自定义类型：\"></a><strong>自定义类型：</strong></h3><ul>\n<li>类型别名： </li>\n</ul>\n<ol>\n<li><p>typedef double Area, V;</p>\n</li>\n<li><p>using Area = double</p>\n</li>\n</ol>\n<ul>\n<li>枚举类型： 有限的个数</li>\n</ul>\n<p>　　　　不限定作用域： enum 类型名 { 变量值列表}</p>\n<p>　　　　限定作用域：</p>\n<p>　　　注：枚举元素是常量，不能赋值</p>\n<p>　　　　　枚举元素有默认值，默认0,1,2,3,4，声明时可以另外指定</p>\n<p>　　　　　可以进行关系运算</p>\n<ul>\n<li><p>auto类型 和decltyoe类型</p>\n<pre><code>      decltype( float( i )) j = 2;   // j值是2，类型是float;\n\n      auto m = 2.5;  // m 为float;\n</code></pre></li>\n<li><p>结构体( C语言中的)： struct</p>\n<pre><code>      struct MyTimeStruct{   //定义 结构体类型\n          unsigned int year,mouth,day,hour,min,sec;\n      };\n</code></pre></li>\n</ul>\n<h2 id=\"函数：-可重用的功能模块（定义和调用）\"><a href=\"#函数：-可重用的功能模块（定义和调用）\" class=\"headerlink\" title=\"函数： 可重用的功能模块（定义和调用）\"></a><strong>函数： 可重用的功能模块（定义和调用）</strong></h2><h3 id=\"函数定义：\"><a href=\"#函数定义：\" class=\"headerlink\" title=\"函数定义：\"></a><strong>函数定义：</strong></h3><p>　　形参不占用空间，调用时分配；</p>\n<h3 id=\"函数调用：\"><a href=\"#函数调用：\" class=\"headerlink\" title=\"函数调用：\"></a><strong>函数调用：</strong></h3><p>　　调用前要函数声明： int sum<strong>(</strong> int a<strong>,</strong> int b<strong>);</strong></p>\n<p>　　1. 函数的嵌套调用：</p>\n<p>　　2. 函数的递归调用： 直接或者间接调用自身</p>\n<p>计算n!</p>\n<pre><code>    unsigned int fac( unsigned int n){\n        if (n == 0) return 1;\n        return fac( n - 1) * n;\n    }\n</code></pre><p>汉诺塔</p>\n<pre><code>    分析：\n    1.    A 上的n-1个盘子移动到B上（借助C）;\n    2.    A上剩下的盘子移动到C上；\n    3.    B上的n-1个盘子移动到C上（借助A）\n    void move(char src, char obj)\n    {\n        cout &lt;&lt; src &lt;&lt; &quot;---&gt;&gt;&gt;&quot; &lt;&lt; obj &lt;&lt; endl;\n    }\n\n    void hanoi(int n, char src, char medium, char obj)\n    {\n        if(n == 1)\n            move(src, obj);\n        else{\n            hanoi(n-1, src, obj, medium);\n            move(src, obj);\n            hanoi(n-1, medium, src, obj);\n        }\n    }\n</code></pre><h3 id=\"函数的参数：\"><a href=\"#函数的参数：\" class=\"headerlink\" title=\"函数的参数：\"></a><strong>函数的参数：</strong></h3><ol>\n<li><p>形参不占用空间，调用时分配；</p>\n</li>\n<li><p>计算结果返回多个（利用引用）</p>\n</li>\n<li><p>多个参数时，从后开始传</p>\n</li>\n</ol>\n<h3 id=\"引用类型（-amp-）：-必须初始化，该类型不可改变，是其他变量的别名\"><a href=\"#引用类型（-amp-）：-必须初始化，该类型不可改变，是其他变量的别名\" class=\"headerlink\" title=\"引用类型（&amp;）： 必须初始化，该类型不可改变，是其他变量的别名\"></a><strong>引用类型（&amp;）：</strong> 必须初始化，该类型不可改变，是其他变量的别名</h3><pre><code>    int i, j;\n    int &amp; ri = i;  // 定义int引用类型变量 ri, 初始化为i的引用\n</code></pre><h3 id=\"含有可变参数的函数：（两种方法）\"><a href=\"#含有可变参数的函数：（两种方法）\" class=\"headerlink\" title=\"含有可变参数的函数：（两种方法）\"></a><strong>含有可变参数的函数：（两种方法）</strong></h3><ol>\n<li><p>所有实参类型相同：<code>initializer_list&lt;int&gt; li; //类模板, 都是常量</code></p>\n</li>\n<li><p>具体看第九章</p>\n</li>\n<li><p>类型不同：</p>\n</li>\n</ol>\n<h3 id=\"内联函数（inline）：-用函数体内的语句，替换函数调用表达式，编译时完成，类似-define\"><a href=\"#内联函数（inline）：-用函数体内的语句，替换函数调用表达式，编译时完成，类似-define\" class=\"headerlink\" title=\"内联函数（inline）： 用函数体内的语句，替换函数调用表达式，编译时完成，类似 #define\"></a><strong>内联函数（inline）： </strong>用函数体内的语句，替换函数调用表达式，编译时完成，类似 #define</h3><p>声明： <code>inline int calArea(int a){  }</code></p>\n<p>要求： 1. 不能有循环，switch语句 2. 定义在调用之前 3. 不能有异常接口声明</p>\n<h3 id=\"constexpr-函数：（常量表达式函数）\"><a href=\"#constexpr-函数：（常量表达式函数）\" class=\"headerlink\" title=\"constexpr 函数：（常量表达式函数）\"></a>constexpr 函数：（常量表达式函数）</h3><h3 id=\"带默认参数的函数：\"><a href=\"#带默认参数的函数：\" class=\"headerlink\" title=\"带默认参数的函数：\"></a><strong>带默认参数的函数：</strong></h3><pre><code>    int getVa(int length, int weight = 2)\n</code></pre><h3 id=\"函数的重载：（C-多态性的重要机制，编译过程中实现）\"><a href=\"#函数的重载：（C-多态性的重要机制，编译过程中实现）\" class=\"headerlink\" title=\"函数的重载：（C++多态性的重要机制，编译过程中实现）\"></a><strong>函数的重载：</strong>（C++多态性的重要机制，编译过程中实现）</h3><p>函数体同名，参数类型不同/参数个数不同</p>\n<pre><code>    int add(int x, int y);\n\n    float add(float x, float y);\n\n    float add(float x, float y, float z);\n</code></pre><h3 id=\"C-系统函数：\"><a href=\"#C-系统函数：\" class=\"headerlink\" title=\"C++系统函数：\"></a><strong>C++系统函数：</strong></h3><pre><code>    #include &lt;cmath&gt;\n        |_\n        |_\n    #include &lt;cstdlib&gt;\n        |_\n        |_\n    #include &lt;cstdio&gt;\n        |_\n        |_\n    #include &lt;ctime&gt;\n        |_\n        |_\n</code></pre><h2 id=\"类和对象\"><a href=\"#类和对象\" class=\"headerlink\" title=\"类和对象\"></a><strong>类和对象</strong></h2><p>类：构建对象的蓝图，</p>\n<p>对象：由类创建，含有数据和方法</p>\n<p>封装：对数据和操作数据的方法的组合绑定</p>\n<p>继承：在已有类基础上，形成新的类</p>\n<p>多态：</p>\n<p>构造函数：定义对象时，通过构造函数初始化</p>\n<p>析构函数：删除对象时，通过析构函数释放资源</p>\n<h3 id=\"类和对象的定义：\"><a href=\"#类和对象的定义：\" class=\"headerlink\" title=\" 类和对象的定义：\"></a><strong> 类和对象的定义：</strong></h3><p>定义类：</p>\n<pre><code>    class {  //类名称 \n        public:\n            // 公有成员,外部接口\n        private:\n            // 私有成员\n        protected:\n            int hour = 0; // 类内初始化\n            // 保护型成员\n    }\n</code></pre><p>注意：不指定类型，默认为私有；</p>\n<h3 id=\"成员函数：\"><a href=\"#成员函数：\" class=\"headerlink\" title=\"成员函数：\"></a><strong>成员函数：</strong></h3><pre><code>    |_ 内联成员函数： 类内声明或者inline关键字\n\n    |_类外实现：void 类名称::成员函数名称（）{ }\n</code></pre><h3 id=\"构造函数：\"><a href=\"#构造函数：\" class=\"headerlink\" title=\"构造函数：\"></a><strong>构造函数：</strong></h3><ul>\n<li><p>在创建对象时，自动调用来初始化数据</p>\n</li>\n<li><p>与类名相同</p>\n</li>\n<li><p>构造函数有初始化列表</p>\n</li>\n<li><p>格式 类名（string s, lei i）：s(初始值)，i(初始值){ }；</p>\n</li>\n</ul>\n<h3 id=\"委托构造函数：一个构造函数-通过另一个构造函数-初始化\"><a href=\"#委托构造函数：一个构造函数-通过另一个构造函数-初始化\" class=\"headerlink\" title=\"委托构造函数：一个构造函数 通过另一个构造函数 初始化\"></a><strong>委托构造函数：</strong>一个构造函数 通过另一个构造函数 初始化</h3><h3 id=\"复制构造函数：\"><a href=\"#复制构造函数：\" class=\"headerlink\" title=\"复制构造函数：\"></a><strong>复制构造函数：</strong></h3><p>用途：</p>\n<ul>\n<li><p>用存在的对象 去初始化新对象 （通过引用旧的对象）</p>\n</li>\n<li><p>函数f的形参是类的对象，调用f时，将用实参对象初始化形参对象</p>\n</li>\n<li><p>函数g的返回值是类的对象，用return的对象来在主调函数中初始化一个无名对象</p>\n</li>\n</ul>\n<h3 id=\"析构函数：生存期结束，删除清理工作，不能有return，不能有参数\"><a href=\"#析构函数：生存期结束，删除清理工作，不能有return，不能有参数\" class=\"headerlink\" title=\"析构函数：生存期结束，删除清理工作，不能有return，不能有参数\"></a><strong>析构函数：</strong>生存期结束，删除清理工作，不能有return，不能有参数</h3><pre><code>    class 类名{\n\n    public:\n        类名（形参）； // 构造函数\n        类名（const 类名&amp; 旧对象名）；  // 复制构造函数 =delete是不生成\n        ~ 类名（）；\n    }\n</code></pre><blockquote>\n<p>  注：未声明时，编译器自己生成一个默认的</p>\n</blockquote>\n<h3 id=\"前向引用声明：两个类相互引用时，某个类在引用之前就声明\"><a href=\"#前向引用声明：两个类相互引用时，某个类在引用之前就声明\" class=\"headerlink\" title=\"前向引用声明：两个类相互引用时，某个类在引用之前就声明\"></a><strong>前向引用声明：</strong>两个类相互引用时，某个类在引用之前就声明</h3><pre><code>    class A;  //前向引用声明，只是一个标识符，不是万能的\n    class B{\n    public:\n        void A(B b);\n    }\n\n    class A{\n    public：\n        void B（A a）;\n    }\n</code></pre><h3 id=\"结构体：特殊的类，默认是公有的，可以有函数成员\"><a href=\"#结构体：特殊的类，默认是公有的，可以有函数成员\" class=\"headerlink\" title=\"结构体：特殊的类，默认是公有的，可以有函数成员\"></a><strong>结构体：</strong>特殊的类，默认是公有的，可以有函数成员</h3><pre><code>    //公有成员\n        int a;\n    protected:\n        int b;\n    private:\n        int c;\n    };\n</code></pre><h3 id=\"联合体：\"><a href=\"#联合体：\" class=\"headerlink\" title=\"联合体：\"></a><strong>联合体：</strong></h3><p>目的：存储空间的共用，成员不能同时有效，比如某人语文课成绩，只有一种可能；</p>\n<pre><code>    union Mark{ // 成绩的联合体， 只有一个成立\n        char grade;  //等级类的成绩\n        bool pass;  // 是否通过的成绩\n    int percent;  //百分制成绩  }\n</code></pre><h3 id=\"枚举类：\"><a href=\"#枚举类：\" class=\"headerlink\" title=\"枚举类：\"></a><strong>枚举类：</strong></h3><p>enum class 枚举类型名： 底层类型（int）<strong>{</strong> 枚举列表 <strong>};</strong></p>\n<pre><code>//默认 int\n</code></pre><p>优势：</p>\n<ul>\n<li><p>强制作用域 —必须在枚举类 枚举类型名：：枚举值，不同枚举类可以有同名值了</p>\n</li>\n<li><p>转换限制 —枚举对象不能与整型 隐式转换</p>\n</li>\n<li><p>底层类型 —可以指定</p>\n</li>\n</ul>\n<h2 id=\"数据共享和保护：\"><a href=\"#数据共享和保护：\" class=\"headerlink\" title=\"数据共享和保护：\"></a><strong>数据共享和保护：</strong></h2><h3 id=\"作用域分类：\"><a href=\"#作用域分类：\" class=\"headerlink\" title=\"作用域分类：\"></a><strong>作用域分类：</strong></h3><p>函数原型作用域：</p>\n<ul>\n<li>形参的范围在（）内，所以不需要名字也行，int area( int );</li>\n</ul>\n<p>局部作用域</p>\n<ul>\n<li><p>函数{ }内</p>\n</li>\n<li><p>if、for、while { }内</p>\n</li>\n</ul>\n<p>类作用域： 类外访问类的成员</p>\n<ul>\n<li><p>静态成员：通过 对象名.成员名 访问</p>\n</li>\n<li><p>非静态成员：</p>\n</li>\n<li><p>文件作用域</p>\n</li>\n<li><p>命名空间作用域： 10章</p>\n</li>\n</ul>\n<h3 id=\"对象的生存期：\"><a href=\"#对象的生存期：\" class=\"headerlink\" title=\"对象的生存期：\"></a><strong>对象的生存期：</strong></h3><p>静态生存期： 整个程序结束后消失</p>\n<ul>\n<li>函数内的静态对象， 用static ，全局寿命，只局部可见</li>\n</ul>\n<p>动态生存期：</p>\n<ul>\n<li><p>离开作用域后消失</p>\n</li>\n<li><p>下次进函数重新生成对象</p>\n</li>\n</ul>\n<h3 id=\"类的静态数据成员：\"><a href=\"#类的静态数据成员：\" class=\"headerlink\" title=\"类的静态数据成员：\"></a><strong>类的静态数据成员：</strong></h3><ul>\n<li><p>static 声明</p>\n</li>\n<li><p>为该类所有对象共享，具有静态生存期</p>\n</li>\n<li><p>必须在类外定义和初始化，类内声明，用：：指明所属于的类</p>\n</li>\n</ul>\n<p>比如记录 类产生了多少对象；opencv中的Mat对象好像用到了？？？？</p>\n<pre><code>    class base{   \n        public :   \n               static   int   _num;//声明   \n    };   \n    int  base::_num=0;  //真正定义  \n</code></pre><h3 id=\"类的友元：\"><a href=\"#类的友元：\" class=\"headerlink\" title=\"类的友元：\"></a><strong>类的友元：</strong></h3><ul>\n<li><p>破坏数据封装和数据隐藏的机制</p>\n</li>\n<li><p>尽量不用</p>\n</li>\n</ul>\n<h3 id=\"友元函数：\"><a href=\"#友元函数：\" class=\"headerlink\" title=\" 友元函数：\"></a><strong> 友元函数：</strong></h3><ul>\n<li><p>类声明中由关键字 friend 修饰说明的非成员函数</p>\n</li>\n<li><p>可以在其函数体内访问对象的private,protected成员</p>\n</li>\n<li><p>但必须通过对象名：：访问，函数参数为类的引用</p>\n</li>\n<li><h3 id=\"友元类：\"><a href=\"#友元类：\" class=\"headerlink\" title=\" 友元类：\"></a><strong> 友元类：</strong></h3><pre><code>class A{\n    friend B;\n  public:\n    void display(){\n        count &lt;&lt; x &lt;&lt; enld;\n    }\n  private:\n    int x;\n}\n\nclass B{\n  public:\n    void set(int i);\n    void display();\n  private:\n    A a;\n}\n\nvoid B::set(int i){\n    a.x = i;   // B类中改变 A类私有值\n}\nvoid B::display(){\n    a.display()\n}\n</code></pre></li>\n</ul>\n<h3 id=\"共享数据的保护：\"><a href=\"#共享数据的保护：\" class=\"headerlink\" title=\"共享数据的保护：\"></a><strong>共享数据的保护：</strong></h3><h1 id=\"常类型：const\"><a href=\"#常类型：const\" class=\"headerlink\" title=\"常类型：const\"></a><strong>常类型：</strong>const</h1><p>常对象：必须初始化，不可更新</p>\n<pre><code>    class A{\n    }\n    A const a; // a是常对象\n</code></pre><p>常成员：(不可以放在构造函数体内复制，可以在初始化列表中)</p>\n<pre><code>    A：：A(int i):a(i){ }\n</code></pre><ul>\n<li><p>常数据成员：const修饰的</p>\n</li>\n<li><p>静态常数据成员： static const int b;</p>\n</li>\n<li><p>常函数成员（用来处理常对象的函数）</p>\n<ul>\n<li><p>不更新对象的数据成员</p>\n</li>\n<li><p>声明和实现都带const</p>\n</li>\n</ul>\n</li>\n</ul>\n<pre><code>        class A{\n            void f（int a）const;\n        }\n        void A::f(int a) const{  \n        }; // f是常对象函数, 处理常对象\n</code></pre><ul>\n<li>常引用：不可更新</li>\n</ul>\n<p>　　　引用是双向传递的，避免修改原值的方法就是常引用；</p>\n<pre><code>     const A&amp; a;\n</code></pre><ul>\n<li><p>常数组：</p>\n</li>\n<li><p>常指针：</p>\n</li>\n</ul>\n<h3 id=\"多文件结构和预编译命令：\"><a href=\"#多文件结构和预编译命令：\" class=\"headerlink\" title=\"多文件结构和预编译命令：\"></a><strong>多文件结构和预编译命令：</strong></h3><ul>\n<li><p>.h 系统使用</p>\n</li>\n<li><p>.hpp 个人使用(类的声明,函数的声明)</p>\n</li>\n<li><p>.cpp (类的实现，函数的实现)</p>\n<p> <img src=\"/2019/01/20/C-梳理笔记/f5d645ed218d5fa3e753f771b72310fc.png\" alt=\"\"></p>\n</li>\n</ul>\n<h3 id=\"外部变量：\"><a href=\"#外部变量：\" class=\"headerlink\" title=\"外部变量：\"></a><strong>外部变量：</strong></h3><p>文件作用域中定义的变量默认是外部变量，其他文件使用前，extern声明</p>\n<p>将变量和函数限制在编译单元内：namespcae:</p>\n<pre><code>    namespace{ //匿名的命名空间，外部不可调用任何东西\n        int i;\n        void fun(){\n            i++;\n        }\n    }\n</code></pre><h3 id=\"预编译命令：\"><a href=\"#预编译命令：\" class=\"headerlink\" title=\"预编译命令：\"></a><strong>预编译命令：</strong></h3><pre><code>    #include&lt; &gt;  标准方式搜索，从系统目录include\n\n\n    #include”” 先当前目录搜索，没有再标准搜索\n\n\n    #define \n\n\n    #undef 删除有#define的宏\n\n    #if 表达式  // 条件编译指令\n    ---\n    #else\n    ---\n    #endif \n\n\n    #ifndef 标识符\n    ---\n    #else  \n    ---\n    #endif\n</code></pre><h2 id=\"数组，指针与字符串：\"><a href=\"#数组，指针与字符串：\" class=\"headerlink\" title=\"数组，指针与字符串：\"></a><strong>数组，指针与字符串：</strong></h2><h3 id=\"数组：\"><a href=\"#数组：\" class=\"headerlink\" title=\"数组：\"></a><strong>数组：</strong></h3><p>定义： <code>int arr**[**m**][**n**]**…;</code></p>\n<p>　　注：二维数组中 arr[1] 第二行首地址</p>\n<h3 id=\"数组作为函数参数：\"><a href=\"#数组作为函数参数：\" class=\"headerlink\" title=\"数组作为函数参数：\"></a><strong>数组作为函数参数：</strong></h3><p>　　数组名做参数： 形参，实参都是数组名，传入的是地址</p>\n<h3 id=\"对象数组：\"><a href=\"#对象数组：\" class=\"headerlink\" title=\"对象数组：\"></a><strong>对象数组：</strong></h3><p>　　定义：类名 数组名[对象元素个数]</p>\n<p>　　访问：数组名[下标].成员名</p>\n<h3 id=\"基于范围的for循环：c-11-自动遍历整个容器\"><a href=\"#基于范围的for循环：c-11-自动遍历整个容器\" class=\"headerlink\" title=\"基于范围的for循环：c++11,自动遍历整个容器\"></a><strong>基于范围的for循环：</strong>c++11,自动遍历整个容器</h3><pre><code>  for( auto x : 容器){ } for( auto &amp;x : 容器){ }\n</code></pre><p>注意：</p>\n<ul>\n<li><p>auto &amp;x是元素引用，auto x是元素的副本</p>\n</li>\n<li><p>auto推导出的类型是容器中的值类型</p>\n</li>\n<li><p>：冒号后的表达式只执行一次</p>\n</li>\n</ul>\n<h3 id=\"指针：\"><a href=\"#指针：\" class=\"headerlink\" title=\"指针：\"></a><strong>指针：</strong></h3><h3 id=\"定义：\"><a href=\"#定义：\" class=\"headerlink\" title=\"定义：\"></a><strong>定义：</strong></h3><pre><code>    static int i;\n\n    static int * p = &amp;I;\n</code></pre><h3 id=\"指针的初始化和赋值：\"><a href=\"#指针的初始化和赋值：\" class=\"headerlink\" title=\"指针的初始化和赋值：\"></a><strong>指针的初始化和赋值：</strong></h3><h3 id=\"指针的算术运算，关系运算：\"><a href=\"#指针的算术运算，关系运算：\" class=\"headerlink\" title=\"指针的算术运算，关系运算：\"></a><strong>指针的算术运算，关系运算：</strong></h3><h3 id=\"指针数组：\"><a href=\"#指针数组：\" class=\"headerlink\" title=\"指针数组：\"></a><strong>指针数组：</strong></h3><pre><code>    类名  *p[2];\n</code></pre><h3 id=\"指向数组的指针：\"><a href=\"#指向数组的指针：\" class=\"headerlink\" title=\"指向数组的指针：\"></a><strong>指向数组的指针：</strong></h3><pre><code>    int **p; 指向二维数组的指针\n</code></pre><h3 id=\"指针与函数：\"><a href=\"#指针与函数：\" class=\"headerlink\" title=\"指针与函数：\"></a><strong>指针与函数：</strong></h3><ul>\n<li><p>指针做参数：大批量数据提高效率</p>\n</li>\n<li><p>指针类型的函数：返回类型是指针</p>\n<pre><code>  int * function(int i){return 全局或者静态的 }；// 不能返回非静态局部变量\n</code></pre></li>\n<li><p>指向函数的指针：实现函数回调的功能</p>\n</li>\n</ul>\n<blockquote>\n<p>  定义： 数据类型 (*f)(参数表);</p>\n<p>  数据类型：返回值</p>\n</blockquote>\n<ul>\n<li>对象指针：</li>\n</ul>\n<blockquote>\n<p>  定义： 类名 *对象指针名 = &amp; 对象；</p>\n<p>  访问对象： 对象指针名->成员名</p>\n</blockquote>\n<p>（*对象指针名）.成员名</p>\n<ul>\n<li><p>this 指针：成员函数的一个隐士参数，初始化为对象的地址，不可改变</p>\n</li>\n<li><p>隐含于类的每个非静态成员函数中</p>\n</li>\n<li><p>指出成员函数所操作的当前的对象</p>\n</li>\n<li><p>*this 是当前对象地址</p>\n</li>\n</ul>\n<h3 id=\"动态内存分配：\"><a href=\"#动态内存分配：\" class=\"headerlink\" title=\"动态内存分配：\"></a><strong>动态内存分配：</strong></h3><p>new<strong> 类型名 </strong>(<strong>初始化列表</strong>) // 返回首字节地址</p>\n<p>delete 指针p //p一直在，删除的只是p指向的对象申请的空间</p>\n<p>动态数组：<br>new 类型名[数组长度]</p>\n<p>delete[] 数组首地址p指针</p>\n<h3 id=\"智能指针：C-11\"><a href=\"#智能指针：C-11\" class=\"headerlink\" title=\"智能指针：C++11\"></a><strong>智能指针：</strong>C++11</h3><h3 id=\"内存管理\"><a href=\"#内存管理\" class=\"headerlink\" title=\"内存管理\"></a><strong>内存管理</strong></h3><ul>\n<li><p>unique_ptr:</p>\n<ul>\n<li>不允许多个指针共享资源，标准库中move可以转移指针，但原来指针会失效</li>\n</ul>\n</li>\n<li><p>shared_ptr:</p>\n<ul>\n<li>多指针共享</li>\n</ul>\n</li>\n<li><p>weak_ptr:</p>\n<ul>\n<li>可复制共享</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>  Vector对象：类模板</p>\n</blockquote>\n<p>优势：</p>\n<ul>\n<li><p>封装任何形式的动态数组，自动创建，删除</p>\n</li>\n<li><p>下标越界检查</p>\n</li>\n</ul>\n<p>定义： vector &lt;元素类型&gt; object（长度）</p>\n<ul>\n<li><p><code>object.begin()  object.end()  object.size()</code></p>\n</li>\n<li><p>auto 遍历vector <code>for(auto e: object);</code></p>\n</li>\n</ul>\n<h3 id=\"对象的复制和移动：\"><a href=\"#对象的复制和移动：\" class=\"headerlink\" title=\"对象的复制和移动：\"></a><strong>对象的复制和移动：</strong></h3><ul>\n<li><p>浅层复制和深层复制：复制对象用到复制构造函数，默认的复制构造只传递了指针，两个变量指向同一块内存，释放其中一个，再释放第二个会出错；</p>\n<ul>\n<li><p>浅层：实现对象间数据一一对应的复制，但两个对象指向同一内存</p>\n</li>\n<li><p>深层：当对象成员是指针类型，应该对指针所指对象进行复制。</p>\n</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>  类名<strong>::</strong>类名<strong>(</strong>const 类名<strong>&amp;</strong> v<strong>){</strong></p>\n<p>  size <strong>=</strong> v<strong>.</strong>size<strong>;</strong></p>\n<p>  data_ptr <strong>= new</strong> Ponit<strong>[</strong>size<strong>];</strong></p>\n<p>  <strong>for(</strong>int i<strong>=</strong>0<strong>;</strong> i <strong>\\&lt;</strong> size<strong>; ++</strong>i<strong>){</strong></p>\n<p>  data_ptr<strong>[</strong>i<strong>] =</strong> v<strong>.</strong>data_ptr<strong>[</strong>i<strong>];</strong></p>\n<p>  <strong>}</strong></p>\n<p>  <strong>}</strong></p>\n</blockquote>\n<ul>\n<li><p>移动构造：C++11,省去了构造和删除临时对象的过程</p>\n<p><img src=\"/2019/01/20/C-梳理笔记/8c3092d99bcdba78edeb2d8123270ffe.png\" alt=\"\"></p>\n</li>\n</ul>\n<blockquote>\n<p>  class_name<strong>(</strong>class_name <strong>&amp;&amp;</strong>old<strong>)::</strong>xptr<strong>(</strong>old<strong>.</strong>xptr<strong>){</strong></p>\n<p>  n<strong>.</strong>xptr <strong>= NULL;</strong> // 原来的指针清空</p>\n<p>  <strong>}</strong></p>\n</blockquote>\n<h3 id=\"C风格字符串：字符数组\"><a href=\"#C风格字符串：字符数组\" class=\"headerlink\" title=\"C风格字符串：字符数组\"></a><strong>C风格字符串：</strong>字符数组</h3><h3 id=\"string类：\"><a href=\"#string类：\" class=\"headerlink\" title=\"string类：\"></a><strong>string类：</strong></h3><p>常用构造函数：</p>\n<ul>\n<li><p>string(); //默认构造，长度为0</p>\n<ul>\n<li>string s1<strong>;</strong></li>\n</ul>\n</li>\n<li><p>string(const char *s) //指针s所指向的字符串常量初始化该对象</p>\n<pre><code>string s2 = “abc”;\n\nstring(const string &amp;rhs) //复制构造函数\n\nstring s3 = s2;\n</code></pre></li>\n</ul>\n<p>访问：下标访问</p>\n<p>整行字符串的输入： cin 被空格隔开</p>\n<p>getline(cin,s2); //包含#include\\<string\\></string\\></p>\n<p>getline(cin,s2,’,’);</p>\n<h2 id=\"继承和派生：-充分利用原有的\"><a href=\"#继承和派生：-充分利用原有的\" class=\"headerlink\" title=\"继承和派生： 充分利用原有的\"></a><strong>继承和派生：</strong> 充分利用原有的</h2><p>继承：保持已有类的特征来构造新类</p>\n<p>派生：在已有类基础上新增自己的特性</p>\n<p>基类：父类</p>\n<p>派生类：子类</p>\n<p>直接基类和间接基类</p>\n<p>单继承：</p>\n<pre><code>class 派生类名：继承方式 基类名{  //继承方式，\n    成员声明；//新增成员的声明\n}\n</code></pre><p>多继承：</p>\n<pre><code>class 派生类名：继承方式1 基类1，继承方式2 基类2{\n    成员声明；\n}\n</code></pre><h3 id=\"继承的方式：\"><a href=\"#继承的方式：\" class=\"headerlink\" title=\"继承的方式：\"></a><strong>继承的方式：</strong></h3><p>控制：派生类对基类成员的访问权限</p>\n<ul>\n<li>公有继承 public</li>\n</ul>\n<blockquote>\n<p>  基类中的pubilc和protected访问属性在派生类中不变</p>\n<p>  基类的pravate不可被对象直接访问</p>\n</blockquote>\n<ul>\n<li><p>私有继承 ：内部可以访问基类的公有和保护成员，但是其对象不再可以访问</p>\n</li>\n<li><p>保护继承 ：基类的公有和保护，到这都成了保护成员，类内可以访问，但对象不能</p>\n</li>\n</ul>\n<p>派生类的构成：</p>\n<ul>\n<li><p>吸收基类成员</p>\n</li>\n<li><p>改造基类成员</p>\n<ul>\n<li>增加同名成员，基类成员被覆盖（重新定义继承的成员函数必须用虚函数）</li>\n</ul>\n</li>\n<li><p>添加新成员</p>\n</li>\n</ul>\n<h3 id=\"类型转换：-1\"><a href=\"#类型转换：-1\" class=\"headerlink\" title=\"类型转换：\"></a><strong>类型转换：</strong></h3><p>基类和派生类之间：</p>\n<p>派生类的对象可以隐含转换为基类对象；</p>\n<p>派生类的对象可以初始化基类的引用；</p>\n<p>派生类的指针可以隐含转换为基类的指针；</p>\n<h3 id=\"派生类的构造函数：\"><a href=\"#派生类的构造函数：\" class=\"headerlink\" title=\"派生类的构造函数：\"></a><strong>派生类的构造函数：</strong></h3><p>默认情况下，基类的构造函数不被继承，派生类需要自己构造</p>\n<p>c++11，using语句继承基类构造函数</p>\n<h3 id=\"派生类的复制构造函数：\"><a href=\"#派生类的复制构造函数：\" class=\"headerlink\" title=\"派生类的复制构造函数：\"></a><strong>派生类的复制构造函数：</strong></h3><h3 id=\"派生类的析构函数：\"><a href=\"#派生类的析构函数：\" class=\"headerlink\" title=\"派生类的析构函数：\"></a><strong>派生类的析构函数：</strong></h3><h3 id=\"虚基类：\"><a href=\"#虚基类：\" class=\"headerlink\" title=\"虚基类：\"></a><strong>虚基类：</strong></h3><h2 id=\"多态性\"><a href=\"#多态性\" class=\"headerlink\" title=\"多态性\"></a><strong>多态性</strong></h2><h3 id=\"运算符重载：\"><a href=\"#运算符重载：\" class=\"headerlink\" title=\"运算符重载：\"></a><strong>运算符重载：</strong></h3><pre><code>//双目运算符\n函数类型 operator 运算符（参数）  \n{\n    // 参数个数 = 原操作数个数 - 1\n}\n//前置单目运算符，返回引用所以可以当左值\n函数类型 &amp; operator ++（无参数）  \n{\n    return * this;\n}\n//后置单目运算符，\n函数类型 operator ++（参数为int类型）  \n{\n    old = *this;\n    ++(*this);  //调用的前置\n    return old;\n}\n</code></pre><ul>\n<li>重载为非成员函数：</li>\n</ul>\n<ol>\n<li><p>列出所有操作数</p>\n</li>\n<li><p>至少有一个自定义类型参数</p>\n</li>\n<li><p>后置单目运算，参数要增加int,但不用写形参名</p>\n</li>\n<li><p>要操作某类对象的私有成员，则可声明为该类的友元函数</p>\n</li>\n</ol>\n<h3 id=\"虚函数：virtual改造基类成员，实现动态绑定；必须是非静态成员\"><a href=\"#虚函数：virtual改造基类成员，实现动态绑定；必须是非静态成员\" class=\"headerlink\" title=\"虚函数：virtual改造基类成员，实现动态绑定；必须是非静态成员\"></a><strong>虚函数：</strong>virtual改造基类成员，实现动态绑定；必须是非静态成员</h3><blockquote>\n<p>  原理：编译时先不确定和哪个类的成员对应，在程序运行时刻，再对应；</p>\n</blockquote>\n<pre><code>#include &lt;iostream&gt;\nusing namespace std;\nclass Base1{\npublic:\n    virtual void display() const; //虚函数，不要用内联\n};\n\nvoid Base1::display() const{\n    cout &lt;&lt; &quot;Base1 &quot; &lt;&lt; endl;\n}\n\nclass Base2:public Base1{\npublic:\n    virtual void display() const;\n}\nvoid Base2::display() const{\n    cout &lt;&lt; &quot;Base2&quot; &lt;&lt; endl;\n}\n</code></pre><h3 id=\"虚析构函数：打算通过基类指针调用某一个对象的析构函数（执行delete）\"><a href=\"#虚析构函数：打算通过基类指针调用某一个对象的析构函数（执行delete）\" class=\"headerlink\" title=\"虚析构函数：打算通过基类指针调用某一个对象的析构函数（执行delete）\"></a><strong>虚析构函数：</strong>打算通过基类指针调用某一个对象的析构函数（执行delete）</h3><h3 id=\"虚表和动态绑定：\"><a href=\"#虚表和动态绑定：\" class=\"headerlink\" title=\"虚表和动态绑定：\"></a><strong>虚表和动态绑定：</strong></h3><blockquote>\n<p>  虚表：</p>\n</blockquote>\n<ul>\n<li><p>每个多态类都有虚表；</p>\n</li>\n<li><p>存放各个数函数的入口地址；</p>\n</li>\n<li><p>每个对象有指向当前类的虚表的指针（虚指针vptr）；</p>\n</li>\n</ul>\n<blockquote>\n<p>  动态绑定：</p>\n</blockquote>\n<ul>\n<li>构造函数为对象的虚指针赋值</li>\n</ul>\n<h3 id=\"抽象类：含有纯虚函数的类-不能直接定义对象\"><a href=\"#抽象类：含有纯虚函数的类-不能直接定义对象\" class=\"headerlink\" title=\"抽象类：含有纯虚函数的类,不能直接定义对象\"></a><strong>抽象类：</strong>含有纯虚函数的类,不能直接定义对象</h3><blockquote>\n<p>  纯虚函数：</p>\n<p>  基类中声明的虚函数，在基类中没有定义具体的操作，要求在派生类中根据实际需求完</p>\n<p>  成自己的版本：</p>\n</blockquote>\n<pre><code>virtual 函数类型 函数名**(**参数名**) =** 0**;**\n</code></pre><h3 id=\"override-和-final-C-11\"><a href=\"#override-和-final-C-11\" class=\"headerlink\" title=\"override 和 final :C++11\"></a><strong>override 和 final :</strong>C++11</h3><p>override声明的函数，必须在基类中找到原型；</p>\n<p>final 不允许继承或者覆盖；</p>\n<h2 id=\"模板\"><a href=\"#模板\" class=\"headerlink\" title=\"模板\"></a><strong>模板</strong></h2><h3 id=\"函数魔板：整数和浮点数求绝对值，需要多次重载函数，但是用函数模板，只需要设计通用功能；\"><a href=\"#函数魔板：整数和浮点数求绝对值，需要多次重载函数，但是用函数模板，只需要设计通用功能；\" class=\"headerlink\" title=\"函数魔板：整数和浮点数求绝对值，需要多次重载函数，但是用函数模板，只需要设计通用功能；\"></a><strong>函数魔板：</strong>整数和浮点数求绝对值，需要多次重载函数，但是用函数模板，只需要设计通用功能；</h3><p>template\\&lt;模板参数表> // 类型：class或者typename 常量：</p>\n<p>函数定义</p>\n<pre><code>template&lt;typename T&gt;\nT abs(T x){\n    return x&lt;0?-x:x;\n}\n</code></pre><h3 id=\"类模板：\"><a href=\"#类模板：\" class=\"headerlink\" title=\"类模板：\"></a><strong>类模板：</strong></h3><pre><code>template&lt;模板参数表&gt;\nclass 类名{\n    类成员声明;\n}\n\n//类成员定义\ntemplate &lt;模板参数表&gt;\n类型名  类名&lt;模板参数标识符列表&gt; :: 函数名(参数表)\n{\n\n}\n</code></pre><h3 id=\"线性群体：按位置顺序有序排列\"><a href=\"#线性群体：按位置顺序有序排列\" class=\"headerlink\" title=\"线性群体：按位置顺序有序排列\"></a><strong>线性群体：</strong>按位置顺序有序排列</h3><p>直接访问：</p>\n<p>数组类模板：</p>\n<p>索引访问：</p>\n<p>顺序访问：</p>\n<p>链表类和结点类模板：</p>\n<p>单链表：每个结点包括数据和指针，只有一个指向后续结点的称为单链表；</p>\n<p><img src=\"/2019/01/20/C-梳理笔记/9167a427f849e864c5d630d0c0bc3163.png\" alt=\"\"></p>\n<p>单链表结点类模板：</p>\n<pre><code>template &lt;class T&gt;\nclass Node{\n    private:\n        Node&lt;T&gt; *next;\n    public:\n        T data; \n        Node(const T&amp;item,Node&lt;T&gt;* next = 0);  //构造函数\n    void insertAfter(Node&lt;T&gt; *p); //插入\n    Node&lt;T&gt; *deleteAfter();  //删除\n    Node&lt;T&gt; *nextNode() const; \n}\n\ntemplate &lt;class T&gt;\nvoid Node&lt;T&gt;::insertAfter(Node&lt;T&gt; *p){  // *p是要插入的结点\n// p节点的指针指向当前节点的后续结点\n    p-&gt;next = next; // next是原链表待插入位置的结点的指针\n    next = p;  \n}\ntemplate &lt;class T&gt;\nNode&lt;T&gt; *deleteAfter(){\n    Node&lt;T&gt; * tempPtr = next;\n    if (next == NULL)  //判断是否是删除最后的元素\n        return 0;\n    next = tempPtr = next;\n    return tempPtr;\n}\n</code></pre><blockquote>\n<p>  插入：</p>\n</blockquote>\n<p><img src=\"/2019/01/20/C-梳理笔记/85d072d9c8a8366378b00b9af8ca4920.png\" alt=\"\"></p>\n<blockquote>\n<p>  头插法：可以当队列</p>\n<p>  尾插法：栈</p>\n<p>  删除：</p>\n</blockquote>\n<p><img src=\"/2019/01/20/C-梳理笔记/ffdd5c0226d2a3f9a7833379eb0ebf90.png\" alt=\"\"></p>\n<p>待查询：</p>\n<p>explicit关键字</p>\n<p>构造函数 explicit可以抑制内置类型隐式转换</p>\n<h2 id=\"泛型设计\"><a href=\"#泛型设计\" class=\"headerlink\" title=\"泛型设计\"></a><strong>泛型设计</strong></h2><p>基本概念：</p>\n<p>编写不依赖具体数据类型的程序，通用的；</p>\n<p>STL简介：(Standard Template Library)</p>\n<p>C++ string类库入门：</p>\n<pre><code>#include &lt;iostream&gt;\n\n#include &lt;string&gt;\n\nusing namespace std;\n\nint main()\n{\n\n    // 构造函数：\n    string str1 = &quot;Yesterday&quot;;\n\n    string str2(&quot;Today&quot;);\n\n    string str3(&quot;Hello&quot;,2); //取c风格字符串 长度为 2 作为初值，即&quot;He&quot;\n\n    string str4(str1, 6); // 始于位置6开始的字符串，即&quot;day&quot;\n\n    string str5(str1,6,1); // 始于6，长度1，即&quot;d&quot;\n\n    string str6(1,&#39;a&#39;); //6个&#39;a&#39;\n\n    // 赋值，交换\n    str1.assign(&quot;hahahaha&quot;); //重新赋值\n\n    swap(str1,str2); //交换两个字符串内容 str1=&quot;Today&quot; str2=&quot;hahahaha&quot;\n\n    // 追加\n    str1 += &quot; we&quot;; // += 可追加 string对象，字符串，字符\n\n    str1.append(&quot; ar&quot;); // append 可追加 string对象，字符串\n\n    str1.push_back(&#39;e&#39;); //push_back 只能追加字符 str1 = &quot;Today we are&quot;\n\n    // 插入\n    str1.insert(0,&quot; family&quot;); //str1 = &quot;Today we are family&quot;\n\n    // 删除\n    str1.erase(2,1); //第2个位置开始， len = 1 个字符\n\n    str1.clear(); //删除全部\n\n    // 访问字符串\n    string s = &quot;asdfgh&quot;;\n\n    cout &lt;&lt; s[1]; // &#39;s&#39;\n\n    cout &lt;&lt; s.at(2); // &#39;d&#39;\n\n    // 查找\n    int position = s.find(&#39;f&#39;,0); // 从0开始查找第一次出现‘f’的坐标\n\n    // 替换\n    s.replace(s.find(&#39;f&#39;),3,&quot;ZZZ&quot;); //替换find的位置处\n    3个字符串为 “ZZZ”\n\n    // 分割\n    getchar();\n\n    return 0;\n\n}\n</code></pre>"},{"layout":"w","title":"pandas-2索引和选择数据","mathjax":true,"date":"2019-07-24T23:01:01.000Z","_content":"# pandas -2 索引和选择数据\n\n> 对于一种数据结构,最基本的操作就应该是增删改查了。\n\n## 1. 行列选择\n行选择和列选择有许多方法，很容易记混，常用的要记住。\n主要方法有三种： `iloc`, `loc`, `[]`\n\n### 行选择\n\n- 切片 \n```\n    // 切片\n    df[a:b]\n    \n    // 隔1行选择\n    df[::2]\n```\n\n- 指定位置\n\n  ` df.iloc[1, 1]`\n  \n  ` df.iloc[1:10, 2:3]`\n\n  ` df.iloc[1:10]['Price']`\n  \n- 指定索引\n\n  `df.loc[\"index1\", \"index2\"]`\n- 按照条件查找\n\n  ` df[( df[\"row2\"] == 1) & (df[\"row2\"] == \"null\")]`\n  \n  ` df.loc[( df[\"row2\"] == 1) & (df[\"row2\"] == \"null\")]`\n\n  \n### 列选择\n\n- 通过列标签选择单列\n\n    `df[\"price\"]`\n  \n- 通过列标签选择多列\n\n   `df[[\"price\", \"time\"]]`\n   \n- 通过列索引,选择前3列\n\n  `df.iloc[:, :3]` \n\n### 行列选择\n\n  `df.loc[:,  [\"price\"]]`\n\n  \n  `df.iloc[a:b]['Price']`\n  \n### 随机采样行或者列\n\n```\n    s.sample(frac=0.5)\n    // 参数\n    // 默认选择行，n = 行数，  frac = 比例\n    // replace: 默认False 无放回采样\n    // weights: 样本采样权重\n    // axis:  默认=0 行,  =1 列\n    // random_state=2\n    \n    \n```\n  \n  \n## 2. 行的增删改查\n\n### 增加\n\n> 单列\n\n```\n// 末尾增加\n   df[\"new col\"] = None\n   \n// 指定位置增加，在2列后\n   df.insert(2,'city') \n```\n   \n> 多列\n\n   ` pd.concat([df, pd.DataFrame(columns=[\"C\",\"D\"])])`\n   \n> 单行（待验证）\n\n```\n// loc 添加\n  df.loc[‘5‘] = [3, 3, 3, 3]\n    \n// set_value 添加\n  df.set_value(‘5‘, df.columns, [3,3,3,3], takeable=False) \n```\n> 多行\n\n多行相当于合并两张表了,可以参考(merge,concat)[方法](https://note.youdao.com/)。\n\n\n### 删除\n\n> 列\n\n```\n// del 方法\n   def df[\"col_name\"]\n\n//根据列名 drop 方法\n   df.drop([\"b\", \"c\"], axis=1,inplace = True)\naxis = 1 列\naxis = 0 行\n\n// 根据列号 drop 方法\n   df.drop(df.columns[[1,2]], axis=1, inplace=True)\n```\n\n> 行\n\n```\n// 根据索引 删除行\n   df = df.drop([1, 2])\n\n// 根据value 删除行\n   df = df[~df[\"col\"].isin(5,9)\n    \n```\n\n### 修改与查找\n\n> 单值修改和查找时, 参考选择行列方法。\n\n> 多值查找时，\n\n#### 按条件查找\n\n ` df_train[( df_train[\"row\"] == 1) &( == \"null\")]`\n \n#### query 查找\n\n `df.query('(a < b) & (b < c)')`\n \n#### 替换\n\n> 单个替换，inplace = True 覆盖源文件\n\n  `df.replace(to_replace, value, inplace = True)`\n  \n> 多值替换---字典\n\n  `df.replace({\"A\":\"B\",  29:100})`\n  \n> 按条件替换\n\n  `df.where(df > 0, -df, inplace=True)`\n  \n#### 交换两列的位置\n\n```\n    df[['B', 'A']] = df[['A', 'B']]\n\n```\n\n\n\n\n\n\n\n","source":"_posts/pandas-2索引和选择数据.md","raw":"---\nlayout: w\ntitle: pandas-2索引和选择数据\nmathjax: true\ndate: 2019-07-25 07:01:01\ncategories: pandas系列教程\ntags: pandas\n---\n# pandas -2 索引和选择数据\n\n> 对于一种数据结构,最基本的操作就应该是增删改查了。\n\n## 1. 行列选择\n行选择和列选择有许多方法，很容易记混，常用的要记住。\n主要方法有三种： `iloc`, `loc`, `[]`\n\n### 行选择\n\n- 切片 \n```\n    // 切片\n    df[a:b]\n    \n    // 隔1行选择\n    df[::2]\n```\n\n- 指定位置\n\n  ` df.iloc[1, 1]`\n  \n  ` df.iloc[1:10, 2:3]`\n\n  ` df.iloc[1:10]['Price']`\n  \n- 指定索引\n\n  `df.loc[\"index1\", \"index2\"]`\n- 按照条件查找\n\n  ` df[( df[\"row2\"] == 1) & (df[\"row2\"] == \"null\")]`\n  \n  ` df.loc[( df[\"row2\"] == 1) & (df[\"row2\"] == \"null\")]`\n\n  \n### 列选择\n\n- 通过列标签选择单列\n\n    `df[\"price\"]`\n  \n- 通过列标签选择多列\n\n   `df[[\"price\", \"time\"]]`\n   \n- 通过列索引,选择前3列\n\n  `df.iloc[:, :3]` \n\n### 行列选择\n\n  `df.loc[:,  [\"price\"]]`\n\n  \n  `df.iloc[a:b]['Price']`\n  \n### 随机采样行或者列\n\n```\n    s.sample(frac=0.5)\n    // 参数\n    // 默认选择行，n = 行数，  frac = 比例\n    // replace: 默认False 无放回采样\n    // weights: 样本采样权重\n    // axis:  默认=0 行,  =1 列\n    // random_state=2\n    \n    \n```\n  \n  \n## 2. 行的增删改查\n\n### 增加\n\n> 单列\n\n```\n// 末尾增加\n   df[\"new col\"] = None\n   \n// 指定位置增加，在2列后\n   df.insert(2,'city') \n```\n   \n> 多列\n\n   ` pd.concat([df, pd.DataFrame(columns=[\"C\",\"D\"])])`\n   \n> 单行（待验证）\n\n```\n// loc 添加\n  df.loc[‘5‘] = [3, 3, 3, 3]\n    \n// set_value 添加\n  df.set_value(‘5‘, df.columns, [3,3,3,3], takeable=False) \n```\n> 多行\n\n多行相当于合并两张表了,可以参考(merge,concat)[方法](https://note.youdao.com/)。\n\n\n### 删除\n\n> 列\n\n```\n// del 方法\n   def df[\"col_name\"]\n\n//根据列名 drop 方法\n   df.drop([\"b\", \"c\"], axis=1,inplace = True)\naxis = 1 列\naxis = 0 行\n\n// 根据列号 drop 方法\n   df.drop(df.columns[[1,2]], axis=1, inplace=True)\n```\n\n> 行\n\n```\n// 根据索引 删除行\n   df = df.drop([1, 2])\n\n// 根据value 删除行\n   df = df[~df[\"col\"].isin(5,9)\n    \n```\n\n### 修改与查找\n\n> 单值修改和查找时, 参考选择行列方法。\n\n> 多值查找时，\n\n#### 按条件查找\n\n ` df_train[( df_train[\"row\"] == 1) &( == \"null\")]`\n \n#### query 查找\n\n `df.query('(a < b) & (b < c)')`\n \n#### 替换\n\n> 单个替换，inplace = True 覆盖源文件\n\n  `df.replace(to_replace, value, inplace = True)`\n  \n> 多值替换---字典\n\n  `df.replace({\"A\":\"B\",  29:100})`\n  \n> 按条件替换\n\n  `df.where(df > 0, -df, inplace=True)`\n  \n#### 交换两列的位置\n\n```\n    df[['B', 'A']] = df[['A', 'B']]\n\n```\n\n\n\n\n\n\n\n","slug":"pandas-2索引和选择数据","published":1,"updated":"2019-09-11T06:18:41.751Z","comments":1,"photos":[],"link":"","_id":"ck0evlzot0000q8plb1cg2ev3","content":"<h1 id=\"pandas-2-索引和选择数据\"><a href=\"#pandas-2-索引和选择数据\" class=\"headerlink\" title=\"pandas -2 索引和选择数据\"></a>pandas -2 索引和选择数据</h1><blockquote>\n<p>对于一种数据结构,最基本的操作就应该是增删改查了。</p>\n</blockquote>\n<h2 id=\"1-行列选择\"><a href=\"#1-行列选择\" class=\"headerlink\" title=\"1. 行列选择\"></a>1. 行列选择</h2><p>行选择和列选择有许多方法，很容易记混，常用的要记住。<br>主要方法有三种： <code>iloc</code>, <code>loc</code>, <code>[]</code></p>\n<h3 id=\"行选择\"><a href=\"#行选择\" class=\"headerlink\" title=\"行选择\"></a>行选择</h3><ul>\n<li><p>切片 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 切片</span><br><span class=\"line\">df[a:b]</span><br><span class=\"line\"></span><br><span class=\"line\">// 隔1行选择</span><br><span class=\"line\">df[::2]</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>指定位置</p>\n<p><code>df.iloc[1, 1]</code></p>\n<p><code>df.iloc[1:10, 2:3]</code></p>\n<p><code>df.iloc[1:10][&#39;Price&#39;]</code></p>\n</li>\n<li><p>指定索引</p>\n<p><code>df.loc[&quot;index1&quot;, &quot;index2&quot;]</code></p>\n</li>\n<li><p>按照条件查找</p>\n<p><code>df[( df[&quot;row2&quot;] == 1) &amp; (df[&quot;row2&quot;] == &quot;null&quot;)]</code></p>\n<p><code>df.loc[( df[&quot;row2&quot;] == 1) &amp; (df[&quot;row2&quot;] == &quot;null&quot;)]</code></p>\n</li>\n</ul>\n<h3 id=\"列选择\"><a href=\"#列选择\" class=\"headerlink\" title=\"列选择\"></a>列选择</h3><ul>\n<li><p>通过列标签选择单列</p>\n<p>  <code>df[&quot;price&quot;]</code></p>\n</li>\n<li><p>通过列标签选择多列</p>\n<p> <code>df[[&quot;price&quot;, &quot;time&quot;]]</code></p>\n</li>\n<li><p>通过列索引,选择前3列</p>\n<p><code>df.iloc[:, :3]</code> </p>\n</li>\n</ul>\n<h3 id=\"行列选择\"><a href=\"#行列选择\" class=\"headerlink\" title=\"行列选择\"></a>行列选择</h3><p>  <code>df.loc[:,  [&quot;price&quot;]]</code></p>\n<p>  <code>df.iloc[a:b][&#39;Price&#39;]</code></p>\n<h3 id=\"随机采样行或者列\"><a href=\"#随机采样行或者列\" class=\"headerlink\" title=\"随机采样行或者列\"></a>随机采样行或者列</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">s.sample(frac=0.5)</span><br><span class=\"line\">// 参数</span><br><span class=\"line\">// 默认选择行，n = 行数，  frac = 比例</span><br><span class=\"line\">// replace: 默认False 无放回采样</span><br><span class=\"line\">// weights: 样本采样权重</span><br><span class=\"line\">// axis:  默认=0 行,  =1 列</span><br><span class=\"line\">// random_state=2</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-行的增删改查\"><a href=\"#2-行的增删改查\" class=\"headerlink\" title=\"2. 行的增删改查\"></a>2. 行的增删改查</h2><h3 id=\"增加\"><a href=\"#增加\" class=\"headerlink\" title=\"增加\"></a>增加</h3><blockquote>\n<p>单列</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 末尾增加</span><br><span class=\"line\">   df[&quot;new col&quot;] = None</span><br><span class=\"line\">   </span><br><span class=\"line\">// 指定位置增加，在2列后</span><br><span class=\"line\">   df.insert(2,&apos;city&apos;)</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>多列</p>\n</blockquote>\n<p>   <code>pd.concat([df, pd.DataFrame(columns=[&quot;C&quot;,&quot;D&quot;])])</code></p>\n<blockquote>\n<p>单行（待验证）</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// loc 添加</span><br><span class=\"line\">  df.loc[‘5‘] = [3, 3, 3, 3]</span><br><span class=\"line\">    </span><br><span class=\"line\">// set_value 添加</span><br><span class=\"line\">  df.set_value(‘5‘, df.columns, [3,3,3,3], takeable=False)</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>多行</p>\n</blockquote>\n<p>多行相当于合并两张表了,可以参考(merge,concat)<a href=\"https://note.youdao.com/\" target=\"_blank\" rel=\"noopener\">方法</a>。</p>\n<h3 id=\"删除\"><a href=\"#删除\" class=\"headerlink\" title=\"删除\"></a>删除</h3><blockquote>\n<p>列</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// del 方法</span><br><span class=\"line\">   def df[&quot;col_name&quot;]</span><br><span class=\"line\"></span><br><span class=\"line\">//根据列名 drop 方法</span><br><span class=\"line\">   df.drop([&quot;b&quot;, &quot;c&quot;], axis=1,inplace = True)</span><br><span class=\"line\">axis = 1 列</span><br><span class=\"line\">axis = 0 行</span><br><span class=\"line\"></span><br><span class=\"line\">// 根据列号 drop 方法</span><br><span class=\"line\">   df.drop(df.columns[[1,2]], axis=1, inplace=True)</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>行</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 根据索引 删除行</span><br><span class=\"line\">   df = df.drop([1, 2])</span><br><span class=\"line\"></span><br><span class=\"line\">// 根据value 删除行</span><br><span class=\"line\">   df = df[~df[&quot;col&quot;].isin(5,9)</span><br></pre></td></tr></table></figure>\n<h3 id=\"修改与查找\"><a href=\"#修改与查找\" class=\"headerlink\" title=\"修改与查找\"></a>修改与查找</h3><blockquote>\n<p>单值修改和查找时, 参考选择行列方法。</p>\n<p>多值查找时，</p>\n</blockquote>\n<h4 id=\"按条件查找\"><a href=\"#按条件查找\" class=\"headerlink\" title=\"按条件查找\"></a>按条件查找</h4><p> <code>df_train[( df_train[&quot;row&quot;] == 1) &amp;( == &quot;null&quot;)]</code></p>\n<h4 id=\"query-查找\"><a href=\"#query-查找\" class=\"headerlink\" title=\"query 查找\"></a>query 查找</h4><p> <code>df.query(&#39;(a &lt; b) &amp; (b &lt; c)&#39;)</code></p>\n<h4 id=\"替换\"><a href=\"#替换\" class=\"headerlink\" title=\"替换\"></a>替换</h4><blockquote>\n<p>单个替换，inplace = True 覆盖源文件</p>\n</blockquote>\n<p>  <code>df.replace(to_replace, value, inplace = True)</code></p>\n<blockquote>\n<p>多值替换—-字典</p>\n</blockquote>\n<p>  <code>df.replace({&quot;A&quot;:&quot;B&quot;,  29:100})</code></p>\n<blockquote>\n<p>按条件替换</p>\n</blockquote>\n<p>  <code>df.where(df &gt; 0, -df, inplace=True)</code></p>\n<h4 id=\"交换两列的位置\"><a href=\"#交换两列的位置\" class=\"headerlink\" title=\"交换两列的位置\"></a>交换两列的位置</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df[[&apos;B&apos;, &apos;A&apos;]] = df[[&apos;A&apos;, &apos;B&apos;]]</span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"pandas-2-索引和选择数据\"><a href=\"#pandas-2-索引和选择数据\" class=\"headerlink\" title=\"pandas -2 索引和选择数据\"></a>pandas -2 索引和选择数据</h1><blockquote>\n<p>对于一种数据结构,最基本的操作就应该是增删改查了。</p>\n</blockquote>\n<h2 id=\"1-行列选择\"><a href=\"#1-行列选择\" class=\"headerlink\" title=\"1. 行列选择\"></a>1. 行列选择</h2><p>行选择和列选择有许多方法，很容易记混，常用的要记住。<br>主要方法有三种： <code>iloc</code>, <code>loc</code>, <code>[]</code></p>\n<h3 id=\"行选择\"><a href=\"#行选择\" class=\"headerlink\" title=\"行选择\"></a>行选择</h3><ul>\n<li><p>切片 </p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 切片</span><br><span class=\"line\">df[a:b]</span><br><span class=\"line\"></span><br><span class=\"line\">// 隔1行选择</span><br><span class=\"line\">df[::2]</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>指定位置</p>\n<p><code>df.iloc[1, 1]</code></p>\n<p><code>df.iloc[1:10, 2:3]</code></p>\n<p><code>df.iloc[1:10][&#39;Price&#39;]</code></p>\n</li>\n<li><p>指定索引</p>\n<p><code>df.loc[&quot;index1&quot;, &quot;index2&quot;]</code></p>\n</li>\n<li><p>按照条件查找</p>\n<p><code>df[( df[&quot;row2&quot;] == 1) &amp; (df[&quot;row2&quot;] == &quot;null&quot;)]</code></p>\n<p><code>df.loc[( df[&quot;row2&quot;] == 1) &amp; (df[&quot;row2&quot;] == &quot;null&quot;)]</code></p>\n</li>\n</ul>\n<h3 id=\"列选择\"><a href=\"#列选择\" class=\"headerlink\" title=\"列选择\"></a>列选择</h3><ul>\n<li><p>通过列标签选择单列</p>\n<p>  <code>df[&quot;price&quot;]</code></p>\n</li>\n<li><p>通过列标签选择多列</p>\n<p> <code>df[[&quot;price&quot;, &quot;time&quot;]]</code></p>\n</li>\n<li><p>通过列索引,选择前3列</p>\n<p><code>df.iloc[:, :3]</code> </p>\n</li>\n</ul>\n<h3 id=\"行列选择\"><a href=\"#行列选择\" class=\"headerlink\" title=\"行列选择\"></a>行列选择</h3><p>  <code>df.loc[:,  [&quot;price&quot;]]</code></p>\n<p>  <code>df.iloc[a:b][&#39;Price&#39;]</code></p>\n<h3 id=\"随机采样行或者列\"><a href=\"#随机采样行或者列\" class=\"headerlink\" title=\"随机采样行或者列\"></a>随机采样行或者列</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">s.sample(frac=0.5)</span><br><span class=\"line\">// 参数</span><br><span class=\"line\">// 默认选择行，n = 行数，  frac = 比例</span><br><span class=\"line\">// replace: 默认False 无放回采样</span><br><span class=\"line\">// weights: 样本采样权重</span><br><span class=\"line\">// axis:  默认=0 行,  =1 列</span><br><span class=\"line\">// random_state=2</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-行的增删改查\"><a href=\"#2-行的增删改查\" class=\"headerlink\" title=\"2. 行的增删改查\"></a>2. 行的增删改查</h2><h3 id=\"增加\"><a href=\"#增加\" class=\"headerlink\" title=\"增加\"></a>增加</h3><blockquote>\n<p>单列</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 末尾增加</span><br><span class=\"line\">   df[&quot;new col&quot;] = None</span><br><span class=\"line\">   </span><br><span class=\"line\">// 指定位置增加，在2列后</span><br><span class=\"line\">   df.insert(2,&apos;city&apos;)</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>多列</p>\n</blockquote>\n<p>   <code>pd.concat([df, pd.DataFrame(columns=[&quot;C&quot;,&quot;D&quot;])])</code></p>\n<blockquote>\n<p>单行（待验证）</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// loc 添加</span><br><span class=\"line\">  df.loc[‘5‘] = [3, 3, 3, 3]</span><br><span class=\"line\">    </span><br><span class=\"line\">// set_value 添加</span><br><span class=\"line\">  df.set_value(‘5‘, df.columns, [3,3,3,3], takeable=False)</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>多行</p>\n</blockquote>\n<p>多行相当于合并两张表了,可以参考(merge,concat)<a href=\"https://note.youdao.com/\" target=\"_blank\" rel=\"noopener\">方法</a>。</p>\n<h3 id=\"删除\"><a href=\"#删除\" class=\"headerlink\" title=\"删除\"></a>删除</h3><blockquote>\n<p>列</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// del 方法</span><br><span class=\"line\">   def df[&quot;col_name&quot;]</span><br><span class=\"line\"></span><br><span class=\"line\">//根据列名 drop 方法</span><br><span class=\"line\">   df.drop([&quot;b&quot;, &quot;c&quot;], axis=1,inplace = True)</span><br><span class=\"line\">axis = 1 列</span><br><span class=\"line\">axis = 0 行</span><br><span class=\"line\"></span><br><span class=\"line\">// 根据列号 drop 方法</span><br><span class=\"line\">   df.drop(df.columns[[1,2]], axis=1, inplace=True)</span><br></pre></td></tr></table></figure>\n<blockquote>\n<p>行</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 根据索引 删除行</span><br><span class=\"line\">   df = df.drop([1, 2])</span><br><span class=\"line\"></span><br><span class=\"line\">// 根据value 删除行</span><br><span class=\"line\">   df = df[~df[&quot;col&quot;].isin(5,9)</span><br></pre></td></tr></table></figure>\n<h3 id=\"修改与查找\"><a href=\"#修改与查找\" class=\"headerlink\" title=\"修改与查找\"></a>修改与查找</h3><blockquote>\n<p>单值修改和查找时, 参考选择行列方法。</p>\n<p>多值查找时，</p>\n</blockquote>\n<h4 id=\"按条件查找\"><a href=\"#按条件查找\" class=\"headerlink\" title=\"按条件查找\"></a>按条件查找</h4><p> <code>df_train[( df_train[&quot;row&quot;] == 1) &amp;( == &quot;null&quot;)]</code></p>\n<h4 id=\"query-查找\"><a href=\"#query-查找\" class=\"headerlink\" title=\"query 查找\"></a>query 查找</h4><p> <code>df.query(&#39;(a &lt; b) &amp; (b &lt; c)&#39;)</code></p>\n<h4 id=\"替换\"><a href=\"#替换\" class=\"headerlink\" title=\"替换\"></a>替换</h4><blockquote>\n<p>单个替换，inplace = True 覆盖源文件</p>\n</blockquote>\n<p>  <code>df.replace(to_replace, value, inplace = True)</code></p>\n<blockquote>\n<p>多值替换—-字典</p>\n</blockquote>\n<p>  <code>df.replace({&quot;A&quot;:&quot;B&quot;,  29:100})</code></p>\n<blockquote>\n<p>按条件替换</p>\n</blockquote>\n<p>  <code>df.where(df &gt; 0, -df, inplace=True)</code></p>\n<h4 id=\"交换两列的位置\"><a href=\"#交换两列的位置\" class=\"headerlink\" title=\"交换两列的位置\"></a>交换两列的位置</h4><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">df[[&apos;B&apos;, &apos;A&apos;]] = df[[&apos;A&apos;, &apos;B&apos;]]</span><br></pre></td></tr></table></figure>\n"},{"title":"pandas -1数据结构","mathjax":true,"date":"2019-07-22T01:01:01.000Z","_content":"\n# pandas -1 数据结构\n> pandas 基本操作都很简单，只是在刚开始学习的过程中，容易忘掉一些API，导致完成一些操作时，总会想着翻翻手册，这一系列博客，是对这些方法进行了梳理，可作为入门学习的参考材料。平时经常翻阅。\n\n“index” (axis=0, default), “columns” (axis=1)\n## 1. Series\n\n> Series 是一个带有 名称 和索引的一维数组。\n\n### 创建seriex\n\n```\n\n// Series 数组生成，指定数据类型\nIn:   \n    user_age = pd.Series(data=[18, 30, 25, 40], dtype=float)\n    \nOut:\n        0    18\n        1    30\n        2    25\n        3    40\n        dtype: int64\n\n\n// 增加索引 index\nIn:   \n    user_age.index = [\"Tom\", \"Bob\", \"Mary\", \"James\"]\n    \nOut:\n    Tom      18\n    Bob      30\n    Mary     25\n    James    40\n    dtype: int64\n    \n// 表头\nIn:\n    user_age.index.name(\"name\")\n    \nOut:\n    name\n    Tom      18\n    Bob      30\n    Mary     25\n    James    40\n    dtype: int64\n    \n\n```\n\n### 像字典一样使用series\n\n```\n// index 当键值\nIn: \n    user_age[\"Tom\"]\n    user_age.get(\"Tom\")\n\n// 切片-列\nIn:\n    user_age[2:3]\n    \n// 按条件查找\nIn:\n    user_age[user_age > 30]\n    \nOut:\n    name\n    James    40.0\n    Name: user_age_info, dtype: float64\n    \n```\n\n### 像向量一样使用series\n\n> 可以传递给np方法\n\n```\n// 整列加减\nIn:\n    user_age + 1\n    \nOut:\n    name\n    Tom      19.0\n    Bob      31.0\n    Mary     26.0\n    James    41.0\n    Name: user_age_info, dtype: float64\n\n\n```\n\n## 2. DataFrame\n\n> DataFrame 是一个带有 名称 和索引的二维数组，像一张Excel表格。\n\n### 创建DataFrame\n\n```\n\n// DataFrame 根据字典生成\n\nIn:\n    index = pd.Index(data=[\"Tom\", \"Bob\", \"Mary\", \"James\"], name=\"name\")\n    \n    data = {\n        \"age\": [18, 30, 40],\n        \"city\": [\"BeiJing\", \"ShangHai\", \"HangZhou\"]\n    }\n    \n    user_info = pd.DataFrame(data=data, index=index)\n    user_info\n\nOut:\n    \n// DataFrame 根据二维列表生成\nIn:\n    data = [[18, \"BeiJing\"], \n            [30, \"ShangHai\"], \n            [25, \"GuangZhou\"], \n            [40, \"ShenZhen\"]]\n    columns = [\"age\", \"city\"]\n    \n    user_info = pd.DataFrame(data=data, index=index, columns=columns)\n    user_info\n\n```","source":"_posts/pandas-1数据结构.md","raw":"---\ntitle: pandas -1数据结构\nmathjax: true\ndate: 2019-07-22 09:01:01\ncategories: pandas系列教程\ntags: pandas\n---\n\n# pandas -1 数据结构\n> pandas 基本操作都很简单，只是在刚开始学习的过程中，容易忘掉一些API，导致完成一些操作时，总会想着翻翻手册，这一系列博客，是对这些方法进行了梳理，可作为入门学习的参考材料。平时经常翻阅。\n\n“index” (axis=0, default), “columns” (axis=1)\n## 1. Series\n\n> Series 是一个带有 名称 和索引的一维数组。\n\n### 创建seriex\n\n```\n\n// Series 数组生成，指定数据类型\nIn:   \n    user_age = pd.Series(data=[18, 30, 25, 40], dtype=float)\n    \nOut:\n        0    18\n        1    30\n        2    25\n        3    40\n        dtype: int64\n\n\n// 增加索引 index\nIn:   \n    user_age.index = [\"Tom\", \"Bob\", \"Mary\", \"James\"]\n    \nOut:\n    Tom      18\n    Bob      30\n    Mary     25\n    James    40\n    dtype: int64\n    \n// 表头\nIn:\n    user_age.index.name(\"name\")\n    \nOut:\n    name\n    Tom      18\n    Bob      30\n    Mary     25\n    James    40\n    dtype: int64\n    \n\n```\n\n### 像字典一样使用series\n\n```\n// index 当键值\nIn: \n    user_age[\"Tom\"]\n    user_age.get(\"Tom\")\n\n// 切片-列\nIn:\n    user_age[2:3]\n    \n// 按条件查找\nIn:\n    user_age[user_age > 30]\n    \nOut:\n    name\n    James    40.0\n    Name: user_age_info, dtype: float64\n    \n```\n\n### 像向量一样使用series\n\n> 可以传递给np方法\n\n```\n// 整列加减\nIn:\n    user_age + 1\n    \nOut:\n    name\n    Tom      19.0\n    Bob      31.0\n    Mary     26.0\n    James    41.0\n    Name: user_age_info, dtype: float64\n\n\n```\n\n## 2. DataFrame\n\n> DataFrame 是一个带有 名称 和索引的二维数组，像一张Excel表格。\n\n### 创建DataFrame\n\n```\n\n// DataFrame 根据字典生成\n\nIn:\n    index = pd.Index(data=[\"Tom\", \"Bob\", \"Mary\", \"James\"], name=\"name\")\n    \n    data = {\n        \"age\": [18, 30, 40],\n        \"city\": [\"BeiJing\", \"ShangHai\", \"HangZhou\"]\n    }\n    \n    user_info = pd.DataFrame(data=data, index=index)\n    user_info\n\nOut:\n    \n// DataFrame 根据二维列表生成\nIn:\n    data = [[18, \"BeiJing\"], \n            [30, \"ShangHai\"], \n            [25, \"GuangZhou\"], \n            [40, \"ShenZhen\"]]\n    columns = [\"age\", \"city\"]\n    \n    user_info = pd.DataFrame(data=data, index=index, columns=columns)\n    user_info\n\n```","slug":"pandas-1数据结构","published":1,"updated":"2019-09-11T06:19:23.669Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck0evlzpl0003q8plgso7z7ht","content":"<h1 id=\"pandas-1-数据结构\"><a href=\"#pandas-1-数据结构\" class=\"headerlink\" title=\"pandas -1 数据结构\"></a>pandas -1 数据结构</h1><blockquote>\n<p>pandas 基本操作都很简单，只是在刚开始学习的过程中，容易忘掉一些API，导致完成一些操作时，总会想着翻翻手册，这一系列博客，是对这些方法进行了梳理，可作为入门学习的参考材料。平时经常翻阅。</p>\n</blockquote>\n<p>“index” (axis=0, default), “columns” (axis=1)</p>\n<h2 id=\"1-Series\"><a href=\"#1-Series\" class=\"headerlink\" title=\"1. Series\"></a>1. Series</h2><blockquote>\n<p>Series 是一个带有 名称 和索引的一维数组。</p>\n</blockquote>\n<h3 id=\"创建seriex\"><a href=\"#创建seriex\" class=\"headerlink\" title=\"创建seriex\"></a>创建seriex</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">// Series 数组生成，指定数据类型</span><br><span class=\"line\">In:   </span><br><span class=\"line\">    user_age = pd.Series(data=[18, 30, 25, 40], dtype=float)</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">        0    18</span><br><span class=\"line\">        1    30</span><br><span class=\"line\">        2    25</span><br><span class=\"line\">        3    40</span><br><span class=\"line\">        dtype: int64</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">// 增加索引 index</span><br><span class=\"line\">In:   </span><br><span class=\"line\">    user_age.index = [&quot;Tom&quot;, &quot;Bob&quot;, &quot;Mary&quot;, &quot;James&quot;]</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">    Tom      18</span><br><span class=\"line\">    Bob      30</span><br><span class=\"line\">    Mary     25</span><br><span class=\"line\">    James    40</span><br><span class=\"line\">    dtype: int64</span><br><span class=\"line\">    </span><br><span class=\"line\">// 表头</span><br><span class=\"line\">In:</span><br><span class=\"line\">    user_age.index.name(&quot;name&quot;)</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">    name</span><br><span class=\"line\">    Tom      18</span><br><span class=\"line\">    Bob      30</span><br><span class=\"line\">    Mary     25</span><br><span class=\"line\">    James    40</span><br><span class=\"line\">    dtype: int64</span><br></pre></td></tr></table></figure>\n<h3 id=\"像字典一样使用series\"><a href=\"#像字典一样使用series\" class=\"headerlink\" title=\"像字典一样使用series\"></a>像字典一样使用series</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// index 当键值</span><br><span class=\"line\">In: </span><br><span class=\"line\">    user_age[&quot;Tom&quot;]</span><br><span class=\"line\">    user_age.get(&quot;Tom&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">// 切片-列</span><br><span class=\"line\">In:</span><br><span class=\"line\">    user_age[2:3]</span><br><span class=\"line\">    </span><br><span class=\"line\">// 按条件查找</span><br><span class=\"line\">In:</span><br><span class=\"line\">    user_age[user_age &gt; 30]</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">    name</span><br><span class=\"line\">    James    40.0</span><br><span class=\"line\">    Name: user_age_info, dtype: float64</span><br></pre></td></tr></table></figure>\n<h3 id=\"像向量一样使用series\"><a href=\"#像向量一样使用series\" class=\"headerlink\" title=\"像向量一样使用series\"></a>像向量一样使用series</h3><blockquote>\n<p>可以传递给np方法</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 整列加减</span><br><span class=\"line\">In:</span><br><span class=\"line\">    user_age + 1</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">    name</span><br><span class=\"line\">    Tom      19.0</span><br><span class=\"line\">    Bob      31.0</span><br><span class=\"line\">    Mary     26.0</span><br><span class=\"line\">    James    41.0</span><br><span class=\"line\">    Name: user_age_info, dtype: float64</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-DataFrame\"><a href=\"#2-DataFrame\" class=\"headerlink\" title=\"2. DataFrame\"></a>2. DataFrame</h2><blockquote>\n<p>DataFrame 是一个带有 名称 和索引的二维数组，像一张Excel表格。</p>\n</blockquote>\n<h3 id=\"创建DataFrame\"><a href=\"#创建DataFrame\" class=\"headerlink\" title=\"创建DataFrame\"></a>创建DataFrame</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">// DataFrame 根据字典生成</span><br><span class=\"line\"></span><br><span class=\"line\">In:</span><br><span class=\"line\">    index = pd.Index(data=[&quot;Tom&quot;, &quot;Bob&quot;, &quot;Mary&quot;, &quot;James&quot;], name=&quot;name&quot;)</span><br><span class=\"line\">    </span><br><span class=\"line\">    data = &#123;</span><br><span class=\"line\">        &quot;age&quot;: [18, 30, 40],</span><br><span class=\"line\">        &quot;city&quot;: [&quot;BeiJing&quot;, &quot;ShangHai&quot;, &quot;HangZhou&quot;]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    user_info = pd.DataFrame(data=data, index=index)</span><br><span class=\"line\">    user_info</span><br><span class=\"line\"></span><br><span class=\"line\">Out:</span><br><span class=\"line\">    </span><br><span class=\"line\">// DataFrame 根据二维列表生成</span><br><span class=\"line\">In:</span><br><span class=\"line\">    data = [[18, &quot;BeiJing&quot;], </span><br><span class=\"line\">            [30, &quot;ShangHai&quot;], </span><br><span class=\"line\">            [25, &quot;GuangZhou&quot;], </span><br><span class=\"line\">            [40, &quot;ShenZhen&quot;]]</span><br><span class=\"line\">    columns = [&quot;age&quot;, &quot;city&quot;]</span><br><span class=\"line\">    </span><br><span class=\"line\">    user_info = pd.DataFrame(data=data, index=index, columns=columns)</span><br><span class=\"line\">    user_info</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"pandas-1-数据结构\"><a href=\"#pandas-1-数据结构\" class=\"headerlink\" title=\"pandas -1 数据结构\"></a>pandas -1 数据结构</h1><blockquote>\n<p>pandas 基本操作都很简单，只是在刚开始学习的过程中，容易忘掉一些API，导致完成一些操作时，总会想着翻翻手册，这一系列博客，是对这些方法进行了梳理，可作为入门学习的参考材料。平时经常翻阅。</p>\n</blockquote>\n<p>“index” (axis=0, default), “columns” (axis=1)</p>\n<h2 id=\"1-Series\"><a href=\"#1-Series\" class=\"headerlink\" title=\"1. Series\"></a>1. Series</h2><blockquote>\n<p>Series 是一个带有 名称 和索引的一维数组。</p>\n</blockquote>\n<h3 id=\"创建seriex\"><a href=\"#创建seriex\" class=\"headerlink\" title=\"创建seriex\"></a>创建seriex</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">// Series 数组生成，指定数据类型</span><br><span class=\"line\">In:   </span><br><span class=\"line\">    user_age = pd.Series(data=[18, 30, 25, 40], dtype=float)</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">        0    18</span><br><span class=\"line\">        1    30</span><br><span class=\"line\">        2    25</span><br><span class=\"line\">        3    40</span><br><span class=\"line\">        dtype: int64</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">// 增加索引 index</span><br><span class=\"line\">In:   </span><br><span class=\"line\">    user_age.index = [&quot;Tom&quot;, &quot;Bob&quot;, &quot;Mary&quot;, &quot;James&quot;]</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">    Tom      18</span><br><span class=\"line\">    Bob      30</span><br><span class=\"line\">    Mary     25</span><br><span class=\"line\">    James    40</span><br><span class=\"line\">    dtype: int64</span><br><span class=\"line\">    </span><br><span class=\"line\">// 表头</span><br><span class=\"line\">In:</span><br><span class=\"line\">    user_age.index.name(&quot;name&quot;)</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">    name</span><br><span class=\"line\">    Tom      18</span><br><span class=\"line\">    Bob      30</span><br><span class=\"line\">    Mary     25</span><br><span class=\"line\">    James    40</span><br><span class=\"line\">    dtype: int64</span><br></pre></td></tr></table></figure>\n<h3 id=\"像字典一样使用series\"><a href=\"#像字典一样使用series\" class=\"headerlink\" title=\"像字典一样使用series\"></a>像字典一样使用series</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// index 当键值</span><br><span class=\"line\">In: </span><br><span class=\"line\">    user_age[&quot;Tom&quot;]</span><br><span class=\"line\">    user_age.get(&quot;Tom&quot;)</span><br><span class=\"line\"></span><br><span class=\"line\">// 切片-列</span><br><span class=\"line\">In:</span><br><span class=\"line\">    user_age[2:3]</span><br><span class=\"line\">    </span><br><span class=\"line\">// 按条件查找</span><br><span class=\"line\">In:</span><br><span class=\"line\">    user_age[user_age &gt; 30]</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">    name</span><br><span class=\"line\">    James    40.0</span><br><span class=\"line\">    Name: user_age_info, dtype: float64</span><br></pre></td></tr></table></figure>\n<h3 id=\"像向量一样使用series\"><a href=\"#像向量一样使用series\" class=\"headerlink\" title=\"像向量一样使用series\"></a>像向量一样使用series</h3><blockquote>\n<p>可以传递给np方法</p>\n</blockquote>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">// 整列加减</span><br><span class=\"line\">In:</span><br><span class=\"line\">    user_age + 1</span><br><span class=\"line\">    </span><br><span class=\"line\">Out:</span><br><span class=\"line\">    name</span><br><span class=\"line\">    Tom      19.0</span><br><span class=\"line\">    Bob      31.0</span><br><span class=\"line\">    Mary     26.0</span><br><span class=\"line\">    James    41.0</span><br><span class=\"line\">    Name: user_age_info, dtype: float64</span><br></pre></td></tr></table></figure>\n<h2 id=\"2-DataFrame\"><a href=\"#2-DataFrame\" class=\"headerlink\" title=\"2. DataFrame\"></a>2. DataFrame</h2><blockquote>\n<p>DataFrame 是一个带有 名称 和索引的二维数组，像一张Excel表格。</p>\n</blockquote>\n<h3 id=\"创建DataFrame\"><a href=\"#创建DataFrame\" class=\"headerlink\" title=\"创建DataFrame\"></a>创建DataFrame</h3><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">// DataFrame 根据字典生成</span><br><span class=\"line\"></span><br><span class=\"line\">In:</span><br><span class=\"line\">    index = pd.Index(data=[&quot;Tom&quot;, &quot;Bob&quot;, &quot;Mary&quot;, &quot;James&quot;], name=&quot;name&quot;)</span><br><span class=\"line\">    </span><br><span class=\"line\">    data = &#123;</span><br><span class=\"line\">        &quot;age&quot;: [18, 30, 40],</span><br><span class=\"line\">        &quot;city&quot;: [&quot;BeiJing&quot;, &quot;ShangHai&quot;, &quot;HangZhou&quot;]</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    user_info = pd.DataFrame(data=data, index=index)</span><br><span class=\"line\">    user_info</span><br><span class=\"line\"></span><br><span class=\"line\">Out:</span><br><span class=\"line\">    </span><br><span class=\"line\">// DataFrame 根据二维列表生成</span><br><span class=\"line\">In:</span><br><span class=\"line\">    data = [[18, &quot;BeiJing&quot;], </span><br><span class=\"line\">            [30, &quot;ShangHai&quot;], </span><br><span class=\"line\">            [25, &quot;GuangZhou&quot;], </span><br><span class=\"line\">            [40, &quot;ShenZhen&quot;]]</span><br><span class=\"line\">    columns = [&quot;age&quot;, &quot;city&quot;]</span><br><span class=\"line\">    </span><br><span class=\"line\">    user_info = pd.DataFrame(data=data, index=index, columns=columns)</span><br><span class=\"line\">    user_info</span><br></pre></td></tr></table></figure>"}],"PostAsset":[{"_id":"source/_posts/决策树-1基本概念/tree.png","slug":"tree.png","post":"cjz98jgza000qy0pl7i4mlotz","modified":0,"renderable":0},{"_id":"source/_posts/机器学习模型的偏差与方差/biasvariance.png","slug":"biasvariance.png","post":"cjz98jgzj0013y0pla3fpxtul","modified":0,"renderable":0},{"_id":"source/_posts/Deep-Residual-Learning-for-Image-Recognition/resnet1.png","slug":"resnet1.png","post":"cjz98jgyg0004y0plwd1hr2c5","modified":0,"renderable":0},{"_id":"source/_posts/Deep-Residual-Learning-for-Image-Recognition/resnet2.png","slug":"resnet2.png","post":"cjz98jgyg0004y0plwd1hr2c5","modified":0,"renderable":0},{"_id":"source/_posts/Network-in-Network/nerworkInNetwork1.png","slug":"nerworkInNetwork1.png","post":"cjz98jgy70002y0pll2wunuym","modified":0,"renderable":0},{"_id":"source/_posts/Network-in-Network/nerworkInNetwork2.png","slug":"nerworkInNetwork2.png","post":"cjz98jgy70002y0pll2wunuym","modified":0,"renderable":0},{"_id":"source/_posts/华为软挑/huawei.jpg","slug":"huawei.jpg","post":"cjz98jh9w002by0plf67c8vtb","modified":0,"renderable":0},{"_id":"source/_posts/逻辑回归/cost.png","slug":"cost.png","post":"cjz98jha1002cy0pl7tjkwgl5","modified":0,"renderable":0},{"_id":"source/_posts/逻辑回归/sigmoid.png","slug":"sigmoid.png","post":"cjz98jha1002cy0pl7tjkwgl5","modified":0,"renderable":0}],"PostCategory":[{"post_id":"cjz98jgy70002y0pll2wunuym","category_id":"cjz98jgyl0006y0plecowj4r7","_id":"cjz98jgz5000iy0ple9yt3cp4"},{"post_id":"cjz98jgyg0004y0plwd1hr2c5","category_id":"cjz98jgyl0006y0plecowj4r7","_id":"cjz98jgz9000ny0plh9y05r9x"},{"post_id":"cjz98jgyo0008y0plrz0vr4al","category_id":"cjz98jgz4000hy0pl639vgtf1","_id":"cjz98jgzd000ty0pleojh3msh"},{"post_id":"cjz98jgyr000ay0plhh3k9491","category_id":"cjz98jgz9000oy0plycefi2ci","_id":"cjz98jgzi0010y0plwurhame5"},{"post_id":"cjz98jgze000wy0plyn6c764n","category_id":"cjz98jgz9000oy0plycefi2ci","_id":"cjz98jgzm0016y0plok1bo8vh"},{"post_id":"cjz98jgz0000fy0pl5w26g9dm","category_id":"cjz98jgz9000oy0plycefi2ci","_id":"cjz98jgzp001cy0plcy5mu9si"},{"post_id":"cjz98jgz3000gy0plwbgr2it5","category_id":"cjz98jgzm0017y0pljw2zoxwq","_id":"cjz98jgzr001hy0plewkp74f0"},{"post_id":"cjz98jgz6000ly0plme5zjmqa","category_id":"cjz98jgz9000oy0plycefi2ci","_id":"cjz98jgzt001ly0plig2fe399"},{"post_id":"cjz98jgza000qy0pl7i4mlotz","category_id":"cjz98jgzs001ky0pl08ae2i9a","_id":"cjz98jgzv001ty0plfus6yf4l"},{"post_id":"cjz98jgzb000sy0plxdglyowm","category_id":"cjz98jgzs001ky0pl08ae2i9a","_id":"cjz98jgzw001wy0plssakn0qb"},{"post_id":"cjz98jgzg000yy0planh5t7ql","category_id":"cjz98jgzv001sy0plyts3n8hh","_id":"cjz98jgzx0021y0pl4tp53gol"},{"post_id":"cjz98jgzj0013y0pla3fpxtul","category_id":"cjz98jgzs001ky0pl08ae2i9a","_id":"cjz98jgzz0025y0pl63rcrl91"},{"post_id":"cjz98jgzl0015y0plmmrnwls6","category_id":"cjz98jgzs001ky0pl08ae2i9a","_id":"cjz98jgzz0028y0pl0gdaf1ua"},{"post_id":"cjz98jgzn0019y0plvf71njsb","category_id":"cjz98jgzy0024y0plsnfpzkkj","_id":"cjz98jh00002ay0pl8y681m82"},{"post_id":"cjz98jha1002cy0pl7tjkwgl5","category_id":"cjz98jgzs001ky0pl08ae2i9a","_id":"cjz98jha5002fy0plcj5a7d40"},{"post_id":"cjz98jh9w002by0plf67c8vtb","category_id":"cjz98jha3002dy0plbe6uwv0e","_id":"cjz98jha7002iy0pls4yiiq4d"},{"post_id":"cjz98jhc9002ky0pl21cw77fw","category_id":"cjz98jhcc002ly0plly183n2m","_id":"cjz98jhch002oy0plqf5mox1m"},{"post_id":"ck0evlzot0000q8plb1cg2ev3","category_id":"cjz98jgz9000oy0plycefi2ci","_id":"ck0evlzp00002q8pliudvbwmw"},{"post_id":"ck0evlzpl0003q8plgso7z7ht","category_id":"cjz98jgz9000oy0plycefi2ci","_id":"ck0evlzpw0005q8plxjykkdzm"}],"PostTag":[{"post_id":"cjz98jgy70002y0pll2wunuym","tag_id":"cjz98jgyn0007y0pl6qzjbo0a","_id":"cjz98jgz0000ey0pl5dckl00f"},{"post_id":"cjz98jgyg0004y0plwd1hr2c5","tag_id":"cjz98jgyn0007y0pl6qzjbo0a","_id":"cjz98jgz6000ky0pl9jwdzvw3"},{"post_id":"cjz98jgyo0008y0plrz0vr4al","tag_id":"cjz98jgz5000jy0pljkpu4gif","_id":"cjz98jgzb000ry0plkquaoln2"},{"post_id":"cjz98jgyr000ay0plhh3k9491","tag_id":"cjz98jgz9000py0pl44obv793","_id":"cjz98jgzf000xy0plprwkdaz0"},{"post_id":"cjz98jgze000wy0plyn6c764n","tag_id":"cjz98jgzd000vy0pl986lo9kg","_id":"cjz98jgzi0011y0plocgeuef1"},{"post_id":"cjz98jgz0000fy0pl5w26g9dm","tag_id":"cjz98jgzd000vy0pl986lo9kg","_id":"cjz98jgzp001by0plrsq58hs5"},{"post_id":"cjz98jgz3000gy0plwbgr2it5","tag_id":"cjz98jgzn0018y0plsd6udq7h","_id":"cjz98jgzr001fy0plq9ai2p3r"},{"post_id":"cjz98jgz6000ly0plme5zjmqa","tag_id":"cjz98jgzd000vy0pl986lo9kg","_id":"cjz98jgzs001jy0plm5cot0jp"},{"post_id":"cjz98jgza000qy0pl7i4mlotz","tag_id":"cjz98jgzt001my0plu6zncn54","_id":"cjz98jgzu001ry0pltqtvxr6n"},{"post_id":"cjz98jgzb000sy0plxdglyowm","tag_id":"cjz98jgzu001qy0plblzgm7fi","_id":"cjz98jgzw001vy0pl6i8h6oqi"},{"post_id":"cjz98jgzg000yy0planh5t7ql","tag_id":"cjz98jgzv001uy0pl7ammvvi4","_id":"cjz98jgzx001zy0pl661393ot"},{"post_id":"cjz98jgzj0013y0pla3fpxtul","tag_id":"cjz98jgzx001yy0plk93ko9ws","_id":"cjz98jgzy0023y0pl9f3btc30"},{"post_id":"cjz98jgzl0015y0plmmrnwls6","tag_id":"cjz98jgzy0022y0pl03610r9v","_id":"cjz98jgzz0027y0plj2br86nl"},{"post_id":"cjz98jgzn0019y0plvf71njsb","tag_id":"cjz98jgzz0026y0pl2oao16af","_id":"cjz98jh000029y0plmwq8hey5"},{"post_id":"cjz98jh9w002by0plf67c8vtb","tag_id":"cjz98jha3002ey0plzi3iz1yn","_id":"cjz98jha6002hy0pll26dp1j9"},{"post_id":"cjz98jha1002cy0pl7tjkwgl5","tag_id":"cjz98jha5002gy0plnlqoqznl","_id":"cjz98jha7002jy0pllbrrfoca"},{"post_id":"cjz98jhc9002ky0pl21cw77fw","tag_id":"cjz98jhcd002my0pleihnzt3g","_id":"cjz98jhch002ny0plbdkrz45l"},{"post_id":"ck0evlzot0000q8plb1cg2ev3","tag_id":"cjz98jgzd000vy0pl986lo9kg","_id":"ck0evlzoz0001q8plghjr96a9"},{"post_id":"ck0evlzpl0003q8plgso7z7ht","tag_id":"cjz98jgzd000vy0pl986lo9kg","_id":"ck0evlzpv0004q8plrpvg5hv9"}],"Tag":[{"name":"深度学习论文","_id":"cjz98jgyn0007y0pl6qzjbo0a"},{"name":"git","_id":"cjz98jgz5000jy0pljkpu4gif"},{"name":"pandas-MultiIndex","_id":"cjz98jgz9000py0pl44obv793"},{"name":"pandas","_id":"cjz98jgzd000vy0pl986lo9kg"},{"name":"XGBoost","_id":"cjz98jgzn0018y0plsd6udq7h"},{"name":"决策树","_id":"cjz98jgzt001my0plu6zncn54"},{"name":"ROC","_id":"cjz98jgzu001qy0plblzgm7fi"},{"name":"闲聊","_id":"cjz98jgzv001uy0pl7ammvvi4"},{"name":"方差与偏差","_id":"cjz98jgzx001yy0plk93ko9ws"},{"name":"集成学习","_id":"cjz98jgzy0022y0pl03610r9v"},{"name":"Java类加载机制","_id":"cjz98jgzz0026y0pl2oao16af"},{"name":"华为软挑初赛","_id":"cjz98jha3002ey0plzi3iz1yn"},{"name":"逻辑回归","_id":"cjz98jha5002gy0plnlqoqznl"},{"name":"C++","_id":"cjz98jhcd002my0pleihnzt3g"}]}}